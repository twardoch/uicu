This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.cursor/
  rules/
    data-flow.mdc
    data-models.mdc
    unicode-wrapper-implementation.mdc
.giga/
  specifications.json
.github/
  workflows/
    push.yml
    release.yml
research/
  res-gemi.md
  res-gpt.md
  res-grok.md
  res-phind.md
src/
  uicu/
    uicu.py
tests/
  test_package.py
.cursorrules
.gitignore
.pre-commit-config.yaml
AGENTS.md
build.sh
CLAUDE.md
LICENSE
package.toml
pyproject.toml
README.md
TODO.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".cursor/rules/data-flow.mdc">
---
description: Documents Unicode data processing flows, transformations and integration points between PyICU and fontTools.unicodedata
globs: src/uicu/**/*.py,tests/**/*_test.py
alwaysApply: false
---


# data-flow

## Core Unicode Data Pipeline

1. **PyICU Integration Layer**
- Wraps PyICU's Unicode processing capabilities into a Pythonic interface
- Handles raw Unicode data input from PyICU API
- Transforms data into Python native Unicode objects
- File: `src/uicu/pyicu_wrapper.py`

2. **FontTools Data Enrichment**
- Augments Unicode data with writing system information from fontTools.unicodedata
- Merges supplementary Unicode properties into the data stream
- File: `src/uicu/font_tools_bridge.py`

3. **Unified Data Model**
- Combines data from both sources into cohesive Unicode objects 
- Maintains relationship between original PyICU data and enriched properties
- File: `src/uicu/models.py`

## Data Transformation Flows

1. **Unicode Normalization Pipeline**
- Processes incoming Unicode through configurable normalization forms
- Integrates PyICU normalization with Python's unicodedata
- File: `src/uicu/normalizer.py`

2. **Writing System Analysis**
- Extracts writing system metadata from fontTools
- Associates script information with Unicode code points
- File: `src/uicu/writing_systems.py`

## Integration Points

1. **PyICU Bridge** 
- Direct interface to ICU Unicode processing
- Handles data format conversions between PyICU and Python
- File: `src/uicu/icu_bridge.py`

2. **FontTools Connector**
- Manages access to supplementary Unicode data
- Synchronizes property lookups between systems
- File: `src/uicu/font_tools.py`

$END$

 If you're using this file in context, clearly say in italics in one small line that "Context added by Giga data-flow".
</file>

<file path=".cursor/rules/data-models.mdc">
---
description: Defines core data structures and models for Unicode data handling and Python type relationships
globs: src/uicu/*.py,tests/**/test_models.py,tests/**/test_data.py
alwaysApply: false
---


# data-models

## Core Data Models (Importance: 95)

The data model architecture centers around representing and transforming Unicode data between PyICU objects and Python native types:

1. **Unicode Data Representation**
- Custom data structures for Unicode character properties
- Mappings between PyICU Unicode database entries and Python string types
- Integration with fontTools.unicodedata writing system information
File: `src/uicu/models.py`

2. **Type Relationships** 
- Data models defining bidirectional conversion between:
  - PyICU UChar objects
  - Python str/bytes types
  - Writing system metadata from fontTools
- Cross-reference tables for character properties
File: `src/uicu/types.py`

## Object Model Hierarchy (Importance: 85)

Core class hierarchy for Unicode data abstraction:

```python
class UnicodeData:
    """Base class for Unicode character data"""
    # Maps to PyICU character database

class WritingSystemData:
    """Writing system metadata"""  
    # Integrates fontTools script information
```

File: `src/uicu/models.py`

## Model Relationships (Importance: 80)

The data models maintain bidirectional relationships between:

- PyICU's native character database structures
- Python's built-in Unicode string handling
- fontTools writing system metadata
- Custom property mappings and cross-references

These relationships enable seamless conversion while preserving Unicode data integrity.

File: `src/uicu/relationships.py`

$END$

 If you're using this file in context, clearly say in italics in one small line that "Context added by Giga data-models".
</file>

<file path=".cursor/rules/unicode-wrapper-implementation.mdc">
---
description: Specifies the implementation of the Pythonic Unicode wrapper functionality around PyICU and fontTools.unicodedata
globs: src/uicu/*.py,tests/*_unicode*.py,tests/*_icu*.py
alwaysApply: false
---


# unicode-wrapper-implementation

### Core Unicode Wrapper Components

1. **PyICU Integration Layer** (Importance: 95)
- Custom wrapper classes that provide Pythonic interfaces to PyICU's Unicode operations
- Handles encoding/decoding between Python's native Unicode and ICU's internal formats
- File path: `src/uicu/icu_wrapper.py`

2. **fontTools Integration** (Importance: 85)
- Supplementary writing system information extraction from fontTools.unicodedata
- Merges font-specific Unicode data with ICU capabilities
- File path: `src/uicu/font_unicode.py`

3. **Unicode Data Objects** (Importance: 90)
- Rich object model representing Unicode characters with extended properties
- Custom attributes for writing system classification
- Advanced normalization and decomposition handling
- File path: `src/uicu/unicode_data.py`

4. **Unicode Operation Pipeline** (Importance: 85)
- Structured workflow for processing Unicode text through multiple stages
- Configurable transformation chain for character normalization
- Fallback handling for unsupported Unicode operations
- File path: `src/uicu/pipeline.py`

### Domain-Specific Implementations

1. **Writing System Detection** (Importance: 80)
- Custom algorithms for identifying writing systems in mixed Unicode text
- Integration of ICU script detection with fontTools metadata
- File path: `src/uicu/script_detect.py`

2. **Unicode Data Enrichment** (Importance: 75)
- Enhancement of Unicode character properties with additional metadata
- Custom property definitions for specialized text processing needs
- File path: `src/uicu/property_extend.py`

### Test Infrastructure

1. **Unicode Test Cases** (Importance: 70)
- Comprehensive test suite for Unicode handling edge cases
- Validation of character property preservation
- File path: `tests/test_unicode_wrapper.py`

2. **Integration Tests** (Importance: 75)
- Tests for PyICU and fontTools integration points
- Verification of combined Unicode operations
- File path: `tests/test_integration.py`

$END$

 If you're using this file in context, clearly say in italics in one small line that "Context added by Giga unicode-wrapper-implementation".
</file>

<file path=".giga/specifications.json">
[
  {
    "fileName": "main-overview.mdc",
    "description": "High-level overview of the uicu system architecture, core components, and integration with PyICU and fontTools.unicodedata"
  },
  {
    "fileName": "unicode-wrapper-implementation.mdc",
    "description": "Detailed documentation of the Pythonic wrapper implementation around PyICU, including class hierarchies, method signatures, and Unicode handling algorithms"
  },
  {
    "fileName": "data-models.mdc",
    "description": "Documentation of core data structures and models used to represent Unicode data, including relationships between PyICU objects and Python native types"
  },
  {
    "fileName": "data-flow.mdc",
    "description": "Documentation of how Unicode data flows through the system, including processing pipelines, transformations, and integration points between PyICU and fontTools.unicodedata"
  }
]
</file>

<file path="research/res-gemi.md">
Create

# Specification for `uicu`: A Pythonic Internationalization Library

## Part 1: Analysis of Foundation Libraries & Rationale for `uicu`

The landscape of Python internationalization (i18n) is dominated by powerful,
yet often inaccessible, tools. While the standard library provides basic
Unicode support, complex, locale-sensitive operations require more specialized
libraries. The most comprehensive of these is `PyICU`, a Python binding for
the industry-standard "International Components for Unicode" (ICU) C++
libraries. ICU is the gold standard for i18n, implementing vast portions of
the Unicode Standard and the Common Locale Data Repository (CLDR). However,
`PyICU`'s power is encumbered by an Application Programming Interface (API)
that is fundamentally un-pythonic, creating a significant barrier to adoption
and effective use.

This specification details the design of `uicu`, a new Python library that
serves as a high-level, pythonic wrapper around `PyICU`. `uicu` is not a
replacement for `PyICU` but a carefully designed abstraction layer. Its goal
is to expose the full power of the ICU engine through an API that is natural,
intuitive, and seamlessly integrated with the Python language and its
ecosystem. Furthermore, where `PyICU`'s data is incomplete or less accessible,
particularly concerning script and writing system metadata, `uicu` will
strategically supplement its functionality with the `fontTools.unicodedata`
module, which provides access to the most current Unicode data. This document
provides a complete architectural blueprint for `uicu`, intended to guide its
implementation by a developer.

### 1.1 An Autopsy of the PyICU API: Power Encumbered by a C++ Legacy

To understand the necessity for `uicu`, one must first perform a critical
analysis of `PyICU`. The library is not flawed in its core function—it
successfully exposes the vast capabilities of ICU to Python. Its primary
deficiency lies in its design philosophy, which prioritizes a direct, one-to-
one mapping from the underlying C++ library over Python developer ergonomics.
This results in an API that feels alien to seasoned Python developers and
presents a steep learning curve for newcomers.

#### 1.1.1 The C++ Mirror

The `PyICU` API is, by design, a thin wrapper around the ICU4C C++ library.
There is no official API documentation for `PyICU` itself; the documentation
explicitly directs users to the ICU4C C++ API reference and provides a set of
translation patterns. This design choice has profound consequences for the
user experience:  

  * **Class Naming:** Class names are lifted directly from C++, resulting in `PascalCase` names like `Transliterator`, `BreakIterator`, `Collator`, and `DateFormat`, which deviate from Python's PEP 8 convention of `CapWords` for classes but are often used in contexts where `snake_case` functions would be more appropriate.  

  * **Method Naming:** Method names also follow the C++ `camelCase` convention (e.g., `getDisplayName`, `createInstance`, `nextBoundary`) rather than Python's `snake_case`.

  *  **Enumerations:** `PyICU` uses C-style enumerations, such as `icu.DateFormat.LONG` or `icu.UTransDirection.REVERSE`, which are represented as integer constants. A pythonic approach would favor string literals (`'long'`) or `Enum` types for better readability and self-documentation.

This direct mapping forces the Python developer to learn and operate within a
C++ paradigm, constantly translating concepts and consulting external, non-
Python documentation to perform even basic tasks.

#### 1.1.2 A Catalogue of Pythonic Anti-Patterns

The friction caused by `PyICU` extends beyond naming conventions into
fundamental API design patterns that conflict with established Python idioms.
The following examples represent the most significant sources of this
friction.

  *  **Mutable`UnicodeString` and In-Place Modification:** Python's native `str` type is immutable, a cornerstone of its design that ensures predictability and safety. In stark contrast, `PyICU`'s primary string type, `UnicodeString`, is mutable. This leads to one of the most un-pythonic patterns in the library: functions that modify arguments in-place. This "output parameter" pattern, common in C and C++, is highly unconventional in Python.

For example, to get the display name of a locale, the "ICU way" involves
passing a mutable `UnicodeString` object to be modified:

Python

    
        # PyICU: In-place modification (un-pythonic)
    from icu import UnicodeString, Locale
    locale = Locale('pt_BR')
    string_buffer = UnicodeString()
    name = locale.getDisplayName(string_buffer)
    # `name` is the same object as `string_buffer`, which has been modified.
    # name is string_buffer -> True
    

While `PyICU` often provides a more "Python way" that allocates a new string,
the existence and documentation of the in-place modification pattern is a
source of confusion and potential bugs. It violates the principle that
functions should return results without causing side effects on their
arguments.

  *  **Cumbersome Iteration:** Python's `for` loop is a powerful and elegant construct for iteration. `PyICU`'s iteration mechanisms, however, are low-level and stateful, requiring manual bookkeeping. The `BreakIterator`, used for segmenting text into words, sentences, or graphemes, is a prime example. Its usage is described as "a pain" and requires the developer to manually call `nextBoundary()` and track indices.

Python

    
        # PyICU: Manual, stateful iteration
    from icu import BreakIterator, Locale
    text = 'Bist du in der U-Bahn geboren?'
    de_words = BreakIterator.createWordInstance(Locale('de_DE'))
    de_words.setText(text)
    
    words =
    last_pos = 0
    while True:
        next_boundary = de_words.nextBoundary()
        if next_boundary == -1:
            break
        words.append(text[last_pos:next_boundary])
        last_pos = next_boundary
    # words ->
    

A Python developer expects a simple generator or an object that implements the
iterator protocol, allowing for `for word in segmenter:...`. Similarly, the
`StringEnumeration` object provides three different `next` methods (`next`,
`unext`, `snext`) for retrieving different string types, adding another layer
of complexity to what should be a straightforward iteration.

  *  **Opaque Type Conversions:** The library performs some automatic type conversions to bridge the gap between Python and ICU types. For instance, it converts Python `datetime` objects and numeric timestamps into ICU's `UDate` format (a float representing milliseconds since the Unix epoch). While intended as a convenience, this implicit magic can obscure what is happening under the hood. A float passed to a date function is automatically multiplied by 1000, a detail a developer must remember to correctly interpret the underlying `UDate` value. A pythonic library should either be explicit about its conversions or handle them so transparently that the user never needs to be aware of the internal types.

  *  **Generic Error Handling:** `PyICU` commendably translates ICU's C-style `UErrorCode` status values into a Python exception, `ICUError`. This is a significant improvement over checking return codes. However, using a single, generic exception type for the entire library is a missed opportunity. The ICU library can fail for hundreds of different reasons, from a malformed locale string to an invalid formatting pattern. A single `ICUError` forces the developer to parse the error message string to determine the cause of failure, making robust, programmatic error handling difficult.

The cumulative effect of these anti-patterns is a developer experience fraught
with friction. The initial hurdle of installing `PyICU`, which often requires
manual configuration of C++ compilers and library paths due to its dependency
on the ICU C++ libraries, is substantial. For a developer to overcome this
barrier only to be met with a non-intuitive API that requires consulting C++
documentation is a significant deterrent. This compounding friction
discourages the use of ICU's powerful features in the Python ecosystem. The
primary value of `uicu` is to eliminate this second, API-level barrier, thus
making the initial investment in installation a much more reasonable
proposition.

PyICU Anti-Pattern

|

Example `PyICU` Code

|

Problem Description

|

`uicu` Design Principle

|

Proposed `uicu` Code  
  
---|---|---|---|---  
  
In-place argument modification

|

`name = locale.getDisplayName(string_buffer)`

|

Violates Python's convention of immutability and functional returns. Confusing
and error-prone.

|

Immutability and Functional Returns

|

`name = locale.display_name()`  
  
Stateful, manual iteration

|

`while True: boundary = bi.nextBoundary()`

|

Verbose, low-level, and requires manual state tracking. Unnatural for Python
developers.

|

Iterable and Generator-based APIs

|

`for word in segmenter.segment(text):...`  
  
Verbose factory methods with constants

|

`df = DateFormat.createDateInstance(DateFormat.LONG, locale)`

|

Relies on C-style integer constants. Not self-documenting.

|

Object-Oriented Factories with String Keywords

|

`df = locale.get_date_formatter(style='long')`  
  
Ambiguous `key` function for sorting

|

`sorted(L, key=collator.getSortKey)`

|

The method name `getSortKey` is explicit but verbose. The object itself should
be the key.

|

Leverage Dunder Methods (`__call__`)

|

`sorted(L, key=my_collator)`  
  
Generic exception type

|

`except ICUError as e: if "U_ILLEGAL_ARGUMENT_ERROR" in str(e):...`

|

Prevents specific, programmatic error handling. Requires fragile string
parsing of error messages.

|

Rich, Specific Exception Hierarchy

|

`except uicu.ConfigurationError as e:...`  
  
Export to Sheets

#### 1.1.3 Core Functionality Mapping

Despite its challenging API, `PyICU` provides access to an unparalleled suite
of internationalization services. A successful wrapper must recognize and
preserve this power. The key functional domains of `PyICU` that `uicu` will
abstract include:

  *  **Locale:** Handling locale identifiers and providing access to locale-specific data (`icu.Locale`).

  *  **Collation:** Performing locale-sensitive string sorting (`icu.Collator`, `icu.RuleBasedCollator`).

  *  **Formatting:** Formatting dates, times, numbers, currencies, and lists according to locale conventions (`icu.DateFormat`, `icu.NumberFormat`, `icu.ListFormatter`).  

  * **Message Formatting:** Handling pluralization and gender in translated strings (`icu.MessageFormat`).  

  * **Transliteration:** Converting text between different scripts (e.g., Cyrillic to Latin) (`icu.Transliterator`).

  *  **Segmentation:** Breaking text into its logical components like graphemes, words, or sentences (`icu.BreakIterator`).

  *  **Time Zones:** Accessing ICU's comprehensive time zone database (`icu.TimeZone`, `icu.ICUtzinfo`).

`uicu`'s mission is to liberate this functionality, making it accessible
through a clean, pythonic interface.

### 1.2 The Strategic Role of `fontTools.unicodedata`

While `PyICU` is the primary engine for locale-sensitive operations, it is not
the ideal source for all Unicode character data. For this, `uicu` will turn to
`fontTools.unicodedata`, a module within the powerful `fontTools` library.
This is a strategic choice based on data currency, functional specialization,
and API quality.

#### 1.2.1 Decoupling from the Python Runtime

Python's standard library includes a `unicodedata` module. However, the
version of the Unicode Character Database (UCD) it contains is fixed to the
version of the Python interpreter itself. An application running on Python 3.9
will have an older UCD than one on Python 3.12. This can lead to
inconsistencies and an inability to work with the latest characters and
properties.

The `fontTools` library, when installed with the `[unicode]` extra, depends on
`unicodedata2`. `unicodedata2` is a standalone package whose versions are
explicitly tied to Unicode standard versions (e.g., `unicodedata2==15.0.0`
contains data from Unicode 15.0). By using `fontTools.unicodedata`, `uicu`
ensures that developers can access up-to-date Unicode data, independent of the
Python runtime they are using.

#### 1.2.2 Rich Script and Writing System Metadata

The most compelling reason to use `fontTools.unicodedata` is its specialized
functionality related to writing systems, a domain critical for typography and
advanced text processing. It provides a clean, direct API for accessing
properties that are not as easily surfaced through `PyICU`. Key functions
include :  

  * `script(char)`: Returns the four-letter ISO 15924 script code for a character (e.g., `'Latn'`, `'Cyrl'`).

  * `script_name(script_code)`: Converts a script code to its human-readable name (e.g., `'Latn'` -> `'Latin'`).

  * `block(char)`: Returns the Unicode block a character belongs to (e.g., `'Basic Latin'`).

  * `ot_tags_from_script(script_code)`: Provides the crucial mapping from a Unicode script code to its corresponding OpenType script tag(s), essential for font feature interaction.

  * `ot_tag_to_script(tag)`: Provides the reverse mapping.

This functionality directly addresses the needs of applications that go beyond
simple string comparison and formatting into the realm of text layout and font
manipulation.

#### 1.2.3 API Consistency

The API of `fontTools.unicodedata` is simple, functional, and pythonic. It
consists of straightforward functions that take a character or code and return
a result. This design philosophy serves as a model for the non-locale-
sensitive parts of `uicu`, reinforcing the goal of creating a clean and
predictable developer experience.

The use of both `PyICU` and `fontTools.unicodedata` introduces a potential for
inconsistency, as the Unicode data may come from two different sources (the
version of `libicu` linked by `PyICU` and the version of `unicodedata2` used
by `fontTools`). An application dealing with internationalization requires a
single, authoritative source of truth. A subtle bug could arise if a character
property check using one library yields a different result from a check using
the other.

To mitigate this, `uicu` will establish a clear "chain of command" for data
access. For general, non-locale-specific Unicode character properties (e.g.,
name, category, numeric value, script, block), `uicu` will default to
`fontTools.unicodedata` as the primary source, ensuring access to the latest
Unicode standard data. For all locale-sensitive operations (e.g., collation,
date/number formatting, segmentation), `uicu` will exclusively use the `PyICU`
engine, which relies on the comprehensive CLDR data bundled with ICU. This
hybrid approach, clearly defined and documented, provides the best of both
worlds: the most current character data and the most powerful i18n engine.

## Part 2: The `uicu` Library: A Detailed Specification

This section provides the complete architectural and API design for the `uicu`
library. It is intended to be a prescriptive blueprint for implementation,
detailing the structure, classes, methods, and behavior of the new library.

### 2.1 Guiding Principles of the `uicu` API

The design of `uicu` is governed by a set of core principles aimed at creating
an API that is powerful, discoverable, and above all, pythonic. These
principles are a direct response to the shortcomings identified in the `PyICU`
API and are informed by best practices in modern Python library design.

#### 2.1.1 The Pythonic Contract

  *  **Naming Conventions:** All public-facing modules, classes, functions, and methods will strictly adhere to PEP 8 naming conventions. Modules and functions will use `snake_case` (e.g., `uicu.collate`, `uicu.char.get_name`). Classes will use `CapWords` (e.g., `uicu.Locale`, `uicu.format.NumberFormatter`). This provides immediate visual consistency with the broader Python ecosystem.

  *  **Immutability by Default:** Where possible, objects will be immutable. Configuration objects like formatters and collators, once created and configured, will not be modifiable. All functions and methods will return new, native Python objects (`str`, `tuple`, `datetime.datetime`) rather than modifying arguments in-place or returning special wrapper types. This promotes a functional style and prevents unexpected side effects.

  *  **Native Type Integration:** The entire public API surface will exclusively accept and return standard Python types. A user will never need to instantiate or handle a `PyICU.UnicodeString` or be aware of the `UDate` timestamp format. All necessary conversions will be handled transparently within the `uicu` wrapper.

  *  **Leveraging the Language:** The library will make extensive use of Python's special "dunder" methods to make its objects behave intuitively. For example, segmenter objects will be iterable (`__iter__`), collator objects will be callable (`__call__`), and all objects will have useful string representations (`__str__`, `__repr__`).

#### 2.1.2 A Coherent, Object-Oriented Model

`uicu` will be structured around a clear, object-oriented model where objects
represent configured "service providers." Instead of a procedural approach
with standalone functions, the primary workflow will involve:

  1. Instantiating a central `uicu.Locale` object to define context.

  2. Using this `Locale` object as a factory to create specialized, locale-aware service objects (e.g., a `Collator` or `DateTimeFormatter`).

  3. Calling methods on these service objects to perform operations.

This pattern promotes encapsulation, reusability, and thread safety, as
configured service objects can be created once and used many times.

#### 2.1.3 A Rich Exception Hierarchy

To enable robust and specific error handling, `uicu` will define its own
exception hierarchy, inheriting from a common base exception. This allows
consumers of the library to write fine-grained `try...except` blocks, a
significant improvement over `PyICU`'s single `ICUError`.

The proposed hierarchy is:

  * `uicu.Error(Exception)`: The base exception for all errors originating from the `uicu` library.

    * `uicu.ConfigurationError(uicu.Error)`: Raised for errors during setup, such as providing an invalid locale identifier or a malformed rule string.

    * `uicu.FormattingError(uicu.Error)`: Raised by any of the formatters in the `uicu.format` sub-package for invalid patterns or inputs.

    * `uicu.CollationError(uicu.Error)`: Raised by the `uicu.collate` module for issues related to collation rules.

    * `uicu.SegmentationError(uicu.Error)`: Raised by the `uicu.segment` module.

    * `uicu.TransliterationError(uicu.Error)`: Raised for invalid transliteration IDs or rules.

Module/Class

|

Core Purpose

|

Key Method/Usage

|

Abstracts `PyICU` Component  
  
---|---|---|---  
  
`uicu.char`

|

Provides access to non-locale-specific Unicode character properties.

|

`uicu.char.script('A')`

|

`fontTools.unicodedata`  
  
`uicu.locale.Locale`

|

Represents a specific locale and acts as a factory for locale-sensitive
services.

|

`locale = uicu.Locale('de-DE')`

|

`icu.Locale`  
  
`uicu.collate.Collator`

|

Provides locale-sensitive string comparison for sorting.

|

`sorted(L, key=collator)`

|

`icu.Collator`  
  
`uicu.format.DateTimeFormatter`

|

Formats `datetime` objects into locale-specific strings.

|

`formatter.format(datetime.now())`

|

`icu.DateFormat`  
  
`uicu.format.NumberFormatter`

|

Formats numbers, currencies, and percentages.

|

`formatter.format_currency(123.45, 'EUR')`

|

`icu.NumberFormat`  
  
`uicu.format.ListFormatter`

|

Joins a list of strings with locale-correct conjunctions.

|

`formatter.format(['a', 'b', 'c'])`

|

`icu.ListFormatter`  
  
`uicu.segment.WordSegmenter`

|

Segments text into words according to locale-specific rules.

|

`for word in segmenter.segment(text):...`

|

`icu.BreakIterator`  
  
`uicu.translit`

|

Provides functions for script transliteration.

|

`uicu.translit.transliterate(text, 'Cyrl-Latn')`

|

`icu.Transliterator`  
  
Export to Sheets

### 2.2 The `uicu.char` Module: A Unified View of Character Properties

This module will serve as the single, authoritative source for non-locale-
sensitive Unicode character data, implementing the "Data Authority Principle."
It will primarily delegate to `fontTools.unicodedata` to ensure access to the
latest Unicode version data.  

**Functions:**

All functions will take a single argument, `char`, which must be a string of
length 1. They will raise a `ValueError` if the string is not of length 1.

  * `name(char: str, default: Any =...) -> str`: Returns the official Unicode name for the character. If no name exists and a default is provided, returns the default; otherwise, raises a `KeyError`.

  * `category(char: str) -> str`: Returns the two-letter general category abbreviation (e.g., 'Lu', 'Nd', 'Po').

  * `numeric(char: str, default: Any =...) -> Union[int, float]`: Returns the numeric value of the character.

  * `script(char: str) -> str`: Returns the four-letter ISO 15924 script code (e.g., 'Latn').

  * `script_name(char: str) -> str`: Returns the human-readable script name (e.g., 'Latin').

  * `block(char: str) -> str`: Returns the name of the Unicode block the character belongs to.

  * `bidirectional(char: str) -> str`: Returns the bidirectional class (e.g., 'L', 'R', 'AN').

  * `combining(char: str) -> int`: Returns the canonical combining class as an integer.

  * `mirrored(char: str) -> bool`: Returns `True` if the character is a mirrored character in bidirectional text.

  * `is_private_use(char: str) -> bool`: Checks if the character is in a Private Use Area.

  * `is_control(char: str) -> bool`: Checks if the character is a C0 or C1 control code.

### 2.3 The `uicu.locale` Module: The Contextual Heart of the Library

This module defines the `Locale` class, which is the central entry point for
all locale-sensitive operations. It encapsulates a specific locale and acts as
a factory for service objects.

 **`uicu.Locale` Class:**

  *  **`__init__(self, locale_identifier: str)`**

    * Accepts a locale identifier string in BCP 47 format (e.g., `'en-GB'`, `'fr-CA'`, `'zh-Hant-TW'`).

    * The constructor will immediately call the underlying `icu.Locale.canonicalize` to validate and normalize the identifier, raising `uicu.ConfigurationError` on failure.

    * Internally stores the canonicalized `icu.Locale` object.

  *  **Properties (read-only):**

    * `display_name` -> `str`: The full, human-readable name of the locale in the default system locale's language (e.g., `'English (United Kingdom)'`).

    * `language_display_name` -> `str`: The human-readable name of the language (e.g., `'English'`).

    * `script_display_name` -> `str`: The human-readable name of the script.

    * `region_display_name` -> `str`: The human-readable name of the region.

    * `language` -> `str`: The two- or three-letter language code (e.g., `'en'`).

    * `script` -> `str`: The four-letter script code (e.g., `'Latn'`).

    * `region` -> `str`: The two-letter or three-digit region code (e.g., `'GB'`).

    * `base_name` -> `str`: The string representation of the canonicalized locale identifier.

  *  **Factory Methods:**

    * `get_collator(...) -> uicu.collate.Collator`: Returns a configured `Collator` object for this locale.

    * `get_datetime_formatter(...) -> uicu.format.DateTimeFormatter`: Returns a `DateTimeFormatter`.

    * `get_date_formatter(...) -> uicu.format.DateTimeFormatter`: A convenience for a date-only formatter.

    * `get_time_formatter(...) -> uicu.format.DateTimeFormatter`: A convenience for a time-only formatter.

    * `get_number_formatter(...) -> uicu.format.NumberFormatter`: Returns a `NumberFormatter`.

    * `get_list_formatter(...) -> uicu.format.ListFormatter`: Returns a `ListFormatter`.

    * `get_message_formatter(pattern: str) -> uicu.format.MessageFormatter`: Returns a `MessageFormatter` for a given pattern string.

    * `get_grapheme_segmenter() -> uicu.segment.GraphemeSegmenter`: Returns a segmenter for grapheme clusters.

    * `get_word_segmenter() -> uicu.segment.WordSegmenter`: Returns a segmenter for words.

    * `get_sentence_segmenter() -> uicu.segment.SentenceSegmenter`: Returns a segmenter for sentences.

### 2.4 The `uicu.collate` Module: Pythonic Sorting

This module provides an intuitive interface to ICU's powerful collation
engine.

 **`uicu.Collator` Class:**

This class is designed to be used directly as a `key` in sorting functions.

  *  **Instantiation:** Should not be instantiated directly. Use `locale.get_collator()`.

  *  **`__call__(self, text: str) -> bytes`:**

    * This is the core method. It takes a Python string and returns a binary sort key. When used as `sorted(my_list, key=my_collator)`, Python's sorting algorithm will use these binary keys for comparison.

    * This transparently wraps `PyICU`'s `collator.getSortKey(text)`.

  *  **`compare(self, a: str, b: str) -> int`:**

    * Explicitly compares two strings, returning -1, 0, or 1. Wraps `collator.compare(a, b)`.

  *  **Configuration (Builder Pattern):**

    * The `locale.get_collator()` method will accept optional arguments for common configurations. For advanced customization, a builder-style API could be considered for future extension to avoid the complexity of raw ICU rule strings.

 _Example Usage:_

Python

    
        import uicu
    locale = uicu.Locale('sv-SE') # Swedish
    collator = locale.get_collator()
    data = ['ångström', 'apple', 'zebra']
    # The collator object is used directly as the key
    sorted_data = sorted(data, key=collator)
    # Expected: ['apple', 'zebra', 'ångström']
    

### 2.5 The `uicu.format` Sub-package: Intuitive Data Formatting

This sub-package contains a suite of classes, each dedicated to a specific
formatting task.

 **`uicu.format.DateTimeFormatter`:**

  *  **Instantiation:** Via `locale.get_datetime_formatter(date_style: str = 'medium', time_style: str = 'medium', pattern: str = None, timezone: Union[str, datetime.tzinfo] = None)`.

    * `date_style` / `time_style` accept strings: `'full'`, `'long'`, `'medium'`, `'short'`, `'none'`. This replaces `icu.DateFormat.kDefault`, `LONG`, etc..

    * `pattern` allows for custom format strings (e.g., `'yyyy-MM-dd'`).

    * `timezone` accepts a timezone ID string (e.g., `'Europe/Berlin'`) or a `datetime.tzinfo` object.

  *  **`format(self, dt: datetime.datetime) -> str`:** Accepts a standard Python `datetime` object and returns a formatted string.

 **`uicu.format.NumberFormatter`:**

  *  **Instantiation:** Via `locale.get_number_formatter(style: str = 'decimal', pattern: str = None, min_fraction_digits: int = None,...)`

    * `style` accepts strings: `'decimal'`, `'percent'`, `'currency'`, `'scientific'`.

  *  **`format(self, number: Union) -> str`:** Formats a number.

  *  **`format_currency(self, number: Union, currency: str) -> str`:** A dedicated method for currency formatting that takes a 3-letter ISO 4217 currency code (e.g., `'USD'`, `'EUR'`).

 **`uicu.format.ListFormatter`:**

  *  **Instantiation:** Via `locale.get_list_formatter(style: str = 'standard', list_type: str = 'and')`.

    * `list_type` accepts `'and'`, `'or'`, or `'units'`.

  *  **`format(self, items: Iterable[str]) -> str`:** Joins an iterable of strings. _Example Usage:_ `locale.get_list_formatter().format(['one', 'two', 'three'])` -> `'one, two, and three'` (in English).

 **`uicu.format.MessageFormatter`:**

  *  **Instantiation:** Via `locale.get_message_formatter(pattern: str)`.

  *  **`format(self, **kwargs) -> str` or `format(params: Dict[str, Any]) -> str`:** Formats the message using ICU's rich plural and select rule syntax. _Example Usage:_

Python

    
        pattern = "{count, plural, one{# apple} other{# apples}} for {gender, select, male{him} female{her} other{them}}."
    msg_fmt = uicu.Locale('en').get_message_formatter(pattern)
    result = msg_fmt.format(count=1, gender='female')
    # result -> '1 apple for her'
    

### 2.6 The `uicu.segment` Module: Natural Text Segmentation

This module provides pythonic iterators for text boundary analysis, completely
abstracting the stateful `BreakIterator`.

 **`GraphemeSegmenter`, `WordSegmenter`, `SentenceSegmenter` Classes:**

  *  **Instantiation:** Via factory methods on a `Locale` object (e.g., `locale.get_word_segmenter()`). The segmenters are lightweight and can be created on-the-fly.

  *  **`segment(self, text: str) -> Iterator[str]`:**

    * This is the primary method for all segmenter classes. It takes a string and returns a generator that yields the segmented parts of the string.

    * This design allows for efficient, lazy processing of large texts and fits perfectly with Python's iteration patterns.

 _Example Usage:_

Python

    
        import uicu
    text = "The quick brown fox. It jumped."
    segmenter = uicu.Locale('en').get_sentence_segmenter()
    sentences = list(segmenter.segment(text))
    # sentences ->
    
    word_segmenter = uicu.Locale('en').get_word_segmenter()
    words = [word for word in word_segmenter.segment(text) if word.strip()]
    # words ->
    

### 2.7 The `uicu.translit` Module: Simplified Transliteration

This module provides a clean, functional interface for ICU's transliteration
capabilities.

  *  **`transliterate(text: str, transform_id: str) -> str`**

    * A high-level convenience function for one-off transformations. It creates, uses, and discards a `Transliterator` object internally.

    * `transform_id` is a string like `'Greek-Latin'` or `'Any-Hex'`. A list of available IDs can be retrieved via another function, `get_available_ids()`.

    * Raises `uicu.TransliterationError` if the `transform_id` is invalid.

  *  **`get_transliterator(transform_id: str, reverse: bool = False) -> Callable[[str], str]`**

    * A factory function for performance-sensitive applications where the same transformation is applied many times.

    * It pre-compiles the transliteration rule set by calling `icu.Transliterator.createInstance` and returns a simple, highly-optimized callable object (e.g., a function or a callable class instance).

    * This separates the expensive setup cost from the repeated application cost.

 _Example Usage:_

Python

    
        import uicu
    
    # Simple, one-off usage
    latin = uicu.translit.transliterate('Ψάπφω', 'Greek-Latin')
    # latin -> 'Psápphō'
    
    # Performant, repeated usage
    greek_to_latin = uicu.translit.get_transliterator('Greek-Latin')
    names = ['Σωκράτης', 'Πλάτων', 'Ἀριστοτέλης']
    latin_names = [greek_to_latin(name) for name in names]
    

## Part 3: Implementation and Documentation Roadmap

A successful library is more than just its code; it is the sum of its
implementation quality, documentation, and testing infrastructure. This
section provides a roadmap for building `uicu` into a robust, maintainable,
and user-friendly package.

### 3.1 Project Scaffolding and Dependencies

The project will be structured according to modern Python packaging best
practices to ensure compatibility with standard development and deployment
tools.

  *  **Directory Structure:**
    
        uicu/
    ├── docs/              # Sphinx documentation source
    ├── src/
    │   └── uicu/          # Main package source code
    │       ├── __init__.py
    │       ├── char.py
    │       ├── collate.py
    │       ├── locale.py
    │       ├── segment.py
    │       ├── translit.py
    │       └── format/
    │           ├── __init__.py
    │           └──...
    ├── tests/             # Pytest test suite
    ├── LICENSE
    ├── pyproject.toml     # Project metadata and build configuration
    └── README.md
    

  * **`pyproject.toml` Configuration:** This file is the single source of truth for project metadata and build dependencies. A minimal configuration would be:

Ini, TOML

    
        [project]
    name = "uicu"
    version = "0.1.0"
    description = "A pythonic, high-level wrapper for PyICU."
    readme = "README.md"
    requires-python = ">=3.8"
    license = { text = "MIT" }
    authors = [
        { name = "Your Name", email = "your@email.com" }
    ]
    classifiers =
    dependencies = [
        "pyicu >= 2.10",
        "fonttools[unicode] >= 4.40.0"
    ]
    
    [project.urls]
    Homepage = "https://github.com/user/uicu"
    Documentation = "https://uicu.readthedocs.io"
    Repository = "https://github.com/user/uicu"
    
    [build-system]
    requires = ["hatchling"]
    build-backend = "hatchling.build"
    

The critical line is `fonttools[unicode] >= 4.40.0`. The `[unicode]` extra
ensures that the `unicodedata2` dependency is installed, providing the up-to-
date Unicode data that is central to the library's design.

### 3.2 A Culture of Documentation and Testing

For a wrapper library like `uicu`, where the primary value proposition is an
improved developer experience, documentation is not an afterthought—it is a
core feature. The opaque and C++-centric nature of `PyICU`'s documentation is
a major usability obstacle. `uicu` must provide a comprehensive, python-first
documentation experience.

  *  **API Documentation:** Every public class, method, and function must have a comprehensive docstring following a standard format like Google Style or reST. This enables tools like Sphinx to automatically generate a professional API reference. Each docstring must include:

    * A one-line summary.

    * A more detailed explanation of its behavior.

    * Descriptions for all arguments (`Args:`).

    * A description of the return value (`Returns:`).

    * Any exceptions that may be raised (`Raises:`).

    * A simple, runnable code example (`Example:`).

  *  **User-Facing Documentation (to be built with Sphinx):** The documentation should be structured into four distinct categories, following the Diátaxis framework:

    1.  **Tutorials / Quickstart:** A "Getting Started" guide that begins with a consolidated, best-practice guide for installing `PyICU` and its dependencies, drawing from the scattered advice found online. It will then walk the user through a compelling, end-to-end example, such as sorting a list of Swedish names and formatting a date for a German locale.

    2.  **How-To Guides:** Topic-specific, goal-oriented recipes. The most important of these will be a guide titled **"From`PyICU` to `uicu`"**. This document will explicitly show "before" (`PyICU`) and "after" (`uicu`) code for common tasks, directly addressing the anti-patterns identified in Part 1. This provides a clear migration path and immediately demonstrates the library's value to existing `PyICU` users.

    3.  **Explanation / Discussion:** Conceptual articles that explain the "why" behind `uicu`'s design. This will include a page on the "Data Authority Principle," explaining the hybrid use of `PyICU` and `fontTools.unicodedata` and the rationale for it.

    4.  **API Reference:** The complete, auto-generated reference from the code's docstrings.

  *  **Testing Strategy (to be implemented with Pytest):** A rigorous test suite is non-negotiable for ensuring the correctness and stability of the wrapper.

    *  **Unit Tests:** Each module in `uicu` should have corresponding unit tests that mock the underlying `PyICU` and `fontTools` calls. These tests will verify that the wrapper logic (e.g., argument handling, type conversion, method delegation) is correct in isolation.

    *  **Integration Tests:** A suite of tests that use the real `PyICU` and `fontTools` libraries to verify end-to-end functionality. These tests should cover a representative set of locales (e.g., a LTR language like German, a RTL language like Arabic, a CJK language like Japanese) and use cases to ensure the abstractions behave as expected.

    *  **Exception Tests:** Tests must be written to confirm that the correct `uicu` exceptions are raised under specific failure conditions (e.g., passing an invalid locale to `uicu.Locale` should raise `uicu.ConfigurationError`).

    *  **Test Coverage:** The project should aim for high test coverage (e.g., >95%) and use tools to track it, ensuring that all logic paths are exercised.

Sources used in the report

[![](https://t3.gstatic.com/faviconV2?url=https://fonttools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)fonttools.readthedocs.iounicodedata:
Interface to character and script data in Unicode and ... Opens in a new
window
](https://fonttools.readthedocs.io/en/latest/unicodedata/index.html)[![](https://t0.gstatic.com/faviconV2?url=https://unicode-
org.github.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)unicode-
org.github.ioICU 77.1: Main Page Opens in a new window ](https://unicode-
org.github.io/icu-
docs/apidoc/dev/icu4c/)[![](https://t1.gstatic.com/faviconV2?url=https://gitee.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitee.comopenKylin/pyicu
- Gitee Opens in a new window ](https://gitee.com/openkylin/pyicu)

Sources read but not used in the report

[![](https://t3.gstatic.com/faviconV2?url=https://www.bedrick.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)bedrick.orgPython's
ICU Bindings - Steven Bedrick Opens in a new window
](https://www.bedrick.org/notes/python-icu-
bindings/)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.comREADME.md
- ovalhub/pyicu - GitHub Opens in a new window
](https://github.com/ovalhub/pyicu/blob/master/README.md)[![](https://t0.gstatic.com/faviconV2?url=https://gitlab.pyicu.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitlab.pyicu.orgsamples
· main · main / pyicu · GitLab Opens in a new window
](https://gitlab.pyicu.org/main/pyicu/-/tree/main/samples)[![](https://t3.gstatic.com/faviconV2?url=https://www.freshports.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)freshports.orgFreshPorts
-- devel/py-pyicu: Python extension wrapping the ICU C++ API Opens in a new
window ](https://www.freshports.org/devel/py-
pyicu/)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.compyicu/CHANGES
at master - GitHub Opens in a new window
](https://github.com/ovalhub/pyicu/blob/master/CHANGES)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comHow
to correctly install PyICU on Heroku? - Stack Overflow Opens in a new window
](https://stackoverflow.com/questions/67646388/how-to-correctly-install-pyicu-
on-
heroku)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comInstall
Pyicu in python 3.x - Stack Overflow Opens in a new window
](https://stackoverflow.com/questions/46871401/install-pyicu-in-
python-3-x)[![](https://t1.gstatic.com/faviconV2?url=https://llego.dev/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)llego.devAPI
Design and Testing in Python Technical Interviews - llego.dev Opens in a new
window ](https://llego.dev/posts/api-design-testing-python-technical-
interviews/)[![](https://t0.gstatic.com/faviconV2?url=https://dev.to/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)dev.toA
Pythonic Guide to SOLID Design Principles - DEV Community Opens in a new
window ](https://dev.to/ezzy1337/a-pythonic-guide-to-solid-design-
principles-4c8i)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgpyicu
- PyPI Opens in a new window
](https://pypi.org/project/pyicu/)[![](https://t2.gstatic.com/faviconV2?url=https://roguelynn.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)roguelynn.comDesign
of Everyday APIs · roguelynn - Lynn Root Opens in a new window
](https://roguelynn.com/words/everyday-
apis/)[![](https://t2.gstatic.com/faviconV2?url=https://www.pypistats.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypistats.orgpyicu
- PyPI Download Stats Opens in a new window
](https://www.pypistats.org/packages/pyicu)[![](https://t3.gstatic.com/faviconV2?url=https://realpython.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)realpython.comReal
Python: Python Tutorials Opens in a new window
](https://realpython.com/)[![](https://t0.gstatic.com/faviconV2?url=https://gitlab.pyicu.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitlab.pyicu.orgcommon.cpp
- main / pyicu · GitLab Opens in a new window
](https://gitlab.pyicu.org/main/pyicu/-/blob/main/common.cpp?ref_type=heads)[![](https://t3.gstatic.com/faviconV2?url=https://anaconda.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)anaconda.orgPyicu
- Anaconda.org Opens in a new window ](https://anaconda.org/conda-
forge/pyicu)[![](https://t1.gstatic.com/faviconV2?url=https://www.piwheels.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)piwheels.orgPyICU-
binary - piwheels Opens in a new window
](https://www.piwheels.org/project/pyicu-
binary/)[![](https://t0.gstatic.com/faviconV2?url=https://gist.github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gist.github.comInstallation
instructions for libicu-dev, PyICU, libpostal, pypostal on Mac OS X - GitHub
Gist Opens in a new window
](https://gist.github.com/ddelange/6e04e81b99fae08e817a00515d4a378d)[![](https://t3.gstatic.com/faviconV2?url=https://realpython.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)realpython.comPython
and REST APIs: Interacting With Web Services Opens in a new window
](https://realpython.com/api-integration-in-
python/)[![](https://t3.gstatic.com/faviconV2?url=https://hajloo.wordpress.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)hajloo.wordpress.comHow
to Use FontTools Module in Python | Hadjloo's Daily Notes - WordPress.com
Opens in a new window ](https://hajloo.wordpress.com/2011/07/15/how-to-use-
fonttools-module-in-
python/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comPip
can't install pyicu - Stack Overflow Opens in a new window
](https://stackoverflow.com/questions/68349833/pip-cant-install-
pyicu)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.comarrowtype/fonttools-
intro: An introduction to FontTools & font development - GitHub Opens in a new
window ](https://github.com/arrowtype/fonttools-
intro)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.comfonttools/fonttools:
A library to manipulate font files from Python. - GitHub Opens in a new window
](https://github.com/fonttools/fonttools)[![](https://t0.gstatic.com/faviconV2?url=https://docs.unity3d.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.unity3d.comOptimize
font files with font subsetting - Unity - Manual Opens in a new window
](https://docs.unity3d.com/6000.2/Documentation/Manual/UIE-font-
subsetting.html)[![](https://t2.gstatic.com/faviconV2?url=https://markoskon.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)markoskon.comCreating
font subsets - Dev Diary Opens in a new window
](https://markoskon.com/creating-font-
subsets/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comHow
to use fontTools to detect Type 1 and OpenType CFF fonts - Stack Overflow
Opens in a new window ](https://stackoverflow.com/questions/55966692/how-to-
use-fonttools-to-detect-type-1-and-opentype-cff-
fonts)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgfonttools
- PyPI Opens in a new window
](https://pypi.org/project/fonttools/4.51.0/)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgfonttools
- PyPI Opens in a new window
](https://pypi.org/project/fonttools/)[![](https://t3.gstatic.com/faviconV2?url=https://fonttools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)fonttools.readthedocs.io—fontTools
Documentation— — fontTools Documentation Opens in a new window
](https://fonttools.readthedocs.io/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comHow
to use pyftsubset of Fonttools inside of the python environment, not from the
command line - Stack Overflow Opens in a new window
](https://stackoverflow.com/questions/55009981/how-to-use-pyftsubset-of-
fonttools-inside-of-the-python-environment-not-from-
th)[![](https://t0.gstatic.com/faviconV2?url=https://gist.github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gist.github.comPyICU
cheat sheet · GitHub Opens in a new window
](https://gist.github.com/dpk/8325992)[![](https://t0.gstatic.com/faviconV2?url=https://retailtechinnovationhub.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)retailtechinnovationhub.comThe
ultimate guide to structuring a Python package - Retail Technology Innovation
Hub Opens in a new window
](https://retailtechinnovationhub.com/home/2024/2/29/the-ultimate-guide-to-
structuring-a-python-
package)[![](https://t0.gstatic.com/faviconV2?url=https://help.autodesk.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)help.autodesk.comPython
API Best Practices - Autodesk Help Opens in a new window
](https://help.autodesk.com/view/SGDEV/ENU/?guid=SGD_py_python_api_best_practices_html)[![](https://t1.gstatic.com/faviconV2?url=https://nsls-
ii.github.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)nsls-
ii.github.ioGuiding Design Principles — Scientific Python Cookiecutter 0.1
documentation Opens in a new window ](https://nsls-ii.github.io/scientific-
python-cookiecutter/guiding-design-
principles.html)[![](https://t3.gstatic.com/faviconV2?url=https://docs.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.python.orgunicodedata
— Unicode Database — Python 3.13.5 documentation Opens in a new window
](https://docs.python.org/3/library/unicodedata.html)[![](https://t0.gstatic.com/faviconV2?url=https://dev.to/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)dev.toMastering
REST API Best Practices in Python - DEV Community Opens in a new window
](https://dev.to/biswajitfsd/mastering-rest-api-best-practices-in-
python-5bda)[![](https://t0.gstatic.com/faviconV2?url=https://www.stuartellis.name/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stuartellis.nameModern
Good Practices for Python Development - Stuart Ellis Opens in a new window
](https://www.stuartellis.name/articles/python-modern-
practices/)[![](https://t3.gstatic.com/faviconV2?url=https://www.freshports.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)freshports.orgFreshPorts
-- devel/py-unicodedata2: Unicodedata backport updated to the latest Unicode
version Opens in a new window ](https://www.freshports.org/devel/py-
unicodedata2)[![](https://t2.gstatic.com/faviconV2?url=https://stackoverflow.blog/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.blogBest
practices for REST API design - The Stack Overflow Blog Opens in a new window
](https://stackoverflow.blog/2020/03/02/best-practices-for-rest-api-
design/)[![](https://t2.gstatic.com/faviconV2?url=https://docs.python-
guide.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.python-
guide.orgStructuring Your Project - The Hitchhiker's Guide to Python Opens in
a new window ](https://docs.python-
guide.org/writing/structure/)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgunicodedata2
- PyPI Opens in a new window
](https://pypi.org/project/unicodedata2/)[![](https://t3.gstatic.com/faviconV2?url=https://peps.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)peps.python.orgPEP
8 – Style Guide for Python Code | peps.python.org Opens in a new window
](https://peps.python.org/pep-0008/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.compython:
how to add 'unicodedata' module to my current python lib - Stack Overflow
Opens in a new window ](https://stackoverflow.com/questions/26583944/python-
how-to-add-unicodedata-module-to-my-current-python-
lib)[![](https://t3.gstatic.com/faviconV2?url=https://salishsea-meopar-
tools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)salishsea-
meopar-tools.readthedocs.ioGuidelines and Best Practices for Writing Library
Code Opens in a new window ](https://salishsea-meopar-
tools.readthedocs.io/en/latest/python_packaging/library_code.html)[![](https://t1.gstatic.com/faviconV2?url=https://prefix.dev/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)prefix.devunicodedata2
- conda-forge - prefix.dev Opens in a new window
](https://prefix.dev/channels/conda-
forge/packages/unicodedata2)[![](https://t2.gstatic.com/faviconV2?url=https://benhoyt.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)benhoyt.comDesigning
Pythonic library APIs - Ben Hoyt Opens in a new window
](https://benhoyt.com/writings/python-api-
design/)[![](https://t3.gstatic.com/faviconV2?url=https://anaconda.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)anaconda.orgConda
- Anaconda.org Opens in a new window ](https://anaconda.org/conda-
forge/unicodedata2/)[![](https://t2.gstatic.com/faviconV2?url=https://packaging.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)packaging.python.orgPackaging
Python Projects Opens in a new window
](https://packaging.python.org/tutorials/packaging-projects/)

Thoughts

Understanding the Goal

I'm starting a new research task to design a Python library called `uicu`.
This library will serve as a more intuitive and Pythonic wrapper around
`PyICU`, with additional capabilities from `fontTools.unicodedata`. My main
goal is to create a detailed specification for this new library, making it
easy for a junior developer to implement.

Initial Research Approach

My first step is to thoroughly understand the existing APIs of both `PyICU`
and `fontTools.unicodedata`. I'll be looking into their modules, classes, and
methods, paying close attention to areas where `PyICU` might be powerful but
less Pythonic. I'll also investigate how `fontTools.unicodedata` handles
script and property information, and how it compares to Python's standard
`unicodedata` module.

Next Steps in Planning

After understanding the existing libraries, I'll compare their features to
identify overlaps and unique functionalities, which will guide decisions on
how to integrate them into `uicu`. I'll also research best practices for
Python API design to ensure `uicu` is truly Pythonic. Finally, I'll outline
the modular structure, define core objects, and plan for seamless integration
with Python's built-in string types, performance considerations,
documentation, and error handling. I'm beginning by gathering all relevant
documentation for both libraries.

![](https://www.gstatic.com/lamda/images/immersives/google_logo_icon_2380fba942c84387f09cf.svg)

Researching websites

[![](https://t3.gstatic.com/faviconV2?url=https://www.bedrick.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)bedrick.orgPython's
ICU Bindings - Steven Bedrick](https://www.bedrick.org/notes/python-icu-
bindings/)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.comREADME.md
- ovalhub/pyicu -
GitHub](https://github.com/ovalhub/pyicu/blob/master/README.md)[![](https://t0.gstatic.com/faviconV2?url=https://unicode-
org.github.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)unicode-
org.github.ioICU 77.1: Main Page](https://unicode-org.github.io/icu-
docs/apidoc/dev/icu4c/)[![](https://t0.gstatic.com/faviconV2?url=https://gitlab.pyicu.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitlab.pyicu.orgsamples
· main · main / pyicu ·
GitLab](https://gitlab.pyicu.org/main/pyicu/-/tree/main/samples)[![](https://t3.gstatic.com/faviconV2?url=https://www.freshports.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)freshports.orgFreshPorts
-- devel/py-pyicu: Python extension wrapping the ICU C++
API](https://www.freshports.org/devel/py-
pyicu/)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.compyicu/CHANGES
at master -
GitHub](https://github.com/ovalhub/pyicu/blob/master/CHANGES)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comHow
to correctly install PyICU on Heroku? - Stack
Overflow](https://stackoverflow.com/questions/67646388/how-to-correctly-
install-pyicu-on-
heroku)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comInstall
Pyicu in python 3.x - Stack
Overflow](https://stackoverflow.com/questions/46871401/install-pyicu-in-
python-3-x)[![](https://t0.gstatic.com/faviconV2?url=https://gist.github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gist.github.comPyICU
cheat sheet - Gist -
GitHub](https://gist.github.com/dpk/8325992)[![](https://t1.gstatic.com/faviconV2?url=https://llego.dev/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)llego.devAPI
Design and Testing in Python Technical Interviews -
llego.dev](https://llego.dev/posts/api-design-testing-python-technical-
interviews/)[![](https://t1.gstatic.com/faviconV2?url=https://gitee.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitee.comopenKylin/pyicu
-
Gitee](https://gitee.com/openkylin/pyicu)[![](https://t0.gstatic.com/faviconV2?url=https://dev.to/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)dev.toA
Pythonic Guide to SOLID Design Principles - DEV
Community](https://dev.to/ezzy1337/a-pythonic-guide-to-solid-design-
principles-4c8i)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgpyicu
-
PyPI](https://pypi.org/project/pyicu/)[![](https://t2.gstatic.com/faviconV2?url=https://roguelynn.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)roguelynn.comDesign
of Everyday APIs · roguelynn - Lynn
Root](https://roguelynn.com/words/everyday-
apis/)[![](https://t2.gstatic.com/faviconV2?url=https://www.pypistats.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypistats.orgpyicu
- PyPI Download
Stats](https://www.pypistats.org/packages/pyicu)[![](https://t3.gstatic.com/faviconV2?url=https://realpython.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)realpython.comReal
Python: Python
Tutorials](https://realpython.com/)[![](https://t0.gstatic.com/faviconV2?url=https://gitlab.pyicu.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitlab.pyicu.orgcommon.cpp
- main / pyicu ·
GitLab](https://gitlab.pyicu.org/main/pyicu/-/blob/main/common.cpp?ref_type=heads)[![](https://t3.gstatic.com/faviconV2?url=https://anaconda.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)anaconda.orgPyicu
- Anaconda.org](https://anaconda.org/conda-
forge/pyicu)[![](https://t1.gstatic.com/faviconV2?url=https://www.piwheels.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)piwheels.orgPyICU-
binary - piwheels](https://www.piwheels.org/project/pyicu-
binary/)[![](https://t0.gstatic.com/faviconV2?url=https://gist.github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gist.github.comInstallation
instructions for libicu-dev, PyICU, libpostal, pypostal on Mac OS X - GitHub
Gist](https://gist.github.com/ddelange/6e04e81b99fae08e817a00515d4a378d)[![](https://t3.gstatic.com/faviconV2?url=https://realpython.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)realpython.comPython
and REST APIs: Interacting With Web Services](https://realpython.com/api-
integration-in-
python/)[![](https://t0.gstatic.com/faviconV2?url=https://dev.to/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)dev.toMastering
REST API Best Practices in Python - DEV
Community](https://dev.to/biswajitfsd/mastering-rest-api-best-practices-in-
python-5bda)[![](https://t2.gstatic.com/faviconV2?url=https://benhoyt.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)benhoyt.comDesigning
Pythonic library APIs - Ben Hoyt](https://benhoyt.com/writings/python-api-
design/)[![](https://t3.gstatic.com/faviconV2?url=https://hajloo.wordpress.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)hajloo.wordpress.comHow
to Use FontTools Module in Python | Hadjloo's Daily Notes -
WordPress.com](https://hajloo.wordpress.com/2011/07/15/how-to-use-fonttools-
module-in-
python/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comPip
can't install pyicu - Stack
Overflow](https://stackoverflow.com/questions/68349833/pip-cant-install-
pyicu)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.comarrowtype/fonttools-
intro: An introduction to FontTools & font development -
GitHub](https://github.com/arrowtype/fonttools-
intro)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.comfonttools/fonttools:
A library to manipulate font files from Python. -
GitHub](https://github.com/fonttools/fonttools)[![](https://t0.gstatic.com/faviconV2?url=https://docs.unity3d.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.unity3d.comOptimize
font files with font subsetting - Unity -
Manual](https://docs.unity3d.com/6000.2/Documentation/Manual/UIE-font-
subsetting.html)[![](https://t2.gstatic.com/faviconV2?url=https://markoskon.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)markoskon.comCreating
font subsets - Dev Diary](https://markoskon.com/creating-font-
subsets/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comHow
to use fontTools to detect Type 1 and OpenType CFF fonts - Stack
Overflow](https://stackoverflow.com/questions/55966692/how-to-use-fonttools-
to-detect-type-1-and-opentype-cff-
fonts)[![](https://t3.gstatic.com/faviconV2?url=https://docs.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.python.orgunicodedata
— Unicode Database — Python 3.13.5
documentation](https://docs.python.org/3/library/unicodedata.html)[![](https://t3.gstatic.com/faviconV2?url=https://fonttools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)fonttools.readthedocs.iounicodedata:
Interface to character and script data in Unicode and
OpenType](https://fonttools.readthedocs.io/en/latest/unicodedata/index.html)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgfonttools
-
PyPI](https://pypi.org/project/fonttools/4.51.0/)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgfonttools
-
PyPI](https://pypi.org/project/fonttools/)[![](https://t3.gstatic.com/faviconV2?url=https://fonttools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)fonttools.readthedocs.io—fontTools
Documentation— — fontTools
Documentation](https://fonttools.readthedocs.io/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comHow
to use pyftsubset of Fonttools inside of the python environment, not from the
command line - Stack
Overflow](https://stackoverflow.com/questions/55009981/how-to-use-pyftsubset-
of-fonttools-inside-of-the-python-environment-not-from-th)

Initial API Exploration

I've started by gathering information on PyICU and fontTools.unicodedata. For
PyICU, I've found a cheat sheet and official documentation that provide
insights into its core functionalities like transliteration, locale handling,
collation, date formatting, and break iteration. A key observation is that
PyICU often requires explicit `UnicodeString` objects and in-place
modifications, which is less Pythonic than working with native Python strings.
However, it also offers 'Pythonic' ways for some operations, like
`locale.getDisplayName()` returning a Python `str` directly. For
`fontTools.unicodedata`, the documentation highlights its role in accessing
Unicode character properties, script data, and OpenType script tags,
complementing the standard `unicodedata` module with more up-to-date and
specialized data.

Addressing Pythonic Design

I'm also looking into general principles for designing Pythonic APIs. Key
themes emerging include prioritizing intuitive and consistent naming, keeping
APIs simple and minimal, minimizing interdependencies between components
(loose coupling), and supporting versioning. The importance of clear
documentation, comprehensive testing (unit, integration, usability, load), and
effective error handling is also being emphasized. I'm noting examples of both
good and less ideal API designs within the Python standard library to inform
the `uicu` design.

Next Steps in Research

My next step is to delve deeper into the specifics of PyICU and
`fontTools.unicodedata` by browsing the identified key documentation. I'll
focus on understanding the nuances of their APIs, particularly the areas where
PyICU deviates from Pythonic conventions, to inform how `uicu` can bridge
these gaps. I'll also continue to synthesize information on Pythonic API
design to ensure the `uicu` library is both extensive and natural to use.

![](https://www.gstatic.com/lamda/images/immersives/google_logo_icon_2380fba942c84387f09cf.svg)

Researching websites

[![](https://t0.gstatic.com/faviconV2?url=https://gist.github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gist.github.comPyICU
cheat sheet ·
GitHub](https://gist.github.com/dpk/8325992)[![](https://t3.gstatic.com/faviconV2?url=https://fonttools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)fonttools.readthedocs.iounicodedata:
Interface to character and script data in Unicode and
...](https://fonttools.readthedocs.io/en/latest/unicodedata/index.html)[![](https://t0.gstatic.com/faviconV2?url=https://unicode-
org.github.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)unicode-
org.github.ioICU 77.1: Main Page](https://unicode-org.github.io/icu-
docs/apidoc/dev/icu4c/)[![](https://t1.gstatic.com/faviconV2?url=https://gitee.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitee.comopenKylin/pyicu
- Gitee](https://gitee.com/openkylin/pyicu)

Deepening API Understanding

I've gained a clearer understanding of PyICU's API, confirming its direct
mapping to the ICU4C C++ library. This means it often uses mutable
`UnicodeString` objects and in-place modifications, which are less aligned
with Python's immutable string philosophy. I've also identified its reliance
on factory methods and verbose naming conventions. In contrast,
`fontTools.unicodedata` provides specialized Unicode character properties,
script, and OpenType-related information, building upon an updated Unicode
database, which complements Python's built-in `unicodedata` module.

Identifying Design Challenges

A significant challenge for `uicu` will be to abstract away PyICU's non-
Pythonic elements while retaining its powerful functionality. This involves
designing an API that feels natural to Python developers, potentially by
converting mutable `UnicodeString` objects to Python's native immutable
strings where appropriate, and by adopting more idiomatic Python patterns for
object creation and method calls. I'm also considering how to best integrate
the unique capabilities of `fontTools.unicodedata` to provide a comprehensive
and user-friendly experience.

Charting the Path Forward

My immediate next steps involve a detailed feature comparison between PyICU
and `fontTools.unicodedata` to pinpoint overlaps and unique strengths.
Concurrently, I'll synthesize the gathered Pythonic API design principles into
concrete goals for `uicu`. This will then lead to outlining the `uicu` package
structure, defining its core objects, and considering how to manage
performance and integrate seamlessly with Python's native types. I'll also
plan for robust documentation and a custom exception hierarchy.

![](https://www.gstatic.com/lamda/images/immersives/google_logo_icon_2380fba942c84387f09cf.svg)

Researching websites

[![](https://t0.gstatic.com/faviconV2?url=https://retailtechinnovationhub.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)retailtechinnovationhub.comThe
ultimate guide to structuring a Python package - Retail Technology Innovation
Hub](https://retailtechinnovationhub.com/home/2024/2/29/the-ultimate-guide-to-
structuring-a-python-
package)[![](https://t0.gstatic.com/faviconV2?url=https://help.autodesk.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)help.autodesk.comPython
API Best Practices - Autodesk
Help](https://help.autodesk.com/view/SGDEV/ENU/?guid=SGD_py_python_api_best_practices_html)[![](https://t1.gstatic.com/faviconV2?url=https://nsls-
ii.github.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)nsls-
ii.github.ioGuiding Design Principles — Scientific Python Cookiecutter 0.1
documentation](https://nsls-ii.github.io/scientific-python-
cookiecutter/guiding-design-
principles.html)[![](https://t3.gstatic.com/faviconV2?url=https://docs.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.python.orgunicodedata
— Unicode Database — Python 3.13.5
documentation](https://docs.python.org/3/library/unicodedata.html)[![](https://t0.gstatic.com/faviconV2?url=https://dev.to/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)dev.toMastering
REST API Best Practices in Python - DEV
Community](https://dev.to/biswajitfsd/mastering-rest-api-best-practices-in-
python-5bda)[![](https://t0.gstatic.com/faviconV2?url=https://www.stuartellis.name/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stuartellis.nameModern
Good Practices for Python Development - Stuart
Ellis](https://www.stuartellis.name/articles/python-modern-
practices/)[![](https://t3.gstatic.com/faviconV2?url=https://www.freshports.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)freshports.orgFreshPorts
-- devel/py-unicodedata2: Unicodedata backport updated to the latest Unicode
version](https://www.freshports.org/devel/py-
unicodedata2)[![](https://t2.gstatic.com/faviconV2?url=https://stackoverflow.blog/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.blogBest
practices for REST API design - The Stack Overflow
Blog](https://stackoverflow.blog/2020/03/02/best-practices-for-rest-api-
design/)[![](https://t2.gstatic.com/faviconV2?url=https://docs.python-
guide.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.python-
guide.orgStructuring Your Project - The Hitchhiker's Guide to
Python](https://docs.python-
guide.org/writing/structure/)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgunicodedata2
-
PyPI](https://pypi.org/project/unicodedata2/)[![](https://t3.gstatic.com/faviconV2?url=https://peps.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)peps.python.orgPEP
8 – Style Guide for Python Code |
peps.python.org](https://peps.python.org/pep-0008/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.compython:
how to add 'unicodedata' module to my current python lib - Stack
Overflow](https://stackoverflow.com/questions/26583944/python-how-to-add-
unicodedata-module-to-my-current-python-
lib)[![](https://t3.gstatic.com/faviconV2?url=https://salishsea-meopar-
tools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)salishsea-
meopar-tools.readthedocs.ioGuidelines and Best Practices for Writing Library
Code](https://salishsea-meopar-
tools.readthedocs.io/en/latest/python_packaging/library_code.html)[![](https://t1.gstatic.com/faviconV2?url=https://prefix.dev/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)prefix.devunicodedata2
- conda-forge - prefix.dev](https://prefix.dev/channels/conda-
forge/packages/unicodedata2)[![](https://t2.gstatic.com/faviconV2?url=https://benhoyt.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)benhoyt.comDesigning
Pythonic library APIs - Ben Hoyt](https://benhoyt.com/writings/python-api-
design/)[![](https://t3.gstatic.com/faviconV2?url=https://anaconda.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)anaconda.orgConda
- Anaconda.org](https://anaconda.org/conda-
forge/unicodedata2/)[![](https://t2.gstatic.com/faviconV2?url=https://packaging.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)packaging.python.orgPackaging
Python Projects](https://packaging.python.org/tutorials/packaging-projects/)

Synthesizing Research Findings

I have completed my research into PyICU and `fontTools.unicodedata`, and have
a solid understanding of their APIs, strengths, and areas where a more
Pythonic approach is needed. I've also thoroughly explored Pythonic API design
principles, which will be crucial in shaping the `uicu` library. I'm now ready
to synthesize all this information into a detailed specification.

Preparing the `uicu` Specification

My next action is to generate a comprehensive report that will serve as the
detailed specification for the `uicu` package. This report will guide a junior
developer in implementing the library, ensuring it is extensive, natural, and
performant, while seamlessly integrating with Python's native Unicode
capabilities and exposing rich additional functionality.
</file>

<file path="research/res-gpt.md">
Thanks! I’ll begin by researching and documenting the APIs provided by PyICU and fontTools.unicodedata, especially around Unicode properties, transformations, and writing systems. I’ll also provide a detailed design specification for the new `uicu` package—focusing on a Pythonic, well-structured, and modular API that integrates both libraries’ capabilities and supports grapheme-aware iteration, normalization, script detection, and more.

I’ll let you know once everything is ready for your review.


# Design Plan for the `uicu` Unicode Utilities Library

## Introduction and Background

Python’s built-in `unicodedata` module and ICU (International Components for Unicode) offer comprehensive Unicode support, but using them can be cumbersome or low-level. **PyICU**, the Python bindings for ICU, exposes ICU’s powerful Unicode and internationalization features but through a thin, C++-styled API that isn’t very “Pythonic”. For example, splitting text into grapheme clusters (user-perceived characters) with PyICU requires manual iteration and index tracking in a C++-like fashion. On the other hand, **fontTools.unicodedata** (built on the `unicodedata2` backport) provides up-to-date Unicode data (including script and block properties) but is mostly a set of functions mirroring Python’s `unicodedata` API.

The goal of `uicu` is to combine the strengths of both: wrapping PyICU’s advanced Unicode functionalities in a natural, Pythonic interface, while supplementing with fontTools’ Unicode data for character properties. The result will be a **richly documented, easy-to-use library** that integrates seamlessly with Python’s `str` type but offers much more power. This plan outlines the APIs and design of `uicu` in detail, serving as a guide for implementation.

## Existing APIs Summary

### fontTools.unicodedata (unicodedata2)

FontTools’ `unicodedata` module extends Python’s `unicodedata` with additional information, especially about writing systems (scripts) and blocks. It uses the latest Unicode Character Database via the `unicodedata2` package. Key capabilities include:

* **Up-to-date core properties**: functions like `name(char)`, `category(char)`, `bidirectional(char)`, `combining(char)`, numeric values, normalization, etc., equivalent to Python’s built-in `unicodedata` but updated to the latest Unicode version.
* **Script identification**: `script(char)` returns the four-letter script code for a character (e.g. `'Latn'` for `'a'` and `'Zyyy'` for a comma). `script_extension(char)` returns a **set** of script codes if a character is used in multiple scripts (e.g. U+060C ARABIC COMMA has script extensions `'Arab', 'Thaa', ...` etc.).
* **Script metadata**: `script_name(code)` and `script_code(name)` map between the 4-letter script codes and human-readable script names. Also `script_horizontal_direction(code)` reports text direction (“LTR” or “RTL”) of a given script – for example, it returns `"RTL"` for `"Hebr"` or `"Arab"` and `"LTR"` for `"Latn"`.
* **Block identification**: `block(char)` gives the Unicode block name for the character (e.g. `'Basic Latin'` for `'A'`, `'Arabic'` for an Arabic character, or `'No_Block'` if none).
* **OpenType tag mapping** (for fonts): `ot_tags_from_script(script_code)` and `ot_tag_to_script(tag)` map between Unicode script codes and OpenType script tags.

These APIs provide a **richer Unicode database interface** than the basic `unicodedata` module. We will leverage them in `uicu` to offer script and block info, ensuring our library stays current with new Unicode versions.

### PyICU (Python ICU bindings)

PyICU wraps the ICU C++ libraries, which implement much of the Unicode standard and CLDR (Common Locale Data Repository) functionality. PyICU’s scope includes:

* **Locale-aware transformations**: e.g. case conversions, collation (sorting), formatting dates/numbers, transliteration between writing systems, etc.
* **Unicode algorithms**: e.g. normalization (NFC/NFD etc.), text boundary analysis (grapheme, word, line, sentence segmentation), bidirectional text handling, and more – essentially “big guns” for Unicode processing.
* **Extensive locale data**: ICU knows about various locales’ sorting rules, date/number formats, etc., accessible via PyICU.

However, PyICU’s API closely mirrors ICU’s C++ API, making it less intuitive for Python developers. For instance, to use a break iterator for word boundaries, one must do:

```python
bi = icu.BreakIterator.createWordInstance(icu.Locale('de_DE'))
bi.setText("Ein Beispiel.")
for boundary in bi:
    # boundary is an integer index; need to slice the string manually
    ...
```

As the example suggests, iterating text by words or graphemes requires manual index handling and understanding ICU’s classes. Similarly, to transliterate text, one must instantiate a Transliterator and call its method. While powerful, this approach is not as pythonic or straightforward as it could be.

**PyICU Highlights to Wrap in `uicu`:**

* **Break Iterators**: ICU provides `BreakIterator` factories for **grapheme clusters**, words, sentences, and line breaks. PyICU exposes these via `BreakIterator.createCharacterInstance()`, `createWordInstance()`, etc. and iteration yields boundary indices. We will wrap these to directly yield substrings (e.g. actual grapheme or word strings) to the user.
* **Collation**: ICU’s `Collator` allows locale-aware string comparison and sorting. PyICU’s `Collator.createInstance(locale)` gives a collator; one can then e.g. use `collator.getSortKey(string)` for sorting. We plan to simplify sorting and comparison with an easy interface.
* **Transliteration**: ICU has a rich set of transliterators (script conversions, accent removal, etc.). PyICU exposes `Transliterator.createInstance(id, direction)` and a `.transliterate(str)` method. We will provide a more direct function and class for transliteration.
* **Case Conversion**: ICU handles locale-specific case rules (e.g. Turkish ‘i’). In PyICU, one can use `icu.UnicodeString(text).toLower(locale)` or `toUpper(locale)`. We will wrap these so users can easily do locale-aware case changes on Python strings.
* **Other ICU features**: PyICU also supports formatting (dates, numbers via `DateFormat`, `NumberFormat`), time zones, bidi processing (`Bidi` class), and UnicodeSet/Regex. In this initial plan we focus on text and Unicode-specific features, but our design will be open to adding more (e.g. we might include number/date formatting helpers later).

One important detail: **PyICU handles Python strings by converting them to ICU’s internal UTF-16 representation (UnicodeString)**. Indices returned by ICU (e.g. break positions) count **16-bit code units** – which means Python and ICU indices can differ for characters outside the Basic Multilingual Plane (BMP). For example, an emoji or certain scripts use two 16-bit units in UTF-16 but count as a single character in Python’s str indexing. This can lead to misaligned indices if not handled. Indeed, PyICU users note that when using a native Python `str` with BreakIterator, the boundaries may not align with Python slicing, whereas using ICU’s `UnicodeString` avoids that issue. We will keep this in mind to ensure `uicu` functions return correct results for all Unicode characters (likely by internally using ICU UnicodeString for segmentation tasks).

## Design Goals for `uicu`

1. **Pythonic and Intuitive**: The API should feel natural to Python developers. Common tasks (like iterating over graphemes or words, comparing strings in a locale-aware way, converting text to another script) should be one-liners or simple loops – not requiring manual index arithmetic or obscure ICU constants. We’ll favor Python idioms (iterators, context managers if appropriate, simple functions) over ICU’s class boilerplate.
2. **Leverage ICU Performance**: ICU is written in C/C++ for performance. Our wrapper will call into PyICU (C++ extension) for heavy lifting, ensuring that even though we provide a higher-level interface, it remains efficient. We must be mindful of conversion overhead between Python and ICU (e.g., minimize repeated conversions of large strings).
3. **Comprehensive Unicode Support**: Cover the key features needed for robust Unicode text processing:

   * Character metadata (names, categories, scripts, blocks, numeric values, bidi classes, etc.)
   * Normalization (NFC, NFD, etc. as well as case-folding)
   * Grapheme cluster, word, sentence, and line segmentation
   * Locale-aware case transformations (upper, lower, title)
   * Transliteration between writing systems or transliteration rules
   * Locale-aware collation (comparison and sorting)
   * (Future/optional) Bi-directional text support, regex with Unicode properties, etc.
4. **Integration with Python Types**: Users of `uicu` should primarily work with Python’s built-in types (`str`, possibly `list` for results, etc.) and high-level objects. Internally we may use ICU’s `UnicodeString` or PyICU classes, but the user interface will abstract those away. For example, a user can pass a plain `str` or a locale code as a simple string `"en_US"`, rather than needing to import and use `icu.Locale` explicitly. Return values should be Python strings or collections thereof (except for specialized objects like a Collator instance).
5. **Clean Architecture**: Organize the package into a maintainable structure. Even if initially implemented in a single module `uicu.py`, the code should be modular and logically grouped (we may later split into submodules like `uicu.collation`, `uicu.segmentation`, etc.). We must adhere to the provided project structure, ensuring we have a proper `pyproject.toml`, tests, and documentation files. All public classes/functions need clear docstrings with examples.
6. **Compatibility**: `uicu` will target CPython (since PyICU itself is a CPython extension) and should also work on PyPy (PyICU supports PyPy as well). We will ensure our code doesn’t use any CPython-only API unnecessarily, and rely on PyICU for ICU access.

## Proposed API and Features

Below we detail the key components of `uicu` and how a developer should implement them. We will design `uicu` as a multifile package (if needed) within `src/uicu/`. For clarity, we describe them in categories:

### 1. Unicode Character Properties and Database

**Objective**: Provide easy access to Unicode character information, combining Python’s and ICU’s data.

* **Basic properties**: Functions mirroring `unicodedata` should be provided (or re-exported) for convenience:

  * `uicu.name(char)` – Unicode name of the character, e.g. `"LATIN CAPITAL LETTER A"`. Use `unicodedata.name()` from `unicodedata2` (for up-to-date data) or built-in as fallback.
  * `uicu.category(char)` – General category (e.g. `"Lu"` for uppercase letter).
  * `uicu.bidirectional(char)` – Bidi class (e.g. `"L"` for left-to-right letters).
  * `uicu.combining(char)` – Canonical combining class (integer).
  * `uicu.decimal(char)`, `uicu.digit(char)`, `uicu.numeric(char)` – Numeric values if applicable.
  * `uicu.mirrored(char)` – Whether character is mirrored in bidirectional text.
  * `uicu.east_asian_width(char)` – East Asian width property.
  * `uicu.decomposition(char)` – Decomposition mapping.
    These can directly call `fontTools.unicodedata` (which transparently uses `unicodedata2` or built-in). For example, `uicu.category(c)` can do `return ftunicodedata.category(c)`. The developer should import `fontTools.unicodedata` as, say, `ftunicodedata` at the top of `uicu.py`. (If fontTools/unicodedata2 is not installed, we will document that `uicu` requires it as a dependency – perhaps we list it in `pyproject.toml` extras or include `unicodedata2` as part of installation).

* **Script and block properties**: These are not in Python’s built-in unicodedata, so we expose them via fontTools:

  * `uicu.script(char)` – returns the 4-letter script code of the char (or `"Zzzz"` if unknown).
  * `uicu.script_name(code)` – full English name of a script given its 4-letter code. E.g. `"Latn" -> "Latin"`.
  * `uicu.script_code(name)` – inverse of the above, get script code from name (case-insensitive, ignores spaces/hyphens).
  * `uicu.script_extensions(char)` – returns a **set** of script codes if the char has Script Extensions property. (For chars with a single script, it can return a set with one element, e.g. `{'Latn'}`.)
  * `uicu.block(char)` – Unicode block name as a string (e.g. `'Basic Latin'`).
  * `uicu.block_code(char)` – (Optional) We might define a short code or range for blocks if needed, though just the name is usually enough.
  * **Directionality**: `uicu.script_direction(code)` – returns `"LTR"` or `"RTL"` for a given script code using fontTools’ logic. This can help, for example, to quickly check if text of that script should be rendered right-to-left.

  Implementation: all the above can call corresponding functions in `fontTools.unicodedata`. For example, `uicu.script = ftunicodedata.script`, `uicu.block = ftunicodedata.block`, etc., or use them internally. We should wrap them to handle any necessary type normalization (ensure input `char` is a single-character string or an int codepoint). If a user passes an integer (Unicode code point), we can convert it to `chr(code)` internally to use these functions. This adds pythonic flexibility.

* **Encapsulated Character Object** (optional but encouraged for richness): We can introduce a class `uicu.Char` (or `UnicodeChar`) that represents a single Unicode character and exposes all these properties as attributes. For example:

  ```python
  ch = uicu.Char('您')
  ch.char         # '您'
  ch.name         # 'CJK UNIFIED IDEOGRAPH-60A8'
  ch.category     # 'Lo'
  ch.script       # 'Hani'
  ch.block        # 'CJK Unified Ideographs'
  ch.numeric      # None (not a numeric character)
  ch.bidirectional # 'L'
  ```

  This `Char` class’s `__init__` would take either a one-length string or an integer code point. It can then store the character and lazily compute properties via the above functions (or compute once in constructor). This provides an OO way to bundle character info. It’s not strictly necessary for functionality, but it satisfies the goal of “rich objects” that integrate with Python’s Unicode: the `Char` object could implement `__str__` to return the character, so it prints as the character itself, and maybe `__repr__` to show e.g. `<Char '您' (U+60A8): Name='CJK ...'>`. This can help developers inspect characters easily.

  The junior developer should be guided to implement this class after the functions are in place. Ensure to document each attribute in the class docstring. Also, make it iterable or indexable? Probably not needed (it’s a single char). Comparison between `Char` objects could compare the underlying char. But primarily it's a container for properties.

* **Unicode Version**: We can expose `uicu.unicode_version` indicating the Unicode version of the data (from `unicodedata.unidata_version` which `unicodedata2` provides up-to-date). For completeness, also `uicu.icu_version` via PyICU (perhaps from `icu.ICU_VERSION` if available). These are informational.

**Documentation and Testing**: Document each function with the meaning of returned values (for example, list possible category codes or mention script codes are per ISO 15924). In tests, we should verify a few known values (e.g. `script('A') == 'Latn':contentReference[oaicite:42]{index=42}, script('你') == 'Hani'`, `block('A') == 'Basic Latin':contentReference[oaicite:43]{index=43}`, script\_extensions on a known char, etc.).

### 2. Unicode Normalization and Case Handling

**Normalization**: ICU and Python both support NFC, NFD, NFKC, NFKD normalization. We can simply wrap Python’s `unicodedata.normalize(form, text)` (again from `unicodedata2` for latest data). Provide an easy API:

* `uicu.normalize(text, form='NFC')` – returns the normalized string (form can be "NFC","NFD","NFKC","NFKD"). We can default to NFC as that’s common. This is basically a direct call to `unicodedata.normalize(form, text)`. Include in doc that this uses the latest Unicode data via unicodedata2, so it may recognize characters added in newer versions that the standard library might not (if on older Python).

**Case Folding**: Unicode case folding (for case-insensitive matching) can also be accessed via `unicodedata.normalize("NFKD", s).casefold()` or via ICU’s CaseFold. Simpler: Python’s `str.casefold()` is available (though Python’s casefold should be up-to-date with its Unicode version). We can provide `uicu.casefold(text)` to explicitly use the latest Unicode’s case folding. Implement by simply calling `text.casefold()`. (If we want to be absolutely sure it’s latest, the `unicodedata2` package might have a method for casefold? If not, Python’s will do – casefold doesn’t change often).

**Locale-Aware Case Conversion**: This is where ICU excels beyond Python. Python’s `str.upper()` and `lower()` are **not locale-aware** (they are context-insensitive except for Turkic dotted/dotless i which Python handles in a simplified way via `casefold`). ICU knows, for example, that in Turkish locale, `"i".upper()` should produce `"\u0130"` (Latin capital I with dot). We provide:

* `uicu.to_lower(text, locale=None)`
* `uicu.to_upper(text, locale=None)`
* `uicu.to_title(text, locale=None)`

Each converts the string to the respective case, following the rules of the given locale (if locale is None, use default locale or a root Unicode default). Implement by leveraging ICU’s `UnicodeString` transformations: e.g.

```python
def to_lower(text: str, locale: str = None) -> str:
    # If locale is provided (as BCP47 or ICU format string), get an ICU Locale
    loc = icu.Locale(locale) if locale else icu.Locale()  # default locale
    ustr = icu.UnicodeString(text)
    ustr_lowered = ustr.toLower(loc)
    return str(ustr_lowered)
```

The `icu.UnicodeString.toLower()` will apply locale-specific rules. We then convert back to Python `str` (PyICU allows `str(UnicodeString)` to do that conversion). Similarly for `to_upper` (using `toUpper`) and `to_title`. ICU’s `toTitle` can optionally take a break iterator to define word boundaries (for titlecasing each word), but if not provided, ICU will titlecase the first letter of each word by default. We can accept an optional parameter if needed in future to provide different titlecasing behavior, but not mandatory. Document that these are useful for locales like Turkish (`uicu.to_upper("i", "tr") -> "İ"`, whereas Python’s `"i".upper() -> "I"`). Add tests for such cases.

### 3. Text Segmentation (Graphemes, Words, Sentences, Lines)

One of the most valuable ICU features is splitting text on Unicode boundaries (grapheme cluster, word, etc.), according to the Unicode Text Segmentation standard (UAX #29). We will expose this in a very user-friendly way.

**Grapheme Clusters**: In Python, `for ch in text` iterates code points, not user-visible characters when combined marks are involved. For example, `"🇨🇦"` (Canadian flag emoji) is 2 code points, Python `len("🇨🇦") == 2` and iterating yields two separate regional indicator symbols. We want `uicu.graphemes(text)` to iterate or return the *actual characters* as seen by users.

* Implement `uicu.graphemes(text)` as a generator (or list) of grapheme cluster strings. Internally:

  1. Create an ICU break iterator for *character* boundaries: `bi = icu.BreakIterator.createCharacterInstance(locale)`. Typically, grapheme segmentation isn’t locale-variant (except for certain cases like Hangul syllable breaks, but those are algorithmic). ICU uses root locale if none given. We can allow an optional `locale` arg just in case (default to None).
  2. **Important**: Use ICU’s `UnicodeString` for the text to avoid index issues. E.g. `u16 = icu.UnicodeString(text)`, then `bi.setText(u16)`.
  3. Iterate over `bi` to get break positions (PyICU’s BreakIterator supports Python iteration yielding indices). Collect the segments by slicing the **UnicodeString** at those indices. For each segment `u_segment = u16[i:j]` (PyICU allows slicing a UnicodeString with Python slice syntax), convert it to str and yield.
  4. Alternatively, PyICU might have a convenience: perhaps `for seg in bi.getText()` or similar, but likely not – so we do manual slicing as above.
  5. This yields each grapheme cluster as a Python string.

  We should ensure this handles the entire string (the iterator will yield indices including the final length as end). We stop when `nextBoundary()` returns `-1` (the ICU convention). The last segment from last boundary to end of text must be included. (When using the Python iteration protocol as in `for j in bi:`, I believe it yields the end positions and after loop we’re done – we can manage it as in the blog example: track a `last_pos`, and for each boundary index yield `text[last_pos:j]` then update `last_pos`. But since we have `UnicodeString` and can slice it directly, that approach works similarly, using the UnicodeString for slicing).

  Provide this as both an **iterator** (generator function) and possibly as a method on a higher-level class (if we introduce a `UnicodeString` wrapper class in `uicu`). We could make `uicu.graphemes(text)` return a list for convenience, but for large texts a generator is more memory efficient. Perhaps return an iterator by default; users can do `list(uicu.graphemes(text))` if needed. Document this clearly.

* **Words**: `uicu.words(text, locale=None)` similarly uses `BreakIterator.createWordInstance(locale)`. Word boundary finding is definitely locale-dependent (e.g. Thai, Chinese segmentation). Implementation is analogous: feed a UnicodeString to the break iterator, iterate boundaries, slice out each word. However, note ICU’s definition of “word” will include punctuation and whitespace segments as separate tokens (as seen in the example output where spaces and punctuation came as separate items). We might choose to **filter out non-word tokens** by default – for instance, ICU marks boundaries and you often get empty or whitespace tokens. PyICU’s BreakIterator likely has methods to check the **rule status** to see if a boundary is a word boundary versus whitespace. But to keep it simple, we can initially include everything (so the output list would include spaces/punctuation as separate items, like in the example). Alternatively, we could filter to only alphabetic word tokens by skipping segments that are just whitespace or punctuation. This could be an option flag (e.g. `words(text, skip_delimiters=True)`). For now, perhaps return all segments (as ICU defines them), and mention in docs that punctuation and spaces will appear as separate tokens.

* **Sentences**: `uicu.sentences(text, locale=None)` uses `BreakIterator.createSentenceInstance(locale)`. This will yield sentence by sentence (including the trailing punctuation like period). Implementation is straightforward with slicing like above. Likely we won’t filter anything here; each segment should be a full sentence string.

* **Line Breaks**: `uicu.lines(text, locale=None)` using `BreakIterator.createLineInstance(locale)` for line break opportunities. ICU’s line breaking algorithm identifies places a line can break (considering hyphenation, punctuation, etc.). Typically used for wrapping, but we can expose it similarly. This might include the newline characters if present or potential breaks in text. We should clarify whether we mean *existing* lines or *possible* line break opportunities. Perhaps more useful is splitting on existing newline characters plus ICU’s discretionary breaks. However, as a first pass, we might skip this unless explicitly needed. If included, implement like others.

For all these segmentation functions, to **guide the developer**: write a helper internal function to avoid repetition, e.g. `_break_iterator_segments(text, break_iterator) -> iterator` that given a prepared `BreakIterator` (already set with text) yields substrings. Then each public function (graphemes/words/sentences) can create the appropriate break iterator via PyICU and call this helper. This avoids duplicating the loop logic. The helper can be similar to the pseudocode from ICU examples or our described method. Also, be careful to convert any results to Python str. (PyICU’s UnicodeString slicing yields UnicodeString objects; we should call `str()` on them or ensure iteration yields Python strings directly. Possibly PyICU’s iteration might yield Python str if the BreakIterator was given a Python str… but we gave it UnicodeString. To be safe, explicitly convert segments to str.)

**Locale handling**: If locale is None, use a neutral default. ICU’s `BreakIterator.createXXXInstance(locale)` requires an `icu.Locale` object. We can do `icu.Locale(locale_code)` if a string is given. If None, use `icu.Locale.getDefault()` (current locale) or simply `icu.Locale()` which uses default. Document that locale can influence especially word and sentence boundaries (for example, \`"Mr." might or might not end a sentence depending on locale conventions, etc.).

**Testing**: Use multilingual examples. E.g., grapheme clusters: an emoji with skin tone and ZWJ (👨🏽‍⚕️ as doctor emoji) should count as one grapheme. Korean Hangul syllables vs Jamo sequence should not split, etc. Words: test English (split on spaces/punctuation), CJK (Chinese text should ideally output per Chinese character or idiographic word), and Thai (which has no spaces but ICU should segment Thai words). We might compare results with known correct segmentations for a few cases. Sentence: input with multiple sentences. These tests ensure our wrapper correctly yields expected segments.

### 4. Locale-Aware Collation (String Comparison & Sorting)

Sorting strings in Unicode can be non-trivial (accented letters, different scripts, etc.). ICU’s **Collator** provides proper locale-sensitive ordering (the Unicode Collation Algorithm, UCA). Python’s default sorting is binary/unicode codepoint order which may not be culturally correct. We will create a high-level Collator API in `uicu`:

* **Collator Class**: Introduce `uicu.Collator(locale=None, **options)` as a Pythonic wrapper around ICU’s Collator. This class will encapsulate an ICU collator object (`icu.Collator` or `icu.RuleBasedCollator`). Key methods and usage:

  * `__init__`: Accepts a locale identifier (string or ICU Locale). If None, use default locale. Internally, do `icu.Collator.createInstance(locale_obj)` to get the collator. Also accept optional `options` like **strength** and **case/numeric settings**:

    * `strength`: Unicode collation strength level (primary, secondary, tertiary, quaternary, identical). We can map string or enum values to ICU’s constants. For example, strength="primary" means base letters only (ignore accents and case), "tertiary" is default (distinguish accents and case), etc. If provided, call `collator.setStrength(...)`. PyICU likely exposes an enum or we may use `icu.Collator.PRIMARY` etc.
    * `ignore_case`: If True, set collator to case-insensitive (could set strength to secondary if we want to ignore case differences but keep accents, or use `collator.setAttribute(UCollAttribute.CASE_LEVEL, VALUE_OFF)` accordingly).
    * `numeric`: If True, enable **numeric collation** (so "file2" comes before "file10", treating digits as numbers). ICU allows this via `collator.setAttribute(UCOL_NUMERIC_COLLATION, UCOL_ON)`. If PyICU exposes it, we use it. If not easily, perhaps skip or use a RuleBasedCollator with “\[numeric on]”. But likely PyICU has a way.
    * We can add other options like alternate handling (shifted for punctuation), but to keep it simple for now, these three cover common needs. Document them.

  * **Comparison methods**:

    * `compare(str1, str2) -> int`: return negative if str1 < str2, zero if equal, positive if str1 > str2 under the collation. Implement by calling `self._collator.compare(str1, str2)` if PyICU provides it ( ICU C++ has Collator::compare). If not directly, one can compare sort keys (see below). This is for completeness, though Python typically doesn’t use comparator functions.
    * `key(str) -> object`: return a collation key for the string, suitable for sorting. This could return the raw sort key (often a byte sequence). PyICU’s `collator.getSortKey(str)` returns a Python bytes object that encodes the collation ordering. We can return that directly. These keys, when compared lexicographically (bytewise), reflect the proper order. In usage, one can do `sorted(strings, key=collator.key)`. We might also implement `Collator.__call__(self, s)` to alias to `key(s)`, so that the Collator instance can be passed as a key function directly (since callables are accepted as key in sort). E.g., `sorted(names, key=uicu.Collator('sv_SE'))` to sort Swedish names. This would be very convenient.
    * Perhaps also `__lt__`, `__eq__` methods on Collator that compare two strings? That’s tricky because it’s unclear what to compare to – if we say `collator1 < collator2` doesn’t make sense. We could allow `collator.compare(str1, str2)` usage explicitly. So maybe no need for `__lt__` on Collator itself.

  * **Advanced**: `Collator.sort(list_of_str)` – convenience method to sort a list in place according to that collator. It could just do `list.sort(key=self.key)`. Not essential but a nice one-liner for users.

  * **Rule-based tailoring**: ICU allows custom collation rules (e.g. to change sorting order of certain characters). PyICU has `RuleBasedCollator(rules)`. For completeness, we might allow `Collator(rules="...")` as an alternative way to initialize – detect if the first arg is a string containing collation rules (perhaps if it contains newline or special characters like `&` typical in rules syntax). If so, create `icu.RuleBasedCollator(rules)` instead of locale-based. This is an advanced use-case; we can document but a junior dev can implement by checking an `rules` keyword argument.

  Implementation notes: The Collator wrapper stores `self._collator = icu.Collator.createInstance(loc)` or a RuleBasedCollator. All methods will use this internal `_collator`. We will ensure any string passed to `_collator` is a Python `str`, which PyICU will accept (it converts to UnicodeString under the hood). (If any issues with surrogates, ICU will handle internally in sort key generation correctly.)

* **Functional API**: In addition to the class, provide quick functions:

  * `uicu.sort(strings, locale)` that returns a new list sorted by locale. Implementation: `sorted(strings, key=Collator(locale))`. This is a one-liner using our class. So basically a convenience that hides the Collator object. If we implement it, it should be a shallow wrapper. Example usage: `uicu.sort(["zig", "äpfel", "apple"], locale="de")` and get them sorted as a German would (with "ä" correctly sorted near "a").
  * `uicu.sorted(strings, locale)` similarly (like Python’s built-in `sorted`). One could just use the above, so maybe just one of them is enough.
  * We might also provide `uicu.compare(str1, str2, locale)` for a one-off comparison returning -1/0/1 using a ephemeral Collator. But this is minor; users can instantiate Collator if needed.

**Testing**: We will test that sorting works as expected. For example, sorting \["a", "ä", "b"] in German locale should yield \["a", "ä", "b"] (since ä is treated as a = ae maybe, but in Swedish locale it should come after "z"). We can use known correct orders from examples or ICU docs. Also test numeric collation option: e.g. sorting \["file2", "file10", "file1"] with numeric=True should yield \["file1","file2","file10"], whereas default string collation might give "file1","file10","file2".

### 5. Transliteration and Text Transforms

ICU’s transliteration engine can perform complex text transformations (e.g. converting non-Latin scripts to Latin (romanization), or removing diacritics, etc.). `uicu` will provide easy access to common transliterations and a way to use custom ones:

* **Simple Transliteration Function**: `uicu.transliterate(text, id, direction='forward') -> str`. Here `id` is an ICU transliterator identifier string, like `"Greek-Latin"` to transliterate Greek to Latin script. ICU has many built-in IDs (the ICU user guide lists them). We will not hardcode the list but we can link to ICU docs for reference. `direction` can be `'forward'` (default) or `'reverse'` to apply the inverse transliteration (PyICU expects a constant `icu.UTransDirection.REVERSE` or an enum, but in Python we can just pass a flag). Implementation:

  * If direction is reverse, we could either call `icu.Transliterator.createInstance(id, UTransDirection.REVERSE)`, otherwise the normal createInstance. Apply `.transliterate(text)` and return the result. PyICU will accept Python str for transliteration and return a Python str (likely). If not, we may wrap the text in UnicodeString first just to be safe with any non-BMP issues (though transliteration output length is usually aligned with input characters count or more, but ICU likely handles it).
  * Alternatively, ICU offers an easier reverse: you can get a Transliterator and call `.transpose()` to get inverse. But simply creating with reverse flag is fine.

  This function is a one-liner usage for common tasks. E.g. `uicu.transliterate("Παράδειγμα", "Greek-Latin")` → "Parádeigma".

* **Transliterator Class**: For repeated use or more advanced control, provide a `uicu.Transliterator` class. It will wrap `icu.Transliterator`. Usage:

  ```python
  tr = uicu.Transliterator("Latin-Devanagari")  # create transliterator from Latin script to Devanagari
  hindi = tr.transliterate("kshatriya")  # get result
  tr_rev = tr.inverse()  # get inverse transliterator as a new uicu.Transliterator
  ```

  Implementation:

  * `__init__(self, id, direction='forward')`: store `self._icu_trans = icu.Transliterator.createInstance(id, dir)`. If creation fails (e.g. unknown ID), PyICU might throw an ICUError – catch and raise a custom error or message.
  * `transliterate(self, text)`: simply `return self._icu_trans.transliterate(text)`. PyICU returns a Python str here.
  * `inverse(self)`: returns a new `uicu.Transliterator` which is the inverse of the current. Implement by `inv_icu = self._icu_trans.createInverse()`, then wrap in our class.

  We can also allow custom transliteration rules: ICU supports rule strings to create a Transliterator (for example, a rule that removes diacritics could be `"[\\p{M}]>;"` to strip marks). If user passes a rule string rather than a known ID, ICU will treat it as rules if we call `createInstance` with id. Actually, ICU expects either a registered ID or a rule pattern. There is also `icu.Transliterator.createFromRules(name, rules, direction)` if needed for custom rules not registered. We can expose that via an alternative constructor like classmethod `Transliterator.from_rules(name, rules, direction='forward')`. This might be advanced, but including it would make the API “very extensive” as requested. A junior dev can implement by calling that ICU function.

  Common transliterators to mention in docs: "Any-Latin" (to Latin from any script), "Latin-Ascii" (remove accents), "NFD; \[:Nonspacing Mark:] Remove; NFC" (this can be achieved via rules to strip diacritics if not using built-in). We should encourage using built-in IDs where possible.

* **Other Transforms**: ICU’s transliteration also covers things like case folding (there might be an "Any-CaseFold"), or script-specific transforms like "Hiragana-Katakana". We won’t enumerate all, but by providing the flexible interface, users can do what they need.

**Testing**: Test a couple of transliterations: e.g., Greek to Latin as above, or Devanagari to Latin ("देवनागरी"->"devanāgarī"), and a reverse. Also test using the transliterator object multiple times (to ensure state is either stateless or properly handled – ICU transliterators are usually stateless or reset each call). If we provide custom rule usage, test a simple rule (like swapping letters).

### 6. Additional Considerations

**Error Handling**: PyICU functions throw `ICUError` (a Python exception) when something goes wrong (it wraps ICU’s UErrorCode). For example, if an invalid locale ID or transliterator ID is given, an error will be raised. Our `uicu` can either let these exceptions propagate or catch and wrap them in our own exception class (e.g., define `uicu.Error` as a subclass of Exception, possibly holding the original ICUError). It might be simplest to let ICUError surface, but document it. However, to make a cleaner API, wrapping could be good – for instance, raise `ValueError` for invalid locale or ID, with message extracted from ICUError. A junior developer can implement basic try/except around createInstance calls and raise appropriate Pythonic exceptions (ValueError or a custom UICUError). We should specify this clearly in docs: e.g. "If an unknown script code is requested, a KeyError is raised" (as fontTools does), or "If an invalid transliteration ID is given, `uicu.Error` is raised with the ICU message."

**Performance**: We will advise to **reuse objects** when appropriate. For example, if an application needs to segment many strings the same way, reusing a BreakIterator is more efficient than creating a new one each time (ICU break iterator has an expensive initialization). However, PyICU BreakIterator instances are not obviously reusable with new text (though actually they are: one can call `.setText()` repeatedly on the same iterator with different strings). We might expose that by allowing `uicu.GraphemeIterator` class that holds an ICU BreakIterator and can be called on multiple texts. But that might complicate things for little gain at first. Instead, we can internally cache frequently used break iterators. For instance, `uicu.graphemes` could create a global single `BreakIterator.createCharacterInstance(Locale())` on first use and reuse it (with different text set each call). But ICU break iterators are **not thread-safe** unless each thread has its own. Given this is a library, safer to not cache globally by default (to avoid concurrency issues). Perhaps we skip caching. We can note in documentation that if you need to segment thousands of strings, it may be worth to create a BreakIterator once and reuse via a provided class. As an advanced feature, a `uicu.TextBreaker(kind="word", locale=None)` object could be created, with a method `segments(text)` returning segments. The developer can implement that if needed. Initially, keep it simple: create new ones each call.

For collation, similar reasoning: creating a Collator is somewhat expensive (needs to load collation rules). If sorting many lists, reuse the Collator object. Our API already supports that (via the Collator class).

**Integration with Python iteration and slicing**: We will ensure any custom objects behave intuitively:

* If we have a `uicu.UnicodeString` wrapper (if we decide to create one to mirror ICU’s UnicodeString but as Python class), it should perhaps subclass `str` (so it inherits all string behavior) or at least implement sequence methods (`__len__`, `__getitem__`, etc.) by delegating to the internal str. This might be overkill, and since Python’s str is itself adequate, we probably skip making a custom string type. Instead, we use Python str everywhere and only use ICU’s UnicodeString internally. This is simpler and avoids confusion. So likely we do *not* make a `UnicodeString` class in `uicu` (since Python’s str suffices as the public type). The only new classes we introduce are things like `Char`, `Collator`, `Transliterator` as above, and possibly a `Locale` wrapper if needed.

**Locale Handling**: We should decide whether to expose ICU’s `Locale` class or hide it. PyICU’s Locale can be used directly by users, but to keep things consistent, our functions/classes accept `locale` as either a `str` (like `"en_US"` or `"fr-CA"` or BCP47 `"fr-CA-u-nu-latn"` etc.) or an `icu.Locale` object. Internally, we detect and convert if needed. We may also accept Python’s locale identifiers (which are often the same as ICU, just underscore vs hyphen differences). We'll document using the ICU/CLDR format (language\_Country). Provide convenience like `locale = None` means system default.

We could provide a thin wrapper `uicu.Locale` class that maybe inherits or wraps `icu.Locale` just to add Pythonic methods or repr. However, PyICU’s Locale already has nicely named constructors like `Locale.getFrance()`, etc., and properties like `getDisplayName()`. Probably no need to wrap it deeply. We can simply allow PyICU’s Locale to be used. Maybe just mention in docs that advanced locale info can be accessed via `icu.Locale` if needed, but not necessary for basic usage of our library.

**Package Structure**: The final code will reside under `src/uicu/`. We will have at least `uicu.py` implementing everything in one module for now. We also have `__version__.py` for version info. The project root has README, etc. Ensure to update README.md with usage examples demonstrating our new API (this will help the junior dev and users). Possibly maintain a `TODO.md` with any future extensions (like adding Bidi support or Regex wrappers in future).

If the module grows large, we can refactor into submodules: e.g. `uicu/collation.py`, `uicu/segmentation.py`, etc., and import them in `uicu/__init__.py`. The given structure shows a single `uicu.py`, but a “multifile package” was mentioned, so organizing by feature is okay. For now, the plan can proceed with one file, with clearly separated sections internally and maybe using internal helper functions to keep it tidy.

## Step-by-Step Implementation Guide

Following the design above, here’s a suggested order of implementation for a junior developer:

1. **Set up project structure**: Create the directory and files as given. Ensure `pyproject.toml` has dependencies: include `pyicu` and `fonttools[unicode]` (or `unicodedata2`) as requirements. This ensures the environment has ICU and updated Unicode data. Write a brief README introduction (can be filled after implementing, with examples).

2. **Character properties functions**: In `uicu.py`, import `unicodedata` from `unicodedata2` (fall back to built-in if import fails, but ideally require unicodedata2). Also `from fontTools import unicodedata as ftunicodedata`. Start implementing `name(char)`, `category(char)`, etc., by delegating to these. Write docstrings for each, citing that data is from Unicode X.Y (whatever version). Implement `script`, `block`, etc., using fontTools functions. Make sure to handle if input is not a single character: decide if we want to allow strings of length >1 (maybe not, we can enforce len==1 for these functions, and document that they take a single character). If a longer string is given by mistake, maybe we either process first char or raise an error. Possibly safer to raise ValueError to prevent misuse.

3. **Char class**: Define `class Char:` with an `__init__` that stores the char (after validation) and attributes like name, etc., filled by calling the functions above. This is straightforward. Also define `__repr__` to show meaningful info, and maybe `__str__` to return the raw character. This class goes in `uicu.py` as well.

4. **Normalization and case**: Implement `normalize(text, form)` using `unicodedata.normalize`. Implement `casefold(text)` using `str.casefold()`. Then `to_lower, to_upper, to_title` using PyICU’s UnicodeString as described. For this, you need to import `import icu` at top (PyICU module). If any locale code is provided as argument, convert via `icu.Locale(locale_code)`; if None, use `icu.Locale.getDefault()`. Test these quickly in an interactive session to ensure, for example, `to_upper('i', 'tr_TR')` yields `'\u0130'`. Document these functions with examples.

5. **Segmentation functions**: Import `icu.BreakIterator`. Implement an internal helper, e.g. `_iter_segments(text, bi)` where `bi` is a BreakIterator already set to the text. It should yield segments. Use the pattern:

   ```python
   utext = icu.UnicodeString(text)
   bi.setText(utext)
   last = 0
   for boundary in bi:
       segment = utext[last:boundary]    # get ICU UnicodeString from last to boundary
       yield str(segment)               # convert to Python string
       last = boundary
   ```

   Ensure after the loop, we don’t need an extra step (since the iterator yields the final index equal to text length as the last boundary, the loop logic above actually covers the whole text and ends naturally). Implement `graphemes(text)`, `words(text, locale=None)`, `sentences(text, locale=None)` by creating the appropriate BreakIterator via the class method, then delegating to `_iter_segments`. For locale, if provided (string), do `icu.Locale(locale)`, else default. For word segmentation, consider filtering out purely whitespace tokens: ICU will produce them (see example where spaces are separate). Possibly, we can post-filter: e.g., inside the loop for words, skip `segment` that is all whitespace (or that `segment.strip()` is empty). But sometimes punctuation like "-" might also be separated. We could leave them in to exactly mirror ICU, and let user decide to filter if needed. It’s safer to leave as is for now (complete fidelity), and document that output includes whitespace and punctuation segments.

   Also, ensure that if the text is empty, the functions handle gracefully (probably just yield nothing).

6. **Collator and sorting**: Implement the `Collator` class as described. Import `icu.Collator`. In `__init__`, call `icu.Collator.createInstance(locale_obj)`. If `locale` is a str, do `locale_obj = icu.Locale(locale)`. If that fails (bad locale string), catch ICUError and raise ValueError("Unknown locale ..."). Then set attributes if options given (for strength, etc., use `self._collator.setStrength(icu.Collator.TERTIARY)` for example). PyICU likely has those constants under Collator. If numeric option, try `self._collator.setAttribute(icu.UCollAttribute.NUMERIC_COLLATION, icu.UCollAttributeValue.ON)` – these enums might need import from `icu` as well (PyICU might expose them or via Collator class attributes). Refer to PyICU docs or source for exact usage. If it’s complicated, a simpler workaround is to use a rule-based collator string “\[numeric on]” on top of base rules (as the cheat sheet did for Welsh example), but that's not straightforward for arbitrary locale combination. We expect PyICU Collator to allow setting numeric via `collator.setAttribute`. We’ll proceed with that plan.

   Methods: `compare(a,b)` could use `self._collator.compare(a,b)`. (We should verify PyICU Collator object indeed has a compare method – ICU C++ Collator does. If not, we can simulate by computing keys and comparing those bytewise.) `key(s)` uses `self._collator.getSortKey(s)` which returns `bytes`. That can be returned directly or we might want to return a \_Key wrapper with defined comparison. Simpler: return bytes, since Python will compare those correctly. It’s fine. Implement `__call__ = key` to make the object callable as key function.

   Add a `sort(iterable)` method if desired (just returns sorted copy using self as key).

   Also implement maybe `__enter__` and `__exit__` for context manager? Not obviously needed for Collator. Probably not.

   The developer should also expose a functional interface: define `uicu.sort(strings, locale, **options)` that internally does `return sorted(strings, key=Collator(locale, **options))`. And/or `uicu.sorted` similarly (one might suffice).

   Test the Collator class on a basic example: e.g., `Collator('en').compare("a","b")` returns -1 (assuming "a" < "b"). Sorting with key should order strings properly (we can test with a list including "é" and "e" in French locale, etc.).

7. **Transliteration**: Implement `transliterate(text, id, direction='forward')` function first. Import `icu.Transliterator` and `icu.UTransDirection`. Map `direction='reverse'` to `icu.UTransDirection.REVERSE` (PyICU likely provides this enum). Otherwise use `UTransDirection.FORWARD` or simply omit since forward is default. The call:

   ```python
   trans = icu.Transliterator.createInstance(id, direction_enum)
   result = trans.transliterate(text)
   return result
   ```

   Wrap in try/except to catch ICUError if the ID is invalid, and raise a ValueError listing the id.

   Then the `Transliterator` class: store `self._trans = icu.Transliterator.createInstance(id, dir)`. Provide `transliterate(self, text)` calling `self._trans.transliterate(text)`. Provide `inverse(self)` doing `inv = self._trans.createInverse()` and wrap in `Transliterator` class (i.e., `return Transliterator.__new__` or better provide an alternate constructor: we can simply do `inv_obj = object.__new__(Transliterator)` and set `inv_obj._trans = inv`, but easier is to call our own **init** by constructing a new Transliterator with the reverse param. Actually, simpler: just do `return Transliterator(id, direction='reverse')` if we know id, but that might redo the lookup; using `createInverse` is more direct and handles compound translits properly. So do `inv_icutrans = self._trans.createInverse(); inv = Transliterator.__new__(Transliterator); inv._trans = inv_icutrans; return inv` – and also maybe store an attribute for id or name in the object if needed for reference).

   Additionally, implement `__call__(self, text)` as alias to `transliterate`, so the object can be used as a function (less important, but could be nice).

   Test transliterator on a known transform. If possible, include in tests: for example `uicu.transliterate("ρας", "Greek-Latin")` -> "ras", and inverse returns original (with appropriate direction).

8. **Documentation and Examples**: Throughout the code, add docstrings with examples (in Markdown or reStructuredText if using Sphinx later). E.g., for `uicu.graphemes`: explain what grapheme clusters are, and show usage:

   ```python
   >>> list(uicu.graphemes("naïve"))
   ["n", "ä", "i", "v", "e"]  # the 'a' with diaeresis is one grapheme
   ```

   and perhaps an emoji example. For collation, show sorting example in docstring. For transliteration, show converting script. These will not only help users but also serve as simple tests (could even be used as doctests).

   Update README.md to describe the package and include a quickstart: e.g., demonstrate how to use a few major features (maybe showing a side-by-side of doing something with PyICU vs how much simpler with uicu, to emphasize the improvement). For instance, show how to get grapheme clusters in one line with `list(uicu.graphemes(text))` instead of 10 lines of PyICU code.

9. **Testing**: In `tests/test_package.py`, write tests for each major function. Use assertions for known values. For segmentation, you might include known tricky cases (like flags, family emojis 👨‍👩‍👦, which should count as one grapheme each). For collation, test that Collator sorts strings in expected order for a couple of locales. Note: Running ICU collation tests might require known reference data; we can do a simpler test like sorting `["Z", "a"]` in a case-insensitive Collator and expecting `["a","Z"]` when strength=primary (ignoring case). Transliteration test as mentioned. Character property tests using a couple of characters from different scripts.

10. **Performance check** (optional): If possible, benchmark that calling our functions isn’t egregiously slow. Likely fine, but if issues, consider optimizations (like caching ICU objects). Since this is an initial version, clarity and correctness come first; optimizations can be listed in TODO.md.

By following this plan, the junior developer should be able to implement `uicu` as a well-organized package. The end result will be a multi-faceted Unicode utility library that harnesses ICU’s power with a clean Python interface. This will greatly simplify tasks such as iteration over graphemes (previously “more of a pain than you’d hope” in raw PyICU), handling full Unicode properties, and performing locale-aware text processing in Python.

## Package Structure Confirmation

The `uicu` package will conform to the given structure. All code resides in `src/uicu/`, primarily in `uicu.py` (which can import submodules if we split the code). We will include the version in `__version__.py`. Tests in `tests/`. Documentation in `README.md` and possibly supplementary design notes in `AGENTS.md`/`CLAUDE.md` if those are used for project communication.

After implementation, the developer should verify everything is running using the latest ICU (PyICU) and fontTools data. We expect that this library will make advanced Unicode handling in Python much more accessible, combining **the extensive ICU functionality** with **Pythonic ease of use**.

**Sources:** This plan was informed by ICU/PyICU documentation and examples, as well as fontTools’ Unicode data module reference.
</file>

<file path="research/res-grok.md">
# Specification for `uicu` Package

## 1. Introduction
The `uicu` package is a Pythonic wrapper around [PyICU](https://pypi.org/project/pyicu/), which provides Python bindings for the [ICU library](https://unicode-org.github.io/icu/). The goal is to create an intuitive, well-documented, and performant API that integrates seamlessly with Python’s native Unicode handling (`str`) while exposing ICU’s rich functionality, including Unicode properties, locale handling, formatting, collation, transliteration, and text segmentation. The package may incorporate [fontTools.unicodedata](https://fonttools.readthedocs.io/en/latest/unicodedata/index.html) for specific Unicode data needs, such as writing system information, if it provides advantages over ICU.

This specification outlines the package structure, API design, and implementation guidelines to assist a junior developer in building `uicu`. It includes detailed examples, performance considerations, and documentation standards.

## 2. Package Structure
The `uicu` package will be organized into submodules to reflect ICU’s major components, ensuring modularity and ease of use. The proposed structure is:

- `uicu/__init__.py`: Top-level imports, package metadata, and high-level convenience functions.
- `uicu/unicode.py`: Functions for Unicode character properties and string operations.
- `uicu/locale.py`: Classes and functions for locale handling.
- `uicu/format.py`: Classes for formatting and parsing dates, numbers, and messages.
- `uicu/collation.py`: Functions and classes for locale-aware string comparison and sorting.
- `uicu/transliterate.py`: Functions for transliteration.
- `uicu/breakiter.py`: Classes for text segmentation (e.g., word or sentence boundaries).

Each module will provide Pythonic interfaces, either as functions operating on native Python types (e.g., `str`) or as classes wrapping PyICU objects with simplified methods.

## 3. API Design Principles
To ensure the API is Pythonic, natural, and performant, the following principles will guide development:

- **Simplicity**: Provide high-level functions for common tasks (e.g., `uicu.format_date()` instead of multiple PyICU steps).
- **Integration with Python**: Use Python’s `str` for string operations where possible, supplementing with ICU for advanced functionality.
- **Consistency**: Follow PEP 8 naming conventions (e.g., `lowercase_with_underscores` for functions) and use exceptions for error handling.
- **Performance**: Minimize wrapper overhead by directly calling PyICU methods where feasible.
- **Documentation**: Include detailed docstrings with examples, type hints, and references to ICU documentation.
- **Flexibility**: Offer both simple functions for quick tasks and classes for advanced use cases requiring fine-grained control.

## 4. Detailed API Specification

### 4.1. `uicu.unicode`
This module handles Unicode character properties and string operations, leveraging ICU’s `uchar` module and `UnicodeString` class.

#### Functions
- `normalize(text: str, form: str = 'NFC') -> str`
  - Normalizes a string using ICU’s Normalizer2.
  - Parameters:
    - `text`: Input string to normalize.
    - `form`: Normalization form (`'NFC'`, `'NFD'`, `'NFKC'`, `'NFKD'`).
  - Returns: Normalized Python `str`.
  - Example:
    ```python
    import uicu
    text = "café"
    normalized = uicu.normalize(text, 'NFD')  # Decomposes 'é' into 'e' + combining acute accent
    ```
- `get_category(char: str) -> str`
  - Returns the Unicode general category of a single character (e.g., `'Lu'` for uppercase letter).
  - Uses ICU’s `u_charType` or fontTools.unicodedata’s `category` if specified.
  - Example:
    ```python
    category = uicu.get_category('A')  # Returns 'Lu'
    ```
- `is_alpha(char: str) -> bool`
  - Checks if a character is alphabetic using ICU’s `u_isalpha`.
  - Example:
    ```python
    is_alpha = uicu.is_alpha('α')  # Returns True
    ```

#### Classes
- `UnicodeString`
  - Wraps `icu.UnicodeString` for advanced string operations.
  - Methods:
    - `__str__()`: Converts to Python `str`.
    - `normalize(form: str = 'NFC') -> str`: Normalizes the string.
    - `to_upper(locale: str = None) -> str`: Converts to uppercase, optionally locale-aware.
  - Example:
    ```python
    from uicu import UnicodeString
    us = UnicodeString("café")
    upper = us.to_upper(locale='tr_TR')  # Turkish uppercase rules
    ```

### 4.2. `uicu.locale`
This module provides locale handling, wrapping `icu.Locale`.

#### Classes
- `Locale`
  - Wraps `icu.Locale` with Pythonic properties.
  - Properties:
    - `language`: Returns the language code (e.g., `'en'`).
    - `display_name`: Returns the locale’s display name.
  - Methods:
    - `get_available() -> List[str]`: Returns available locale IDs.
  - Example:
    ```python
    from uicu import Locale
    loc = Locale('fr_FR')
    print(loc.display_name)  # Prints "French (France)"
    ```

#### Context Manager
- `set_locale(locale: str)`
  - Temporarily sets the default locale for ICU operations.
  - Example:
    ```python
    with uicu.set_locale('es_ES'):
        formatted = uicu.format_number(1234.56)  # Uses Spanish formatting
    ```

### 4.3. `uicu.format`
This module handles formatting and parsing for dates, numbers, and messages.

#### Classes
- `DateFormatter`
  - Wraps `icu.DateFormat` for date and time formatting.
  - Methods:
    - `format(dt: datetime) -> str`: Formats a datetime object.
    - `parse(text: str) -> datetime`: Parses a string to a datetime.
  - Example:
    ```python
    from uicu import DateFormatter
    formatter = DateFormatter(locale='en_US', pattern='MMM d, y')
    formatted = formatter.format(datetime.now())  # e.g., "Oct 25, 2025"
    ```
- `NumberFormatter`
  - Wraps `icu.NumberFormat` for number formatting.
  - Methods:
    - `format(number: float) -> str`: Formats a number.
  - Example:
    ```python
    formatter = uicu.NumberFormatter(locale='de_DE')
    formatted = formatter.format(1234.56)  # e.g., "1.234,56"
    ```

#### Functions
- `format_date(dt: datetime, locale: str = None, pattern: str = None) -> str`
  - Convenience function for date formatting.
  - Example:
    ```python
    formatted = uicu.format_date(datetime.now(), locale='en_US', pattern='MMM d, y')
    ```

### 4 U.4. `uicu.collation`
This module provides locale-aware string comparison and sorting.

#### Functions
- `sorted(strings: List[str], locale: str = None) -> List[str]`
  - Sorts strings using ICU’s collation rules.
  - Example:
    ```python
    strings = ['café', 'cafe']
    sorted_list = uicu.sorted(strings, locale='fr_FR')  # Locale-aware sorting
    ```

#### Classes
- `Collator`
  - Wraps `icu.Collator` for custom collation.
  - Methods:
    - `compare(a: str, b: str) -> int`: Compares two strings.
  - Example:
    ```python
    from uicu import Collator
    collator = Collator(locale='fr_FR')
    sorted_list = sorted(strings, key=collator)
    ```

### 4.5. `uicu.transliterate`
This module handles transliteration.

#### Functions
- `transliterate(text: str, transform: str) -> str`
  - Transliterates text using ICU’s transliteration rules.
  - Example:
    ```python
    text = uicu.transliterate("привет", "Cyrillic-Latin")  # Returns "privet"
    ```

### 4.6. `uicu.breakiter`
This module provides text segmentation.

#### Classes
- `BreakIterator`
  - Wraps `icu.BreakIterator` for word, sentence, or line breaking.
  - Methods:
    - `boundaries(text: str) -> List[int]`: Returns boundary indices.
  - Example:
    ```python
    from uicu import BreakIterator
    bi = BreakIterator('word', locale='en_US')
    boundaries = bi.boundaries("Hello world!")  # Returns word boundary indices
    ```

## 5. Integration with fontTools.unicodedata
The `uicu.unicode` module will include an optional parameter to use fontTools.unicodedata for character properties if specified (e.g., `use_fonttools=True`). This allows flexibility for users who prefer fontTools’ data, particularly for writing system information like `script` or `block`. For example:
```python
category = uicu.get_category('A', use_fonttools=True)  # Uses fontTools.unicodedata
```

## 6. Performance Considerations
- **Minimize Overhead**: Wrapper functions should call PyICU methods directly, avoiding multiple layers of abstraction.
- **Caching**: Cache frequently used objects (e.g., `Normalizer2` instances) to reduce initialization costs.
- **Native Types**: Use Python `str` for inputs and outputs where possible to avoid conversion overhead.
- **Profiling**: Test performance against PyICU to ensure minimal slowdown, using tools like `cProfile`.

## 7. Documentation Standards
- **Docstrings**: Follow Google Python Style Guide for docstrings, including Args, Returns, and Examples.
- **Type Hints**: Use type hints for all functions and methods (e.g., `str`, `List[str]`).
- **Examples**: Include practical examples in docstrings and a separate `examples/` directory.
- **Tutorials**: Provide tutorials in the documentation, built with [Sphinx](https://www.sphinx-doc.org/).
- **References**: Link to ICU documentation for advanced details.

## 8. Implementation Guidelines
- **Dependencies**: Require `PyICU>=2.8` and optionally `fonttools[unicodedata]>=4.38.0`.
- **Testing**: Use `pytest` with unit tests covering all functions and edge cases.
- **Error Handling**: Convert ICU error codes to Python exceptions with descriptive messages.
- **Packaging**: Use `setuptools` for distribution, with clear metadata in `setup.py`.
- **Versioning**: Follow Semantic Versioning (e.g., `0.1.0` for initial release).

## 9. Example Usage
```python
import uicu
from datetime import datetime

# Normalize a string
text = "café"
normalized = uicu.normalize(text, 'NFD')

# Format a date
formatted_date = uicu.format_date(datetime.now(), locale='fr_FR', pattern='d MMM y')

# Sort strings with locale-aware collation
strings = ['café', 'cafe']
sorted_strings = uicu.sorted(strings, locale='fr_FR')

# Transliterate text
transliterated = uicu.transliterate("привет", "Cyrillic-Latin")

# Get character properties
category = uicu.get_category('A')  # Returns 'Lu'
```

## 10. Next Steps
1. **Prototype**: Implement core modules (`unicode`, `locale`, `format`) with basic functionality.
2. **Testing**: Write unit tests to verify correctness against PyICU.
3. **Documentation**: Generate initial Sphinx documentation with examples.
4. **Performance Testing**: Profile key functions to ensure minimal overhead.
5. **Community Feedback**: Release a beta version on [PyPI](https://pypi.org/) and gather feedback.

This specification provides a clear roadmap for developing `uicu`, balancing Pythonic design, performance, and comprehensive functionality.
</file>

<file path="research/res-phind.md">
Below is a detailed specification document for the new **`uicu`** package. This spec outlines design goals, module and API structure, integration strategies, error handling, testing guidelines, and documentation conventions. It is written so that a junior developer can follow it step by step to develop the package.

---

# uicu Package Specification

The **`uicu`** package is intended to be a comprehensive, natural, and pythonic API for ICU functionality. It serves as a wrapper around [PyICU](https://pypi.org/project/pyicu/) and supplements any necessary APIs from [fontTools.unicodedata](https://fonttools.readthedocs.io/en/latest/unicodedata/index.html) or the updated [unicodedata2](https://github.com/fonttools/unicodedata2) project. The package will provide rich objects that naturally integrate with Python’s native Unicode types while exposing advanced and performant ICU operations.

---

## 1. Overview and Goals

- **Primary Goal:**  
  Build a pythonic and extensive API for ICU functionality that seamlessly wraps PyICU. The API aims to simplify and enhance the standard ICU features (localization, date and time formatting, Unicode normalization, and more) in a way that leverages Python’s strengths.

- **Key Objectives:**
  - **Pythonic Interface:** Hide low-level ICU details (such as error-code handling and non-native string types) behind a natural interface that works well with Python’s native types.
  - **Rich Typing:** Provide well-documented objects and methods for locales, text formats, time zones, and Unicode data.
  - **Performance:** Wrap the PyICU (C++ based) backend so that performance remains a priority.
  - **Extensibility:** Offer integration points to supplement ICU functionality with advanced Unicode lookup (using fontTools.unicodedata, unicodedata2, or even Python’s builtin unicodedata where applicable).
  - **Error Simplification:** Automatically manage ICU error codes and exceptions by translating them into standard Python exceptions.

---

## 2. Dependencies

- **PyICU:**  
  This is the underlying binding to the ICU C++ API.  
  > *Installation:* `pip install pyicu`

- **FontTools.unicodedata (or unicodedata2):**  
  To provide extra Unicode character data and support for writing systems, fall back on fontTools’ functionalities where needed.

- **Optional:**  
  Python’s built-in [unicodedata](https://docs.python.org/3/library/unicodedata.html) module for additional compatibility utilities.

---

## 3. Package Architecture and Module Layout

To keep the code maintainable, organize **`uicu`** into several modules:

- **`uicu/core.py`:**  
  Core implementations and helpers – low-level wrappers around PyICU objects, type conversions, and common utilities.

- **`uicu/locale.py`:**  
  Provides a pythonic `Locale` class which wraps ICU’s Locale. Include methods that convert ICU data (e.g. display names) into native Python strings.

- **`uicu/formatting.py`:**  
  Contains wrappers for ICU’s date/time formatting APIs. Offers classes like `DateFormat` with methods that accept Python numbers and `datetime` objects.

- **`uicu/unicode.py`:**  
  Provides Unicode-related functionalities, including normalization, lookup, and other text processing utilities:
  - A `UnicodeString` class that mimics a Python string while wrapping ICU’s mutable `UnicodeString`.
  - Functions such as `normalize(form, unistr)`, mirroring ICU’s normalization forms (NFC, NFKC, NFD, NFKD).

- **`uicu/timezone.py`:**  
  Implements time zone related helpers, including a wrapper type (`ICUtzinfo`) that implements Python’s `tzinfo` interface by wrapping ICU’s TimeZone object.

- **`uicu/errors.py`:**  
  Defines exception classes (e.g. `UICUError`) that wrap ICU errors. All errors from lower-level ICU calls will be caught and re-raised as these exceptions.

- **`uicu/data.py`:**  
  Optional module to integrate extra Unicode data (e.g. via fontTools.unicodedata) for enhanced support of writing systems, property lookups, and extended normalization if needed.

- **`uicu/utils.py`:**  
  Utilities for common tasks (e.g. caching lookups, conversion helpers between ICU and Python types).

---

## 4. API Design and Object Specifications

Below is an outline of the key objects and functions exposed by **`uicu`**:

### 4.1. Exceptions

- **`uicu.errors.UICUError(Exception)`**  
  - Base exception for all errors in the package.
  - Wraps ICU error codes and messages.

### 4.2. Locale

- **`uicu.locale.Locale`**
  - **Constructor:**  
    `Locale(identifier: str) → Locale`  
    Uses ICU’s locale constructor. The identifier can be in the form `"en_US"`, `"pt_BR"`, etc.
  - **Methods/Properties:**
    - `get_display_name() -> str`: Returns the locale’s display name using ICU under the hood.
    - `language: str`: Property to get the ISO language.
    - `country: str`: Property to get the country code.
    - `variant: Optional[str]`: If applicable.
  - **Examples:**
    ```python
    from uicu.locale import Locale

    loc = Locale("pt_BR")
    print(loc.get_display_name())  # "Portuguese (Brazil)"
    print(loc.language)  # "pt"
    ```

### 4.3. UnicodeString

- **`uicu.unicode.UnicodeString`**
  - **Description:**  
    A wrapper around ICU’s mutable `UnicodeString` that behaves similar to Python’s native string. Internally it will accept Python `str` in its constructors.
  - **Constructor:**  
    `UnicodeString(s: Union[str, ICU_UnicodeString]= "")`
  - **Methods/Operators:**
    - `__str__() -> str`: Converts the UnicodeString to a native Python string.
    - `__getitem__() and __setitem__()`: Provide slicing and indexing (note that slicing might return a new UnicodeString, as ICU slicing conventions differ).
    - `__iadd__()`: Support for in-place concatenation (`+=`).
    - Additional helper methods: `.to_upper()`, `.to_lower()`, etc.
  - **Usage Example:**
    ```python
    from uicu.unicode import UnicodeString

    ustr = UnicodeString("Café")
    print(str(ustr))  # "Café"
    ustr += " au lait"
    print(ustr)  # "Café au lait"
    ```

### 4.4. Normalization Functions

- **`uicu.unicode.normalize(form: str, unistr: Union[str, UnicodeString]) -> str`**
  - **Supported Forms:** `'NFC'`, `'NFD'`, `'NFKC'`, `'NFKD'`.
  - **Behavior:**  
    Converts the input (either a Python `str` or a `UnicodeString`) into the specified normalized form, utilizing ICU’s normalization functionality.
  - **Example:**
    ```python
    from uicu.unicode import normalize

    normalized = normalize("NFC", "Café")
    print(normalized)
    ```

- **`uicu.unicode.is_normalized(form: str, unistr: Union[str, UnicodeString]) -> bool`**  
  Returns whether a given string is in the specified normalized form.

### 4.5. Date and Time Formatting

- **`uicu.formatting.DateFormat`**
  - **Factory Method(s):**
    - `create_instance(locale: Union[str, Locale] = None) -> DateFormat`
      - Creates a date/time formatter instance. If no locale is provided, use the default.
  - **Methods:**
    - `format(date_value: Union[float, int, datetime, Formattable]) -> str`
      - Accepts numeric values, Python’s `datetime` objects, or ICU-specific Formattable objects. It automatically converts between Python’s time conventions (seconds since epoch) and ICU’s milliseconds.
    - `parse(text: str) -> datetime`
      - Converts formatted date strings back to Python’s `datetime`.
  - **Example:**
    ```python
    from uicu.formatting import DateFormat
    from datetime import datetime

    df = DateFormat.create_instance("en_US")
    now = datetime.now()
    formatted = df.format(now)
    print(formatted)   # e.g., "10/18/23 3:04 PM"
    parsed_date = df.parse(formatted)
    ```

### 4.6. Time Zone Handling

- **`uicu.timezone.ICUtzinfo`**
  - **Purpose:**  
    Provide a class that wraps ICU’s TimeZone and implements Python’s `tzinfo` interface.
  - **Class Methods:**
    - `get_instance(tz_id: str) -> ICUtzinfo`: Returns an instance for the given time zone identifier.
    - `get_default() -> ICUtzinfo`: Returns the system default time zone.
  - **Usage:**
    ```python
    from datetime import datetime
    from uicu.timezone import ICUtzinfo

    tz = ICUtzinfo.get_instance("Pacific/Fiji")
    now = datetime.now(tz)
    print(now)
    ```

### 4.7. Unicode Data / Character Properties

- **`uicu.data.UnicodeData`**
  - **Methods:**
    - `lookup(name: str) -> str`: Look up a Unicode character by its name.
    - `name(char: str, default: Optional[str] = None) -> str`: Return the Unicode name for the given character.
    - `category(char: str) -> str`: Return the general category.
    - `digit(char: str, default: Optional[int]=None) -> int`
    - `decimal(char: str, default: Optional[int]=None) -> int`
    - `numeric(char: str, default: Optional[float]=None) -> float`
  - **Integration Strategy:**  
    This module can either simply proxy calls to Python’s built-in `unicodedata`–or use the more up-to-date fontTools.unicodedata2 as needed. It should provide a single, unified API.

---

## 5. Design Patterns and Conventions

- **Type Coercion & Conversion:**  
  Every method that interacts with ICU’s native types should accept Python’s native types as input (e.g. Python `str` for text for Unicode functions, and Python’s `datetime` or numbers for date/time). Internally, conversion happens so that the PyICU APIs’ requirements are met.

- **Error Handling:**  
  All ICU calls are wrapped in try…except constructs. Instead of dealing with ICU’s `UErrorCode` semantics, our helper functions catch these and raise clean, understandable (`UICUError`) exceptions.

- **Immutable versus Mutable:**  
  Decide clearly on mutable wrappers (e.g. for `UnicodeString`) vs immutable conversions. Document the behavior so that developers know if operations return new objects or modify in place.

- **Naming and Documentation:**  
  Use clear, Pythonic naming conventions. Every public class or function should have a docstring that explains its parameters, return values, and sample usage. Provide inline comments when wrapping lower-level interfaces.

- **Testing / Examples:**  
  For each module, create a corresponding file in a `tests/` directory. Include unit tests covering:
  - Correct conversion between ICU and Python types.
  - Error handling and exception propagation.
  - Cross-platform behavior (especially for timezone and locale handling).

---

## 6. Development and Packaging Guidelines

- **Source Control:**  
  Use Git. Organize commits by feature (Locale, Unicode, Formatting, etc.). Ensure each commit is small and passes tests.

- **Setup and Installation:**  
  - Use a `setup.py` (or the modern `pyproject.toml` and `setuptools` configuration) to declare dependencies (PyICU, fontTools.unicodedata2 if needed).
  - Include instructions in the README for obtaining and configuring ICU libraries on different systems (like PyICU’s guidelines).

- **Documentation:**  
  Write comprehensive documentation using Markdown and host it on ReadTheDocs. Use Sphinx with autodoc extensions to further generate API documentation from the docstrings.

- **Continuous Integration:**  
  Set up CI (for example, GitHub Actions) to run your test suite automatically on different Python versions and platforms.

---

## 7. Example Usage in an Application

Here is an example script demonstrating how a user would benefit from **`uicu`**:

```python
from datetime import datetime
from uicu.locale import Locale
from uicu.formatting import DateFormat
from uicu.unicode import UnicodeString, normalize
from uicu.timezone import ICUtzinfo
from uicu.data import UnicodeData

# Locale usage
locale = Locale("en_US")
print("Locale Display:", locale.get_display_name())

# DateFormat usage
df = DateFormat.create_instance(locale)
now = datetime.now(ICUtzinfo.get_instance("America/New_York"))
print("Formatted Date:", df.format(now))

# UnicodeString and normalization
ustr = UnicodeString("Café")
print("Original:", str(ustr))
print("Normalized NFC:", normalize("NFC", ustr))
ustr += " – Enjoy!"
print("Concatenated:", str(ustr))

# Unicode data lookup
try:
    char = UnicodeData.lookup("LEFT CURLY BRACKET")
    print("Lookup:", char)
except KeyError:
    print("Character not found")
```

---

## 8. Final Checklist

- [ ] **Define core abstractions** (Locale, UnicodeString, DateFormat, ICUtzinfo, UnicodeData) with clear API contracts.  
- [ ] **Implement type conversion helpers** in `uicu/core.py` and `uicu/utils.py`.  
- [ ] **Wrap ICU error codes** into a custom error (`UICUError` in `uicu/errors.py`).  
- [ ] **Integrate (if needed) fontTools.unicodedata** functions in `uicu/data.py` with fallbacks to Python’s `unicodedata`.  
- [ ] **Write unit tests** for every module (each function, method, and error condition).  
- [ ] **Document all public-facing interfaces** with examples and docstrings.  
- [ ] **Package the library** using setuptools/pyproject.toml and add a README with installation instructions and usage examples.  
- [ ] **Set up CI/CD integration** for automated testing across platforms and Python versions.

---

By following this detailed specification, you will create the **`uicu`** package—a highly usable, pythonic, and comprehensive interface to the powerful ICU libraries for Unicode and internationalization support.
</file>

<file path="AGENTS.md">
## Project Overview

`uicu` is a Python package that aims to create a pythonic wrapper around PyICU, supplemented by fontTools.unicodedata. The goal is to provide a natural, performant API that exposes rich, well-documented objects integrating with Python's native Unicode handling while adding extensive Unicode functionality.

## Development Commands

### Environment Setup
```bash
# Install and use uv for package management
pip install uv
# Use hatch for development workflow
uv pip install hatch
```

### Common Development Tasks
```bash
# Activate development environment
hatch shell

# Run tests
hatch run test
python -m pytest

# Run tests with coverage
hatch run test-cov

# Run linting
hatch run lint

# Format code
hatch run format

# Run type checking
hatch run type-check

# After Python changes, run the full formatting pipeline:
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

## Code Architecture

### Project Structure
- **src/uicu/**: Main package source (using src-layout)
  - `__init__.py`: Package initialization
  - `__version__.py`: Version management using hatch-vcs
  - `uicu.py`: Main module (currently skeleton)
- **tests/**: Test suite using pytest
- **pyproject.toml**: PEP 621 compliant project configuration

### Key Dependencies to Research
- **PyICU**: The main Unicode library to wrap
- **fontTools.unicodedata**: Supplementary Unicode data with writing system info

## Development Guidelines

### Python-Specific Rules
- Use `uv pip` instead of `pip`
- Always use `python -m` when running modules
- Use type hints in simple form (list, dict, | for unions)
- Add verbose loguru-based logging and debug-log
- For CLI scripts, use fire & rich libraries
- Scripts should start with `#!/usr/bin/env -S uv run -s`

### Code Quality Standards
- PEP 8 compliant (enforced by Ruff)
- Clear, imperative docstrings (PEP 257)
- Use f-strings for formatting
- Structural pattern matching where appropriate
- Maintain `this_file` comments at the top of each source file

### Development Workflow
1. Create/update `PLAN.md` with detailed flat plan using `[ ]` items
2. Identify important TODOs and update `TODO.md`
3. Implement changes incrementally
4. Update `CHANGELOG.md` after each round of changes
5. Update `README.md` to reflect changes
6. Run the formatting pipeline after Python changes

### Current Project Status
- Initial project structure created
- Main objective: Create pythonic wrapper around PyICU
- First task: Research and document APIs from fontTools.unicodedata and PyICU
- Implementation phase not yet started

## Testing Strategy
- pytest with coverage tracking
- Use pytest-xdist for parallel test execution
- pytest-benchmark for performance testing
- Maintain high test coverage for all new functionality

## Key Principles
- Iterate gradually, avoiding major changes
- Preserve existing code/structure unless necessary
- Write explanatory docstrings that explain what and WHY
- Handle failures gracefully with retries and fallbacks
- Focus on minimal viable increments
- Keep code simple and explicit (PEP 20)

# When you write code

- Iterate gradually, avoiding major changes
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Use constants over magic numbers
- Check for existing solutions in the codebase before starting
- Check often the coherence of the code you're writing with the rest of the code.
- Focus on minimal viable increments and ship early
- Write explanatory docstrings/comments that explain what and WHY this does, explain where and how the code is used/referred to elsewhere in the code
- Analyze code line-by-line
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures
- Consistently keep, document, update and consult the holistic overview mental image of the codebase. 

## Keep track of paths

In each source file, maintain the up-to-date `this_file` record that shows the path of the current file relative to project root. Place the `this_file` record near the top of the file, as a comment after the shebangs, or in the YAML Markdown frontmatter.

## When you write Python

- Use `uv pip`, never `pip`
- Use `python -m` when running code
- PEP 8: Use consistent formatting and naming
- Write clear, descriptive names for functions and variables
- PEP 20: Keep code simple and explicit. Prioritize readability over cleverness
- Use type hints in their simplest form (list, dict, | for unions)
- PEP 257: Write clear, imperative docstrings
- Use f-strings. Use structural pattern matching where appropriate
- ALWAYS add "verbose" mode logugu-based logging, & debug-log
- For CLI Python scripts, use fire & rich, and start the script with

```
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

Work in rounds: 

- Create `PLAN.md` as a detailed flat plan with `[ ]` items. 
- Identify the most important TODO items, and create `TODO.md` with `[ ]` items. 
- Implement the changes. 
- Update `PLAN.md` and `TODO.md` as you go. 
- After each round of changes, update `CHANGELOG.md` with the changes.
- Update `README.md` to reflect the changes.

Ask before extending/refactoring existing code in a way that may add complexity or break things.

When you're finished, print "Wait, but" to go back, think & reflect, revise & improvement what you've done (but don't invent functionality freely). Repeat this. But stick to the goal of "minimal viable next version". Lead two experts: "Ideot" for creative, unorthodox ideas, and "Critin" to critique flawed thinking and moderate for balanced discussions. The three of you shall illuminate knowledge with concise, beautiful responses, process methodically for clear answers, collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

## After Python changes run:

```
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

Be creative, diligent, critical, relentless & funny!

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


`uicu` is a specialized Python package that creates a Pythonic wrapper around PyICU with supplementary Unicode functionality from fontTools.unicodedata. The core business logic revolves around providing rich Unicode data manipulation capabilities through well-documented objects.

## Core Business Components

1. Unicode Data Processing (90)
- Custom wrapper around PyICU providing intuitive Unicode manipulation
- Integration with fontTools.unicodedata for writing system information
- Domain-specific data validation and transformation rules
Location: `src/uicu/uicu.py`

2. Supplementary Unicode Features (85)
- Extended Unicode functionality beyond Python's native capabilities
- Writing system detection and classification
- Custom normalization and decomposition rules
Location: `src/uicu/uicu.py`

3. Unicode Validation Framework (75)
- Custom validation rules for Unicode data integrity
- Error handling specific to Unicode processing
- Fallback mechanisms for unsupported characters
Location: `src/uicu/uicu.py`

## Integration Architecture

The package implements a layered approach to Unicode processing:

1. Base Layer: PyICU Integration
- Direct wrapping of PyICU functionality
- Custom error handling and retry logic
Location: `src/uicu/uicu.py`

2. Enhancement Layer: fontTools Integration
- Additional Unicode metadata and writing system support
- Custom data enrichment rules
Location: `src/uicu/uicu.py`

3. Application Layer: Pythonic Interface
- Natural Python API for Unicode operations
- Rich object model with extensive Unicode properties
Location: `src/uicu/uicu.py`

## Development Workflow

The project follows an iterative development approach with:
- Detailed planning in `PLAN.md`
- Task tracking in `TODO.md`
- Change documentation in `CHANGELOG.md`
- Updated documentation in `README.md`

$END$
</file>

<file path="build.sh">
#!/usr/bin/env bash
npx repomix -o llms.txt .
</file>

<file path="TODO.md">
## Objective

PyICU does not have a very pythonic API. I’d like us to make `uicu`, a very extensive, but mainly a natural, pythonic yet performant API (wrapper around PyICU), supplemented by fontTools.unicodedata if needed. The uciu API should expose rich, well-documented objects that naturally integrate with Python’s native Unicode but also expose rich additional functionality.

## Task 1

Research and meticulously document the various APIs supported by these packages

- https://fonttools.readthedocs.io/en/latest/unicodedata/index.html which includes info about writing systems but otherwise is based on https://github.com/fonttools/unicodedata2 which is like https://docs.python.org/3/library/unicodedata.html but uptodate
- https://pypi.org/project/pyicu/

Think, consult widely, and then make a very detailed, considerate plan for this new `uicu` package. Write a detailed spec that will guide a junior developer by hand allowing her to develop `uric`
</file>

<file path=".github/workflows/push.yml">
name: Build & Test

on:
  push:
    branches: [main]
    tags-ignore: ["v*"]
  pull_request:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: write
  id-token: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run Ruff lint
        uses: astral-sh/ruff-action@v3
        with:
          version: "latest"
          args: "check --output-format=github"

      - name: Run Ruff Format
        uses: astral-sh/ruff-action@v3
        with:
          version: "latest"
          args: "format --check --respect-gitignore"

  test:
    name: Run Tests
    needs: quality
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
        os: [ubuntu-latest]
      fail-fast: true
    runs-on: ${{ matrix.os }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: ${{ matrix.python-version }}
          enable-cache: true
          cache-suffix: ${{ matrix.os }}-${{ matrix.python-version }}

      - name: Install test dependencies
        run: |
          uv pip install --system --upgrade pip
          uv pip install --system ".[test]"

      - name: Run tests with Pytest
        run: uv run pytest -n auto --maxfail=1 --disable-warnings --cov-report=xml --cov-config=pyproject.toml --cov=src/uicu --cov=tests tests/

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.python-version }}-${{ matrix.os }}
          path: coverage.xml

  build:
    name: Build Distribution
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: "3.12"
          enable-cache: true

      - name: Install build tools
        run: uv pip install build hatchling hatch-vcs

      - name: Build distributions
        run: uv run python -m build --outdir dist

      - name: Upload distribution artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist-files
          path: dist/
          retention-days: 5
</file>

<file path=".github/workflows/release.yml">
name: Release

on:
  push:
    tags: ["v*"]

permissions:
  contents: write
  id-token: write

jobs:
  release:
    name: Release to PyPI
    runs-on: ubuntu-latest
    environment:
      name: pypi
      url: https://pypi.org/p/uicu
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: "3.12"
          enable-cache: true

      - name: Install build tools
        run: uv pip install build hatchling hatch-vcs

      - name: Build distributions
        run: uv run python -m build --outdir dist

      - name: Verify distribution files
        run: |
          ls -la dist/
          test -n "$(find dist -name '*.whl')" || (echo "Wheel file missing" && exit 1)
          test -n "$(find dist -name '*.tar.gz')" || (echo "Source distribution missing" && exit 1)

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          password: ${{ secrets.PYPI_TOKEN }}

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          files: dist/*
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
</file>

<file path="src/uicu/uicu.py">
#!/usr/bin/env python3
"""uicu: 

Created by Adam Twardoch
"""

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Union
import logging

__version__ = "0.1.0"

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class Config:
    """Configuration settings for uicu."""
    name: str
    value: Union[str, int, float]
    options: Optional[Dict[str, Any]] = None


def process_data(
    data: List[Any],
    config: Optional[Config] = None,
    *,
    debug: bool = False
) -> Dict[str, Any]:
    """Process the input data according to configuration.
    
    Args:
        data: Input data to process
        config: Optional configuration settings
        debug: Enable debug mode
        
    Returns:
        Processed data as a dictionary
        
    Raises:
        ValueError: If input data is invalid
    """
    if debug:
        logger.setLevel(logging.DEBUG)
        logger.debug("Debug mode enabled")
        
    if not data:
        raise ValueError("Input data cannot be empty")
        
    # TODO: Implement data processing logic
    result: Dict[str, Any] = {}
    return result


def main() -> None:
    """Main entry point for uicu."""
    try:
        # Example usage
        config = Config(
            name="default",
            value="test",
            options={"key": "value"}
        )
        result = process_data([], config=config)
        logger.info("Processing completed: %s", result)
        
    except Exception as e:
        logger.error("An error occurred: %s", str(e))
        raise


if __name__ == "__main__":
    main()
</file>

<file path="tests/test_package.py">
"""Test suite for uicu."""

def test_version():
    """Verify package exposes version."""
    import uicu
    assert uicu.__version__
</file>

<file path=".cursorrules">
## Project Overview

`uicu` is a Python package that aims to create a pythonic wrapper around PyICU, supplemented by fontTools.unicodedata. The goal is to provide a natural, performant API that exposes rich, well-documented objects integrating with Python's native Unicode handling while adding extensive Unicode functionality.

## Development Commands

### Environment Setup
```bash
# Install and use uv for package management
pip install uv
# Use hatch for development workflow
uv pip install hatch
```

### Common Development Tasks
```bash
# Activate development environment
hatch shell

# Run tests
hatch run test
python -m pytest

# Run tests with coverage
hatch run test-cov

# Run linting
hatch run lint

# Format code
hatch run format

# Run type checking
hatch run type-check

# After Python changes, run the full formatting pipeline:
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

## Code Architecture

### Project Structure
- **src/uicu/**: Main package source (using src-layout)
  - `__init__.py`: Package initialization
  - `__version__.py`: Version management using hatch-vcs
  - `uicu.py`: Main module (currently skeleton)
- **tests/**: Test suite using pytest
- **pyproject.toml**: PEP 621 compliant project configuration

### Key Dependencies to Research
- **PyICU**: The main Unicode library to wrap
- **fontTools.unicodedata**: Supplementary Unicode data with writing system info

## Development Guidelines

### Python-Specific Rules
- Use `uv pip` instead of `pip`
- Always use `python -m` when running modules
- Use type hints in simple form (list, dict, | for unions)
- Add verbose loguru-based logging and debug-log
- For CLI scripts, use fire & rich libraries
- Scripts should start with `#!/usr/bin/env -S uv run -s`

### Code Quality Standards
- PEP 8 compliant (enforced by Ruff)
- Clear, imperative docstrings (PEP 257)
- Use f-strings for formatting
- Structural pattern matching where appropriate
- Maintain `this_file` comments at the top of each source file

### Development Workflow
1. Create/update `PLAN.md` with detailed flat plan using `[ ]` items
2. Identify important TODOs and update `TODO.md`
3. Implement changes incrementally
4. Update `CHANGELOG.md` after each round of changes
5. Update `README.md` to reflect changes
6. Run the formatting pipeline after Python changes

### Current Project Status
- Initial project structure created
- Main objective: Create pythonic wrapper around PyICU
- First task: Research and document APIs from fontTools.unicodedata and PyICU
- Implementation phase not yet started

## Testing Strategy
- pytest with coverage tracking
- Use pytest-xdist for parallel test execution
- pytest-benchmark for performance testing
- Maintain high test coverage for all new functionality

## Key Principles
- Iterate gradually, avoiding major changes
- Preserve existing code/structure unless necessary
- Write explanatory docstrings that explain what and WHY
- Handle failures gracefully with retries and fallbacks
- Focus on minimal viable increments
- Keep code simple and explicit (PEP 20)

# When you write code

- Iterate gradually, avoiding major changes
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Use constants over magic numbers
- Check for existing solutions in the codebase before starting
- Check often the coherence of the code you're writing with the rest of the code.
- Focus on minimal viable increments and ship early
- Write explanatory docstrings/comments that explain what and WHY this does, explain where and how the code is used/referred to elsewhere in the code
- Analyze code line-by-line
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures
- Consistently keep, document, update and consult the holistic overview mental image of the codebase. 

## Keep track of paths

In each source file, maintain the up-to-date `this_file` record that shows the path of the current file relative to project root. Place the `this_file` record near the top of the file, as a comment after the shebangs, or in the YAML Markdown frontmatter.

## When you write Python

- Use `uv pip`, never `pip`
- Use `python -m` when running code
- PEP 8: Use consistent formatting and naming
- Write clear, descriptive names for functions and variables
- PEP 20: Keep code simple and explicit. Prioritize readability over cleverness
- Use type hints in their simplest form (list, dict, | for unions)
- PEP 257: Write clear, imperative docstrings
- Use f-strings. Use structural pattern matching where appropriate
- ALWAYS add "verbose" mode logugu-based logging, & debug-log
- For CLI Python scripts, use fire & rich, and start the script with

```
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

Work in rounds: 

- Create `PLAN.md` as a detailed flat plan with `[ ]` items. 
- Identify the most important TODO items, and create `TODO.md` with `[ ]` items. 
- Implement the changes. 
- Update `PLAN.md` and `TODO.md` as you go. 
- After each round of changes, update `CHANGELOG.md` with the changes.
- Update `README.md` to reflect the changes.

Ask before extending/refactoring existing code in a way that may add complexity or break things.

When you're finished, print "Wait, but" to go back, think & reflect, revise & improvement what you've done (but don't invent functionality freely). Repeat this. But stick to the goal of "minimal viable next version". Lead two experts: "Ideot" for creative, unorthodox ideas, and "Critin" to critique flawed thinking and moderate for balanced discussions. The three of you shall illuminate knowledge with concise, beautiful responses, process methodically for clear answers, collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

## After Python changes run:

```
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

Be creative, diligent, critical, relentless & funny!

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


`uicu` is a specialized Python package that creates a Pythonic wrapper around PyICU with supplementary Unicode functionality from fontTools.unicodedata. The core business logic revolves around providing rich Unicode data manipulation capabilities through well-documented objects.

## Core Business Components

1. Unicode Data Processing (90)
- Custom wrapper around PyICU providing intuitive Unicode manipulation
- Integration with fontTools.unicodedata for writing system information
- Domain-specific data validation and transformation rules
Location: `src/uicu/uicu.py`

2. Supplementary Unicode Features (85)
- Extended Unicode functionality beyond Python's native capabilities
- Writing system detection and classification
- Custom normalization and decomposition rules
Location: `src/uicu/uicu.py`

3. Unicode Validation Framework (75)
- Custom validation rules for Unicode data integrity
- Error handling specific to Unicode processing
- Fallback mechanisms for unsupported characters
Location: `src/uicu/uicu.py`

## Integration Architecture

The package implements a layered approach to Unicode processing:

1. Base Layer: PyICU Integration
- Direct wrapping of PyICU functionality
- Custom error handling and retry logic
Location: `src/uicu/uicu.py`

2. Enhancement Layer: fontTools Integration
- Additional Unicode metadata and writing system support
- Custom data enrichment rules
Location: `src/uicu/uicu.py`

3. Application Layer: Pythonic Interface
- Natural Python API for Unicode operations
- Rich object model with extensive Unicode properties
Location: `src/uicu/uicu.py`

## Development Workflow

The project follows an iterative development approach with:
- Detailed planning in `PLAN.md`
- Task tracking in `TODO.md`
- Change documentation in `CHANGELOG.md`
- Updated documentation in `README.md`

$END$
</file>

<file path=".gitignore">
*_autogen/
.DS_Store
__version__.py
__pycache__/
_Chutzpah*
_deps
_NCrunch_*
_pkginfo.txt
_Pvt_Extensions
_ReSharper*/
_TeamCity*
_UpgradeReport_Files/
!?*.[Cc]ache/
!.axoCover/settings.json
!.vscode/extensions.json
!.vscode/launch.json
!.vscode/settings.json
!.vscode/tasks.json
!**/[Pp]ackages/build/
!Directory.Build.rsp
.*crunch*.local.xml
.axoCover/*
.builds
.cr/personal
.fake/
.history/
.ionide/
.localhistory/
.mfractor/
.ntvs_analysis.dat
.paket/paket.exe
.sass-cache/
.vs/
.vscode
.vscode/*
.vshistory/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
[Bb]in/
[Bb]uild[Ll]og.*
[Dd]ebug/
[Dd]ebugPS/
[Dd]ebugPublic/
[Ee]xpress/
[Ll]og/
[Ll]ogs/
[Oo]bj/
[Rr]elease/
[Rr]eleasePS/
[Rr]eleases/
[Tt]est[Rr]esult*/
[Ww][Ii][Nn]32/
*_h.h
*_i.c
*_p.c
*_wpftmp.csproj
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl
*- [Bb]ackup.rdl
*.[Cc]ache
*.[Pp]ublish.xml
*.[Rr]e[Ss]harper
*.a
*.app
*.appx
*.appxbundle
*.appxupload
*.aps
*.azurePubxml
*.bim_*.settings
*.bim.layout
*.binlog
*.btm.cs
*.btp.cs
*.build.csdef
*.cab
*.cachefile
*.code-workspace
*.coverage
*.coveragexml
*.d
*.dbmdl
*.dbproj.schemaview
*.dll
*.dotCover
*.DotSettings.user
*.dsp
*.dsw
*.dylib
*.e2e
*.exe
*.gch
*.GhostDoc.xml
*.gpState
*.ilk
*.iobj
*.ipdb
*.jfm
*.jmconfig
*.la
*.lai
*.ldf
*.lib
*.lo
*.log
*.mdf
*.meta
*.mm.*
*.mod
*.msi
*.msix
*.msm
*.msp
*.ncb
*.ndf
*.nuget.props
*.nuget.targets
*.nupkg
*.nvuser
*.o
*.obj
*.odx.cs
*.opendb
*.opensdf
*.opt
*.out
*.pch
*.pdb
*.pfx
*.pgc
*.pgd
*.pidb
*.plg
*.psess
*.publishproj
*.publishsettings
*.pubxml
*.pyc
*.rdl.data
*.rptproj.bak
*.rptproj.rsuser
*.rsp
*.rsuser
*.sap
*.sbr
*.scc
*.sdf
*.sln.docstates
*.sln.iml
*.slo
*.smod
*.snupkg
*.so
*.suo
*.svclog
*.tlb
*.tlh
*.tli
*.tlog
*.tmp
*.tmp_proj
*.tss
*.user
*.userosscache
*.userprefs
*.vbp
*.vbw
*.VC.db
*.VC.VC.opendb
*.VisualState.xml
*.vsp
*.vspscc
*.vspx
*.vssscc
*.xsd.cs
**/[Pp]ackages/*
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.HTMLClient/GeneratedArtifacts
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
*~
~$*
$tf/
AppPackages/
artifacts/
ASALocalRun/
AutoTest.Net/
Backup*/
BenchmarkDotNet.Artifacts/
bld/
BundleArtifacts/
ClientBin/
cmake_install.cmake
CMakeCache.txt
CMakeFiles
CMakeLists.txt.user
CMakeScripts
CMakeUserPresets.json
compile_commands.json
coverage*.info
coverage*.json
coverage*.xml
csx/
CTestTestfile.cmake
dlldata.c
DocProject/buildhelp/
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/*.HxC
DocProject/Help/*.HxT
DocProject/Help/html
DocProject/Help/Html2
ecf/
FakesAssemblies/
FodyWeavers.xsd
Generated_Code/
Generated\ Files/
healthchecksdb
install_manifest.txt
ipch/
Makefile
MigrationBackup/
mono_crash.*
nCrunchTemp_*
node_modules/
nunit-*.xml
OpenCover/
orleans.codegen.cs
Package.StoreAssociation.xml
paket-files/
project.fragment.lock.json
project.lock.json
publish/
PublishScripts/
rcf/
ScaffoldingReadMe.txt
ServiceFabricBackup/
StyleCopReport.xml
Testing
TestResult.xml
UpgradeLog*.htm
UpgradeLog*.XML
x64/
x86/
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Distribution / packaging
!dist/.gitkeep

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/
.ruff_cache/

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDE
.idea/
.vscode/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Project specific
__version__.py
_private
VERSION.txt
</file>

<file path=".pre-commit-config.yaml">
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.3.4
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format
        args: [--respect-gitignore]
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: check-yaml
      - id: check-toml
      - id: check-added-large-files
      - id: debug-statements
      - id: check-case-conflict
      - id: mixed-line-ending
        args: [--fix=lf]
</file>

<file path="CLAUDE.md">
## Project Overview

`uicu` is a Python package that aims to create a pythonic wrapper around PyICU, supplemented by fontTools.unicodedata. The goal is to provide a natural, performant API that exposes rich, well-documented objects integrating with Python's native Unicode handling while adding extensive Unicode functionality.

## Development Commands

### Environment Setup
```bash
# Install and use uv for package management
pip install uv
# Use hatch for development workflow
uv pip install hatch
```

### Common Development Tasks
```bash
# Activate development environment
hatch shell

# Run tests
hatch run test
python -m pytest

# Run tests with coverage
hatch run test-cov

# Run linting
hatch run lint

# Format code
hatch run format

# Run type checking
hatch run type-check

# After Python changes, run the full formatting pipeline:
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

## Code Architecture

### Project Structure
- **src/uicu/**: Main package source (using src-layout)
  - `__init__.py`: Package initialization
  - `__version__.py`: Version management using hatch-vcs
  - `uicu.py`: Main module (currently skeleton)
- **tests/**: Test suite using pytest
- **pyproject.toml**: PEP 621 compliant project configuration

### Key Dependencies to Research
- **PyICU**: The main Unicode library to wrap
- **fontTools.unicodedata**: Supplementary Unicode data with writing system info

## Development Guidelines

### Python-Specific Rules
- Use `uv pip` instead of `pip`
- Always use `python -m` when running modules
- Use type hints in simple form (list, dict, | for unions)
- Add verbose loguru-based logging and debug-log
- For CLI scripts, use fire & rich libraries
- Scripts should start with `#!/usr/bin/env -S uv run -s`

### Code Quality Standards
- PEP 8 compliant (enforced by Ruff)
- Clear, imperative docstrings (PEP 257)
- Use f-strings for formatting
- Structural pattern matching where appropriate
- Maintain `this_file` comments at the top of each source file

### Development Workflow
1. Create/update `PLAN.md` with detailed flat plan using `[ ]` items
2. Identify important TODOs and update `TODO.md`
3. Implement changes incrementally
4. Update `CHANGELOG.md` after each round of changes
5. Update `README.md` to reflect changes
6. Run the formatting pipeline after Python changes

### Current Project Status
- Initial project structure created
- Main objective: Create pythonic wrapper around PyICU
- First task: Research and document APIs from fontTools.unicodedata and PyICU
- Implementation phase not yet started

## Testing Strategy
- pytest with coverage tracking
- Use pytest-xdist for parallel test execution
- pytest-benchmark for performance testing
- Maintain high test coverage for all new functionality

## Key Principles
- Iterate gradually, avoiding major changes
- Preserve existing code/structure unless necessary
- Write explanatory docstrings that explain what and WHY
- Handle failures gracefully with retries and fallbacks
- Focus on minimal viable increments
- Keep code simple and explicit (PEP 20)

# When you write code

- Iterate gradually, avoiding major changes
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Use constants over magic numbers
- Check for existing solutions in the codebase before starting
- Check often the coherence of the code you're writing with the rest of the code.
- Focus on minimal viable increments and ship early
- Write explanatory docstrings/comments that explain what and WHY this does, explain where and how the code is used/referred to elsewhere in the code
- Analyze code line-by-line
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures
- Consistently keep, document, update and consult the holistic overview mental image of the codebase. 

## Keep track of paths

In each source file, maintain the up-to-date `this_file` record that shows the path of the current file relative to project root. Place the `this_file` record near the top of the file, as a comment after the shebangs, or in the YAML Markdown frontmatter.

## When you write Python

- Use `uv pip`, never `pip`
- Use `python -m` when running code
- PEP 8: Use consistent formatting and naming
- Write clear, descriptive names for functions and variables
- PEP 20: Keep code simple and explicit. Prioritize readability over cleverness
- Use type hints in their simplest form (list, dict, | for unions)
- PEP 257: Write clear, imperative docstrings
- Use f-strings. Use structural pattern matching where appropriate
- ALWAYS add "verbose" mode logugu-based logging, & debug-log
- For CLI Python scripts, use fire & rich, and start the script with

```
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

Work in rounds: 

- Create `PLAN.md` as a detailed flat plan with `[ ]` items. 
- Identify the most important TODO items, and create `TODO.md` with `[ ]` items. 
- Implement the changes. 
- Update `PLAN.md` and `TODO.md` as you go. 
- After each round of changes, update `CHANGELOG.md` with the changes.
- Update `README.md` to reflect the changes.

Ask before extending/refactoring existing code in a way that may add complexity or break things.

When you're finished, print "Wait, but" to go back, think & reflect, revise & improvement what you've done (but don't invent functionality freely). Repeat this. But stick to the goal of "minimal viable next version". Lead two experts: "Ideot" for creative, unorthodox ideas, and "Critin" to critique flawed thinking and moderate for balanced discussions. The three of you shall illuminate knowledge with concise, beautiful responses, process methodically for clear answers, collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

## After Python changes run:

```
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

Be creative, diligent, critical, relentless & funny!

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


`uicu` is a specialized Python package that creates a Pythonic wrapper around PyICU with supplementary Unicode functionality from fontTools.unicodedata. The core business logic revolves around providing rich Unicode data manipulation capabilities through well-documented objects.

## Core Business Components

1. Unicode Data Processing (90)
- Custom wrapper around PyICU providing intuitive Unicode manipulation
- Integration with fontTools.unicodedata for writing system information
- Domain-specific data validation and transformation rules
Location: `src/uicu/uicu.py`

2. Supplementary Unicode Features (85)
- Extended Unicode functionality beyond Python's native capabilities
- Writing system detection and classification
- Custom normalization and decomposition rules
Location: `src/uicu/uicu.py`

3. Unicode Validation Framework (75)
- Custom validation rules for Unicode data integrity
- Error handling specific to Unicode processing
- Fallback mechanisms for unsupported characters
Location: `src/uicu/uicu.py`

## Integration Architecture

The package implements a layered approach to Unicode processing:

1. Base Layer: PyICU Integration
- Direct wrapping of PyICU functionality
- Custom error handling and retry logic
Location: `src/uicu/uicu.py`

2. Enhancement Layer: fontTools Integration
- Additional Unicode metadata and writing system support
- Custom data enrichment rules
Location: `src/uicu/uicu.py`

3. Application Layer: Pythonic Interface
- Natural Python API for Unicode operations
- Rich object model with extensive Unicode properties
Location: `src/uicu/uicu.py`

## Development Workflow

The project follows an iterative development approach with:
- Detailed planning in `PLAN.md`
- Task tracking in `TODO.md`
- Change documentation in `CHANGELOG.md`
- Updated documentation in `README.md`

$END$
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 Adam Twardoch

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="package.toml">
# Package configuration
[package]
include_cli = true        # Include CLI boilerplate
include_logging = true    # Include logging setup
use_pydantic = true      # Use Pydantic for data validation
use_rich = true          # Use Rich for terminal output

[features]
mkdocs = false           # Enable MkDocs documentation
vcs = true              # Initialize Git repository
github_actions = true   # Add GitHub Actions workflows
</file>

<file path="pyproject.toml">
# this_file: pyproject.toml
#==============================================================================
# UICU PACKAGE CONFIGURATION
# This pyproject.toml defines the package metadata, dependencies, build system,
# and development environment for the uicu package.
#==============================================================================

#------------------------------------------------------------------------------
# PROJECT METADATA
# Core package information used by PyPI and package managers.
#------------------------------------------------------------------------------
[project]
name = 'uicu' # Package name on PyPI
description = '' # Short description
readme = 'README.md' # Path to README file
requires-python = '>=3.10' # Minimum Python version
keywords = [
] # Keywords for PyPI search
dynamic = ["version"] # Fields set dynamically at build time

# PyPI classifiers for package categorization
classifiers = [
    'Development Status :: 4 - Beta', # Package maturity level
    'Programming Language :: Python',
    'Programming Language :: Python :: 3.10',
    'Programming Language :: Python :: 3.11',
    'Programming Language :: Python :: 3.12',
    'Programming Language :: Python :: Implementation :: CPython',
    'Programming Language :: Python :: Implementation :: PyPy',
    'Operating System :: OS Independent',
    'License :: OSI Approved :: MIT License',
    'Intended Audience :: Developers',
]

dependencies = [
]

# Author information
[[project.authors]]
name = 'Adam Twardoch'
email = 'adam+github@twardoch.com'

# License information
[project.license]
text = 'MIT'

# Project URLs
[project.urls]
Documentation = 'https://github.com/twardoch/uicu#readme'
Issues = 'https://github.com/twardoch/uicu/issues'
Source = 'https://github.com/twardoch/uicu'

#------------------------------------------------------------------------------
# OPTIONAL DEPENDENCIES
# Additional dependencies for optional features, development, and testing.
#------------------------------------------------------------------------------
[project.optional-dependencies]

# Development tools
dev = [
    'pre-commit>=4.1.0', # Pre-commit hook manager - Keep pre-commit as is, update if newer pre-commit version is required
    'ruff>=0.9.7', # Linting and formatting - Keep ruff as is, update if newer ruff version is required
    'mypy>=1.15.0', # Type checking - Keep mypy as is, update if newer mypy version is required
    'absolufy-imports>=0.3.1', # Convert relative imports to absolute - Keep absolufy-imports as is, update if newer absolufy-imports version is required
    'pyupgrade>=3.19.1', # Upgrade Python syntax - Keep pyupgrade as is, update if newer pyupgrade version is required
    'isort>=6.0.1', # Sort imports - Keep isort as is, update if newer isort version is required
]

# Testing tools and frameworks
test = [
    'pytest>=8.3.4', # Testing framework - Keep pytest as is, update if newer pytest version is required
    'pytest-cov>=6.0.0', # Coverage plugin for pytest - Keep pytest-cov as is, update if newer pytest-cov version is required
    'pytest-xdist>=3.6.1', # Parallel test execution - Keep pytest-xdist as is, update if newer pytest-xdist version is required
    'pytest-benchmark[histogram]>=5.1.0', # Benchmarking plugin - Keep pytest-benchmark as is, update if newer pytest-benchmark version is required
    'pytest-asyncio>=0.25.3', # Async test support - Keep pytest-asyncio as is, update if newer pytest-asyncio version is required
    'coverage[toml]>=7.6.12',
]

docs = [
    "sphinx>=7.2.6",
    "sphinx-rtd-theme>=2.0.0",
    "sphinx-autodoc-typehints>=2.0.0",
    "myst-parser>=3.0.0", # Markdown support in Sphinx
]

# All optional dependencies combined
all = [
]

#------------------------------------------------------------------------------
# COMMAND-LINE SCRIPTS
# Entry points for command-line executables installed with the package.
#------------------------------------------------------------------------------
[project.scripts]
# CLINAME = "uicu.__main__:main"

#------------------------------------------------------------------------------
# BUILD SYSTEM CONFIGURATION
# Defines the tools required to build the package and the build backend.
#------------------------------------------------------------------------------
[build-system]
# Hatchling is a modern build backend for Python packaging
# hatch-vcs integrates with version control systems for versioning
requires = [
    'hatchling>=1.27.0', # Keep hatchling as is, update if newer hatchling version is required
    'hatch-vcs>=0.4.0', # Keep hatch-vcs as is, update if newer hatch-vcs version is required
]
build-backend = 'hatchling.build' # Specifies Hatchling as the build backend


#------------------------------------------------------------------------------
# HATCH BUILD CONFIGURATION
# Configures the build process, specifying which packages to include and
# how to handle versioning.
#------------------------------------------------------------------------------
[tool.hatch.build]
# Include package data files
include = [
    "src/uicu/py.typed", # For better type checking support
    "src/uicu/data/**/*", # Include data files if any

]
exclude = ["**/__pycache__", "**/.pytest_cache", "**/.mypy_cache"]

[tool.hatch.build.targets.wheel]
packages = ["src/uicu"]
reproducible = true


# Version control system hook configuration
# Automatically updates the version file from git tags
[tool.hatch.build.hooks.vcs]
version-file = "src/uicu/__version__.py"

# Version source configuration
[tool.hatch.version]
source = 'vcs' # Get version from git tags or other VCS info

# Metadata handling configuration
[tool.hatch.metadata]
allow-direct-references = true # Allow direct references in metadata (useful for local dependencies)


#------------------------------------------------------------------------------
# DEVELOPMENT ENVIRONMENTS

[tool.hatch.envs.default]
features = ['dev', 'test', 'all']
dependencies = [
]

# Commands available in the default environment
[tool.hatch.envs.default.scripts]
# Run tests with optional arguments
test = 'pytest {args:tests}'
# Run tests with coverage reporting
test-cov = "pytest --cov-report=term-missing --cov-config=pyproject.toml --cov=src/uicu --cov=tests {args:tests}"
# Run type checking
type-check = "mypy src/uicu tests"
# Run linting and formatting
lint = ["ruff check src/uicu tests", "ruff format --respect-gitignore src/uicu tests"]
# Format and fix style issues
fmt = ["ruff format --respect-gitignore src/uicu tests", "ruff check --fix src/uicu tests"]
fix = ["ruff check --fix --unsafe-fixes src/uicu tests", "ruff format --respect-gitignore src/uicu tests"]

# Matrix configuration to test across multiple Python versions

[[tool.hatch.envs.all.matrix]]
python = ["3.10", "3.11", "3.12"]

#------------------------------------------------------------------------------
# SPECIALIZED ENVIRONMENTS
# Additional environments for specific development tasks.
#------------------------------------------------------------------------------

# Dedicated environment for linting and code quality checks
[tool.hatch.envs.lint]
detached = true # Create a separate, isolated environment
features = ['dev'] # Use dev extras  dependencies 

# Linting environment commands
[tool.hatch.envs.lint.scripts]
# Type checking with automatic type installation
typing = "mypy --install-types --non-interactive {args:src/uicu tests}"
# Check style and format code
style = ["ruff check {args:.}", "ruff format --respect-gitignore {args:.}"]
# Format and fix style issues
fmt = ["ruff format --respect-gitignore {args:.}", "ruff check --fix {args:.}"]
fix = ["ruff check --fix --unsafe-fixes {args:.}", "ruff format --respect-gitignore {args:.}"]
# Run all ops
all = ["style", "typing", "fix"]

# Dedicated environment for testing
[tool.hatch.envs.test]
features = ['test'] # Use test extras as dependencies

# Testing environment commands
[tool.hatch.envs.test.scripts]
# Run tests in parallel
test = "python -m pytest -n auto {args:tests}"
# Run tests with coverage in parallel
test-cov = "python -m pytest -n auto --cov-report=term-missing --cov-config=pyproject.toml --cov=src/uicu --cov=tests {args:tests}"
# Run benchmarks
bench = "python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only"
# Run benchmarks and save results
bench-save = "python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only --benchmark-json=benchmark/results.json"

# Documentation environment
[tool.hatch.envs.docs]
features = ['docs']

# Documentation environment commands
[tool.hatch.envs.docs.scripts]
build = "sphinx-build -b html docs/source docs/build"

# GitHub Actions workflow configuration
[tool.hatch.envs.ci]
features = ['test']


[tool.hatch.envs.ci.scripts]
test = "pytest --cov=src/uicu --cov-report=xml"


#------------------------------------------------------------------------------
# CODE QUALITY TOOLS
# Configuration for linting, formatting, and code quality enforcement.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# COVERAGE CONFIGURATION
# Settings for test coverage measurement and reporting.
#------------------------------------------------------------------------------

# Path mapping for coverage in different environments
[tool.coverage.paths]
uicu = ["src/uicu", "*/uicu/src/uicu"]
tests = ["tests", "*/uicu/tests"]

# Coverage report configuration
[tool.coverage.report]
# Lines to exclude from coverage reporting
exclude_lines = [
    'no cov', # Custom marker to skip coverage
    'if __name__ == .__main__.:', # Script execution guard
    'if TYPE_CHECKING:', # Type checking imports and code
    'pass', # Empty pass statements
    'raise NotImplementedError', # Unimplemented method placeholders
    'raise ImportError', # Import error handling
    'except ImportError', # Import error handling
    'except KeyError', # Common error handling
    'except AttributeError', # Common error handling
    'except NotImplementedError', # Common error handling
]

[tool.coverage.run]
source_pkgs = ["uicu", "tests"]
branch = true # Measure branch coverage (if/else statements)
parallel = true # Support parallel test execution
omit = [
    "src/uicu/__about__.py",
]

#------------------------------------------------------------------------------
# MYPY CONFIGURATION
# Configuration for type checking with mypy.
#------------------------------------------------------------------------------

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true

[[tool.mypy.overrides]]
module = ["tests.*"]
disallow_untyped_defs = false
disallow_incomplete_defs = false

#------------------------------------------------------------------------------
# PYTEST CONFIGURATION
# Configuration for pytest, including markers, options, and benchmark settings.
#------------------------------------------------------------------------------

[tool.pytest.ini_options]
addopts = "-v --durations=10 -p no:briefcase"
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"
console_output_style = "progress"
filterwarnings = ["ignore::DeprecationWarning", "ignore::UserWarning"]
log_cli = true
log_cli_level = "INFO"
markers = [
    "benchmark: marks tests as benchmarks (select with '-m benchmark')",
    "unit: mark a test as a unit test",
    "integration: mark a test as an integration test",
    "permutation: tests for permutation functionality", 
    "parameter: tests for parameter parsing",
    "prompt: tests for prompt parsing",
]
norecursedirs = [
    ".*",
    "build",
    "dist", 
    "venv",
    "__pycache__",
    "*.egg-info",
    "_private",
]
python_classes = ["Test*"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
testpaths = ["tests"]

[tool.pytest-benchmark]
min_rounds = 100
min_time = 0.1
histogram = true
storage = "file"
save-data = true
compare = [
    "min",    # Minimum time
    "max",    # Maximum time
    "mean",   # Mean time
    "stddev", # Standard deviation
    "median", # Median time
    "iqr",    # Inter-quartile range
    "ops",    # Operations per second
    "rounds", # Number of rounds
]

#------------------------------------------------------------------------------
# RUFF CONFIGURATION
# Configuration for Ruff, including linter and formatter settings.
#------------------------------------------------------------------------------ 

# Ruff linter and formatter configuration
[tool.ruff]
target-version = "py310"
line-length = 120

# Linting rules configuration
[tool.ruff.lint]
# Rule sets to enable, organized by category
select = [
    # flake8 plugins and extensions
    'A', # flake8-builtins: checks for shadowed builtins
    'ARG', # flake8-unused-arguments: checks for unused function arguments
    'ASYNC', # flake8-async: checks for async/await issues
    'B', # flake8-bugbear: finds likely bugs and design problems
    'C', # flake8-comprehensions: helps write better list/dict comprehensions
    'DTZ', # flake8-datetimez: checks for datetime timezone issues
    'E', # pycodestyle errors: PEP 8 style guide errors
    'EM', # flake8-errmsg: checks for better error messages
    'F', # pyflakes: detects various errors
    'FBT', # flake8-boolean-trap: checks for boolean traps in function signatures
    'I', # isort: sorts imports
    'ICN', # flake8-import-conventions: checks for import conventions
    'ISC', # flake8-implicit-str-concat: checks for implicit string concatenation
    'LOG', # flake8-logging: checks for logging issues
    'N', # pep8-naming: checks naming conventions
    'PLC', # pylint convention: checks for convention issues
    'PLE', # pylint error: checks for errors
    'PLR', # pylint refactor: suggests refactors
    'PLW', # pylint warning: checks for suspicious code
    'PT', # flake8-pytest-style: checks pytest-specific style
    'PTH', # flake8-use-pathlib: checks for stdlib path usage vs pathlib
    'PYI', # flake8-pyi: checks stub files
    'RET', # flake8-return: checks return statement consistency
    'RSE', # flake8-raise: checks raise statements
    'RUF', # Ruff-specific rules
    'S', # flake8-bandit: checks for security issues
    'SIM', # flake8-simplify: checks for code simplification opportunities
    'T', # flake8-print: checks for print statements
    'TCH', # flake8-type-checking: helps with type-checking
    'TID', # flake8-tidy-imports: checks for tidy import statements
    'UP', # pyupgrade: checks for opportunities to use newer Python features
    'W', # pycodestyle warnings: PEP 8 style guide warnings
    'YTT', # flake8-2020: checks for misuse of sys.version or sys.version_info

]
# Rules to ignore (with reasons)
ignore = [
    'B027', # Empty method in abstract base class - sometimes needed for interfaces
    'C901', # Function is too complex - sometimes complexity is necessary
    'FBT003', # Boolean positional argument in function definition - sometimes unavoidable
    'PLR0911', # Too many return statements - sometimes needed for readability
    'PLR0912', # Too many branches - sometimes needed for complex logic
    'PLR0913', # Too many arguments - sometimes needed in APIs
    'PLR0915', # Too many statements - sometimes needed for comprehensive functions
    'PLR1714', # Consider merging multiple comparisons - sometimes less readable
    'PLW0603', # Using the global statement - sometimes necessary
    'PT013', # Pytest explicit test parameter - sometimes clearer
    'PTH123', # Path traversal - sometimes needed
    'PYI056', # Calling open() in pyi file - sometimes needed in type stubs
    'S105', # Possible hardcoded password - often false positives
    'S106', # Possible hardcoded password - often false positives
    'S107', # Possible hardcoded password - often false positives
    'S110', # try-except-pass - sometimes valid for suppressing exceptions
    'SIM102'
    # Nested if statements - sometimes more readable than combined conditions
]
# Rules that should not be automatically fixed
unfixable = [
    'F401', # Don't automatically remove unused imports - may be needed later

]
# Configure extend-exclude to ignore specific directories
extend-exclude = [".git", ".venv", "venv", "dist", "build"]

# isort configuration within Ruff
[tool.ruff.lint.isort]
known-first-party = ['uicu'] # Treat as first-party imports for sorting

# flake8-tidy-imports configuration within Ruff
[tool.ruff.lint.flake8-tidy-imports]
ban-relative-imports = 'all' # Ban all relative imports for consistency

# Per-file rule exceptions
[tool.ruff.lint.per-file-ignores]
# Tests can use magic values, assertions, and relative imports
'tests/**/*' = [
    'PLR2004', # Allow magic values in tests for readability
    'S101', # Allow assertions in tests
    'TID252'
    # Allow relative imports in tests for convenience
]
</file>

<file path="README.md">
# `uicu`

## Objective

PyICU does not have a very pythonic API. I’d like us to make `uicu`, a very extensive, but mainly a natural, pythonic yet performant API (wrapper around PyICU), supplemented by fontTools.unicodedata if needed. The uciu API should expose rich, well-documented objects that naturally integrate with Python’s native Unicode but also expose rich additional functionality.




## Project Overview

`uicu` is a Python package that aims to create a pythonic wrapper around PyICU, supplemented by fontTools.unicodedata. The goal is to provide a natural, performant API that exposes rich, well-documented objects integrating with Python's native Unicode handling while adding extensive Unicode functionality.

## Development Commands

### Environment Setup
```bash
# Install and use uv for package management
pip install uv
# Use hatch for development workflow
uv pip install hatch
```

### Common Development Tasks
```bash
# Activate development environment
hatch shell

# Run tests
hatch run test
python -m pytest

# Run tests with coverage
hatch run test-cov

# Run linting
hatch run lint

# Format code
hatch run format

# Run type checking
hatch run type-check

# After Python changes, run the full formatting pipeline:
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

## Code Architecture

### Project Structure
- **src/uicu/**: Main package source (using src-layout)
  - `__init__.py`: Package initialization
  - `__version__.py`: Version management using hatch-vcs
  - `uicu.py`: Main module (currently skeleton)
- **tests/**: Test suite using pytest
- **pyproject.toml**: PEP 621 compliant project configuration

### Key Dependencies to Research
- **PyICU**: The main Unicode library to wrap
- **fontTools.unicodedata**: Supplementary Unicode data with writing system info

## Development Guidelines

### Python-Specific Rules
- Use `uv pip` instead of `pip`
- Always use `python -m` when running modules
- Use type hints in simple form (list, dict, | for unions)
- Add verbose loguru-based logging and debug-log
- For CLI scripts, use fire & rich libraries
- Scripts should start with `#!/usr/bin/env -S uv run -s`

### Code Quality Standards
- PEP 8 compliant (enforced by Ruff)
- Clear, imperative docstrings (PEP 257)
- Use f-strings for formatting
- Structural pattern matching where appropriate
- Maintain `this_file` comments at the top of each source file

### Development Workflow
1. Create/update `PLAN.md` with detailed flat plan using `[ ]` items
2. Identify important TODOs and update `TODO.md`
3. Implement changes incrementally
4. Update `CHANGELOG.md` after each round of changes
5. Update `README.md` to reflect changes
6. Run the formatting pipeline after Python changes

### Current Project Status
- Initial project structure created
- Main objective: Create pythonic wrapper around PyICU
- First task: Research and document APIs from fontTools.unicodedata and PyICU
- Implementation phase not yet started

## Testing Strategy
- pytest with coverage tracking
- Use pytest-xdist for parallel test execution
- pytest-benchmark for performance testing
- Maintain high test coverage for all new functionality

## Key Principles
- Iterate gradually, avoiding major changes
- Preserve existing code/structure unless necessary
- Write explanatory docstrings that explain what and WHY
- Handle failures gracefully with retries and fallbacks
- Focus on minimal viable increments
- Keep code simple and explicit (PEP 20)

# When you write code

- Iterate gradually, avoiding major changes
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Use constants over magic numbers
- Check for existing solutions in the codebase before starting
- Check often the coherence of the code you're writing with the rest of the code.
- Focus on minimal viable increments and ship early
- Write explanatory docstrings/comments that explain what and WHY this does, explain where and how the code is used/referred to elsewhere in the code
- Analyze code line-by-line
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures
- Consistently keep, document, update and consult the holistic overview mental image of the codebase. 

## Keep track of paths

In each source file, maintain the up-to-date `this_file` record that shows the path of the current file relative to project root. Place the `this_file` record near the top of the file, as a comment after the shebangs, or in the YAML Markdown frontmatter.

## When you write Python

- Use `uv pip`, never `pip`
- Use `python -m` when running code
- PEP 8: Use consistent formatting and naming
- Write clear, descriptive names for functions and variables
- PEP 20: Keep code simple and explicit. Prioritize readability over cleverness
- Use type hints in their simplest form (list, dict, | for unions)
- PEP 257: Write clear, imperative docstrings
- Use f-strings. Use structural pattern matching where appropriate
- ALWAYS add "verbose" mode logugu-based logging, & debug-log
- For CLI Python scripts, use fire & rich, and start the script with

```
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

Work in rounds: 

- Create `PLAN.md` as a detailed flat plan with `[ ]` items. 
- Identify the most important TODO items, and create `TODO.md` with `[ ]` items. 
- Implement the changes. 
- Update `PLAN.md` and `TODO.md` as you go. 
- After each round of changes, update `CHANGELOG.md` with the changes.
- Update `README.md` to reflect the changes.

Ask before extending/refactoring existing code in a way that may add complexity or break things.

When you're finished, print "Wait, but" to go back, think & reflect, revise & improvement what you've done (but don't invent functionality freely). Repeat this. But stick to the goal of "minimal viable next version". Lead two experts: "Ideot" for creative, unorthodox ideas, and "Critin" to critique flawed thinking and moderate for balanced discussions. The three of you shall illuminate knowledge with concise, beautiful responses, process methodically for clear answers, collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

## After Python changes run:

```
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

Be creative, diligent, critical, relentless & funny!
</file>

</files>
