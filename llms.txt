This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.cursor/
  rules/
    data-flow.mdc
    data-models.mdc
    unicode-wrapper-implementation.mdc
.giga/
  specifications.json
.github/
  workflows/
    push.yml
    release.yml
examples/
  uicu_demo.py
issues/
  issue102.md
  issue202.md
  issue203.txt
research/
  res-gemi.md
  res-gpt.md
  res-grok.md
  res-phind.md
src/
  uicu/
    __init__.py
    char.py
    collate.py
    exceptions.py
    format.py
    locale.py
    segment.py
    translit.py
tests/
  test_char.py
  test_collate.py
  test_format.py
  test_locale.py
  test_package.py
  test_segment.py
  test_translit.py
.cursorrules
.gitignore
.pre-commit-config.yaml
build.sh
CHANGELOG.md
CLAUDE.md
DEVELOPMENT_STATUS.md
LICENSE
package.toml
PLAN.md
pyproject.toml
README.md
release.sh
TODO.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="issues/issue203.txt">
Othello:uicu adam$ ./build.sh
Usage: ./build.sh <command>

Commands:
  deps         Install/update dev dependencies (uv, hatch)
  lint         Run Ruff linting and formatting checks
  format       Run Ruff formatter and autofixes
  type-check   Run mypy static type checking
  test         Run pytest test suite
  test-cov     Run tests with coverage report
  build        Build wheel and sdist using Hatch
  docs         Build Sphinx HTML documentation
  clean        Remove build artefacts (build/, dist/, *.egg-info …)
  llms         Regenerate llms.txt using repomix (requires Node + npx)
  all          Run deps → format → lint → type-check → test-cov → build
  help         Show this help message
Othello:uicu adam$ ./build.sh all
cmd [1] | ruff format --respect-gitignore src/uicu tests
15 files left unchanged
cmd [2] | ruff check --fix src/uicu tests
src/uicu/format.py:11:20: F401 `typing.Any` imported but unused
   |
10 | from datetime import datetime, timezone, tzinfo
11 | from typing import Any
   |                    ^^^ F401
12 |
13 | import icu
   |
   = help: Remove unused import: `typing.Any`

src/uicu/format.py:178:35: ARG002 Unused method argument: `lenient`
    |
176 |         return self._formatter.format(icu_time)
177 |
178 |     def parse(self, text: str, *, lenient: bool = True) -> datetime:
    |                                   ^^^^^^^ ARG002
179 |         """Parse a string to a datetime object.
    |

src/uicu/format.py:278:32: RUF001 String contains ambiguous `–` (EN DASH). Did you mean `-` (HYPHEN-MINUS)?
    |
276 |         result = dtifmt.format((start_ts, end_ts), from_field, to_field)
277 |
278 |         return result.replace("–", "-")  # Use standard hyphen instead of en dash
    |                                ^ RUF001
279 |
280 |     @property
    |

src/uicu/format.py:321:9: FBT001 Boolean-typed positional argument in function definition
    |
319 |         max_fraction_digits: int | None = None,
320 |         min_integer_digits: int | None = None,
321 |         grouping: bool = True,
    |         ^^^^^^^^ FBT001
322 |         rounding_mode: str = "half_even",
323 |     ):
    |

src/uicu/format.py:321:9: FBT002 Boolean default positional argument in function definition
    |
319 |         max_fraction_digits: int | None = None,
320 |         min_integer_digits: int | None = None,
321 |         grouping: bool = True,
    |         ^^^^^^^^ FBT002
322 |         rounding_mode: str = "half_even",
323 |     ):
    |

src/uicu/format.py:498:16: RUF002 Docstring contains ambiguous `–` (EN DASH). Did you mean `-` (HYPHEN-MINUS)?
    |
496 |             >>> formatter = NumberFormatter('en-US')
497 |             >>> formatter.format_range(10, 20)
498 |             '10–20'
    |                ^ RUF002
499 |
500 |             >>> formatter = NumberFormatter('de-DE', style='currency')
    |

src/uicu/format.py:502:21: RUF002 Docstring contains ambiguous `–` (EN DASH). Did you mean `-` (HYPHEN-MINUS)?
    |
500 |             >>> formatter = NumberFormatter('de-DE', style='currency')
501 |             >>> formatter.format_range(10.50, 25.75, 'EUR')
502 |             '10,50 €–25,75 €'
    |                     ^ RUF002
503 |         """
504 |         try:
    |

src/uicu/format.py:514:43: RUF001 String contains ambiguous `–` (EN DASH). Did you mean `-` (HYPHEN-MINUS)?
    |
512 |                 start_formatted = self.format(start)
513 |                 end_formatted = self.format(end)
514 |                 return f"{start_formatted}–{end_formatted}"
    |                                           ^ RUF001
515 |             if self._style == "percent":
516 |                 range_formatter = range_formatter.numberFormatterBoth(
    |

src/uicu/format.py:527:39: RUF001 String contains ambiguous `–` (EN DASH). Did you mean `-` (HYPHEN-MINUS)?
    |
525 |             start_formatted = self.format(start)
526 |             end_formatted = self.format(end)
527 |             return f"{start_formatted}–{end_formatted}"
    |                                       ^ RUF001
528 |
529 |     @property
    |

src/uicu/format.py:681:26: PLR2004 Magic value used in comparison, consider replacing `2` with a constant variable
    |
679 |         locale_tag = self._locale.language_tag.lower()
680 |
681 |         if len(items) == 2:
    |                          ^ PLR2004
682 |             # Two items - use appropriate conjunction
683 |             if self._list_type == "or":
    |

src/uicu/locale.py:12:35: F401 `typing.Optional` imported but unused
   |
10 | from __future__ import annotations
11 |
12 | from typing import TYPE_CHECKING, Optional
   |                                   ^^^^^^^^ F401
13 |
14 | import icu
   |
   = help: Remove unused import: `typing.Optional`

src/uicu/locale.py:52:38: EM102 Exception must not use an f-string literal, assign to variable first
   |
50 |             self._icu_locale = icu.Locale(language_tag)
51 |         except Exception as e:
52 |             raise ConfigurationError(f"Failed to create locale for '{language_tag}': {e}") from e
   |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ EM102
53 |
54 |         self._language_tag = language_tag
   |
   = help: Assign to variable; remove f-string literal

src/uicu/locale.py:148:9: PLC0415 `import` should be at the top-level of a file
    |
146 |             A collator for this locale
147 |         """
148 |         from uicu.collate import Collator
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLC0415
149 |
150 |         return Collator(self, strength=strength, numeric=numeric, **kwargs)
    |

src/uicu/locale.py:157:10: F821 Undefined name `DateTimeFormatter`
    |
155 |         time_style: str = "medium",
156 |         **kwargs,
157 |     ) -> DateTimeFormatter:
    |          ^^^^^^^^^^^^^^^^^ F821
158 |         """Create a date/time formatter for this locale.
    |

src/uicu/locale.py:168:9: PLC0415 `import` should be at the top-level of a file
    |
166 |             A date/time formatter for this locale
167 |         """
168 |         from uicu.format import DateTimeFormatter
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLC0415
169 |
170 |         return DateTimeFormatter(
    |

src/uicu/locale.py:181:10: F821 Undefined name `DateTimeFormatter`
    |
179 |         style: str = "medium",
180 |         **kwargs,
181 |     ) -> DateTimeFormatter:
    |          ^^^^^^^^^^^^^^^^^ F821
182 |         """Create a date-only formatter for this locale.
    |

src/uicu/locale.py:197:10: F821 Undefined name `DateTimeFormatter`
    |
195 |         style: str = "medium",
196 |         **kwargs,
197 |     ) -> DateTimeFormatter:
    |          ^^^^^^^^^^^^^^^^^ F821
198 |         """Create a time-only formatter for this locale.
    |

src/uicu/locale.py:260:9: PLC0415 `import` should be at the top-level of a file
    |
258 |         """
259 |         # Import here to avoid circular imports
260 |         from uicu.segment import WordSegmenter
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLC0415
261 |
262 |         return WordSegmenter(self)
    |

src/uicu/locale.py:271:9: PLC0415 `import` should be at the top-level of a file
    |
269 |         """
270 |         # Import here to avoid circular imports
271 |         from uicu.segment import GraphemeSegmenter
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLC0415
272 |
273 |         return GraphemeSegmenter(self)
    |

src/uicu/locale.py:282:9: PLC0415 `import` should be at the top-level of a file
    |
280 |         """
281 |         # Import here to avoid circular imports
282 |         from uicu.segment import SentenceSegmenter
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ PLC0415
283 |
284 |         return SentenceSegmenter(self)
    |

src/uicu/segment.py:10:29: F401 `uicu.exceptions.ConfigurationError` imported but unused
   |
 8 | import icu
 9 |
10 | from uicu.exceptions import ConfigurationError, OperationError
   |                             ^^^^^^^^^^^^^^^^^^ F401
11 | from uicu.locale import Locale
   |
   = help: Remove unused import

src/uicu/segment.py:10:49: F401 `uicu.exceptions.OperationError` imported but unused
   |
 8 | import icu
 9 |
10 | from uicu.exceptions import ConfigurationError, OperationError
   |                                                 ^^^^^^^^^^^^^^ F401
11 | from uicu.locale import Locale
   |
   = help: Remove unused import

src/uicu/translit.py:11:49: F401 `uicu.exceptions.OperationError` imported but unused
   |
 9 | import icu
10 |
11 | from uicu.exceptions import ConfigurationError, OperationError
   |                                                 ^^^^^^^^^^^^^^ F401
12 | from uicu.locale import Locale
   |
   = help: Remove unused import: `uicu.exceptions.OperationError`

src/uicu/translit.py:12:25: F401 `uicu.locale.Locale` imported but unused
   |
11 | from uicu.exceptions import ConfigurationError, OperationError
12 | from uicu.locale import Locale
   |                         ^^^^^^ F401
   |
   = help: Remove unused import: `uicu.locale.Locale`

tests/test_char.py:37:36: RUF001 String contains ambiguous `١` (ARABIC-INDIC DIGIT ONE). Did you mean `l` (LATIN SMALL LETTER L)?
   |
35 |         assert uicu.bidirectional("A") == "L"  # Left-to-right
36 |         assert uicu.bidirectional("א") == "R"  # Right-to-left (Hebrew)
37 |         assert uicu.bidirectional("١") == "AN"  # Arabic number
   |                                    ^ RUF001
38 |
39 |     def test_combining(self):
   |

Found 26 errors (1 fixed, 25 remaining).
No fixes available (1 hidden fix can be enabled with the `--unsafe-fixes` option).
Othello:uicu adam$
</file>

<file path="release.sh">
#!/usr/bin/env bash
# this_file: release.sh
# ============================================================================
# UICU RELEASE SCRIPT
# ----------------------------------------------------------------------------
# A script to handle the release process for uicu.
# ----------------------------------------------------------------------------
#  • Runs all tests and checks
#  • Builds documentation
#  • Updates version
#  • Creates git tag
#  • Builds and uploads to PyPI
# ============================================================================

set -euo pipefail
IFS=$'\n\t'

PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$PROJECT_ROOT"

# ------------------------------- helpers ------------------------------------
usage() {
    cat <<'EOF'
Usage: ./release.sh <version>

Arguments:
  version     The version to release (e.g. 1.0.0)

Example:
  ./release.sh 1.0.0
EOF
}

# ----------------------------- main script --------------------------------
if [ $# -ne 1 ]; then
    usage
    exit 1
fi

VERSION="$1"

echo "[release.sh] Starting release process for version ${VERSION}..."

# Run all checks and tests
echo "[release.sh] Running build script with all checks..."
./build.sh all

# Build documentation
echo "[release.sh] Building documentation..."
./build.sh docs

# Create git tag
echo "[release.sh] Creating git tag v${VERSION}..."
git tag -a "v${VERSION}" -m "Release version ${VERSION}"

# Build distribution
echo "[release.sh] Building distribution..."
./build.sh build

# Upload to PyPI
echo "[release.sh] Uploading to PyPI..."
hatch publish

echo "[release.sh] Release ${VERSION} completed successfully!"
echo
echo "Next steps:"
echo "1. Push the tag: git push origin v${VERSION}"
echo "2. Create a GitHub release: https://github.com/adamchainz/uicu/releases/new"
echo "3. Update the documentation site"
echo "4. Announce the release"
</file>

<file path=".cursor/rules/data-flow.mdc">
---
description: Documents Unicode data processing flows, transformations and integration points between PyICU and fontTools.unicodedata
globs: src/uicu/**/*.py,tests/**/*_test.py
alwaysApply: false
---


# data-flow

## Core Unicode Data Pipeline

1. **PyICU Integration Layer**
- Wraps PyICU's Unicode processing capabilities into a Pythonic interface
- Handles raw Unicode data input from PyICU API
- Transforms data into Python native Unicode objects
- File: `src/uicu/pyicu_wrapper.py`

2. **FontTools Data Enrichment**
- Augments Unicode data with writing system information from fontTools.unicodedata
- Merges supplementary Unicode properties into the data stream
- File: `src/uicu/font_tools_bridge.py`

3. **Unified Data Model**
- Combines data from both sources into cohesive Unicode objects 
- Maintains relationship between original PyICU data and enriched properties
- File: `src/uicu/models.py`

## Data Transformation Flows

1. **Unicode Normalization Pipeline**
- Processes incoming Unicode through configurable normalization forms
- Integrates PyICU normalization with Python's unicodedata
- File: `src/uicu/normalizer.py`

2. **Writing System Analysis**
- Extracts writing system metadata from fontTools
- Associates script information with Unicode code points
- File: `src/uicu/writing_systems.py`

## Integration Points

1. **PyICU Bridge** 
- Direct interface to ICU Unicode processing
- Handles data format conversions between PyICU and Python
- File: `src/uicu/icu_bridge.py`

2. **FontTools Connector**
- Manages access to supplementary Unicode data
- Synchronizes property lookups between systems
- File: `src/uicu/font_tools.py`

$END$

 If you're using this file in context, clearly say in italics in one small line that "Context added by Giga data-flow".
</file>

<file path=".cursor/rules/data-models.mdc">
---
description: Defines core data structures and models for Unicode data handling and Python type relationships
globs: src/uicu/*.py,tests/**/test_models.py,tests/**/test_data.py
alwaysApply: false
---


# data-models

## Core Data Models (Importance: 95)

The data model architecture centers around representing and transforming Unicode data between PyICU objects and Python native types:

1. **Unicode Data Representation**
- Custom data structures for Unicode character properties
- Mappings between PyICU Unicode database entries and Python string types
- Integration with fontTools.unicodedata writing system information
File: `src/uicu/models.py`

2. **Type Relationships** 
- Data models defining bidirectional conversion between:
  - PyICU UChar objects
  - Python str/bytes types
  - Writing system metadata from fontTools
- Cross-reference tables for character properties
File: `src/uicu/types.py`

## Object Model Hierarchy (Importance: 85)

Core class hierarchy for Unicode data abstraction:

```python
class UnicodeData:
    """Base class for Unicode character data"""
    # Maps to PyICU character database

class WritingSystemData:
    """Writing system metadata"""  
    # Integrates fontTools script information
```

File: `src/uicu/models.py`

## Model Relationships (Importance: 80)

The data models maintain bidirectional relationships between:

- PyICU's native character database structures
- Python's built-in Unicode string handling
- fontTools writing system metadata
- Custom property mappings and cross-references

These relationships enable seamless conversion while preserving Unicode data integrity.

File: `src/uicu/relationships.py`

$END$

 If you're using this file in context, clearly say in italics in one small line that "Context added by Giga data-models".
</file>

<file path=".cursor/rules/unicode-wrapper-implementation.mdc">
---
description: Specifies the implementation of the Pythonic Unicode wrapper functionality around PyICU and fontTools.unicodedata
globs: src/uicu/*.py,tests/*_unicode*.py,tests/*_icu*.py
alwaysApply: false
---


# unicode-wrapper-implementation

### Core Unicode Wrapper Components

1. **PyICU Integration Layer** (Importance: 95)
- Custom wrapper classes that provide Pythonic interfaces to PyICU's Unicode operations
- Handles encoding/decoding between Python's native Unicode and ICU's internal formats
- File path: `src/uicu/icu_wrapper.py`

2. **fontTools Integration** (Importance: 85)
- Supplementary writing system information extraction from fontTools.unicodedata
- Merges font-specific Unicode data with ICU capabilities
- File path: `src/uicu/font_unicode.py`

3. **Unicode Data Objects** (Importance: 90)
- Rich object model representing Unicode characters with extended properties
- Custom attributes for writing system classification
- Advanced normalization and decomposition handling
- File path: `src/uicu/unicode_data.py`

4. **Unicode Operation Pipeline** (Importance: 85)
- Structured workflow for processing Unicode text through multiple stages
- Configurable transformation chain for character normalization
- Fallback handling for unsupported Unicode operations
- File path: `src/uicu/pipeline.py`

### Domain-Specific Implementations

1. **Writing System Detection** (Importance: 80)
- Custom algorithms for identifying writing systems in mixed Unicode text
- Integration of ICU script detection with fontTools metadata
- File path: `src/uicu/script_detect.py`

2. **Unicode Data Enrichment** (Importance: 75)
- Enhancement of Unicode character properties with additional metadata
- Custom property definitions for specialized text processing needs
- File path: `src/uicu/property_extend.py`

### Test Infrastructure

1. **Unicode Test Cases** (Importance: 70)
- Comprehensive test suite for Unicode handling edge cases
- Validation of character property preservation
- File path: `tests/test_unicode_wrapper.py`

2. **Integration Tests** (Importance: 75)
- Tests for PyICU and fontTools integration points
- Verification of combined Unicode operations
- File path: `tests/test_integration.py`

$END$

 If you're using this file in context, clearly say in italics in one small line that "Context added by Giga unicode-wrapper-implementation".
</file>

<file path=".giga/specifications.json">
[
  {
    "fileName": "main-overview.mdc",
    "description": "High-level overview of the uicu system architecture, core components, and integration with PyICU and fontTools.unicodedata"
  },
  {
    "fileName": "unicode-wrapper-implementation.mdc",
    "description": "Detailed documentation of the Pythonic wrapper implementation around PyICU, including class hierarchies, method signatures, and Unicode handling algorithms"
  },
  {
    "fileName": "data-models.mdc",
    "description": "Documentation of core data structures and models used to represent Unicode data, including relationships between PyICU objects and Python native types"
  },
  {
    "fileName": "data-flow.mdc",
    "description": "Documentation of how Unicode data flows through the system, including processing pipelines, transformations, and integration points between PyICU and fontTools.unicodedata"
  }
]
</file>

<file path=".github/workflows/push.yml">
name: Build & Test

on:
  push:
    branches: [main]
    tags-ignore: ["v*"]
  pull_request:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: write
  id-token: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run Ruff lint
        uses: astral-sh/ruff-action@v3
        with:
          version: "latest"
          args: "check --output-format=github"

      - name: Run Ruff Format
        uses: astral-sh/ruff-action@v3
        with:
          version: "latest"
          args: "format --check --respect-gitignore"

  test:
    name: Run Tests
    needs: quality
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
        os: [ubuntu-latest]
      fail-fast: true
    runs-on: ${{ matrix.os }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: ${{ matrix.python-version }}
          enable-cache: true
          cache-suffix: ${{ matrix.os }}-${{ matrix.python-version }}

      - name: Install test dependencies
        run: |
          uv pip install --system --upgrade pip
          uv pip install --system ".[test]"

      - name: Run tests with Pytest
        run: uv run pytest -n auto --maxfail=1 --disable-warnings --cov-report=xml --cov-config=pyproject.toml --cov=src/uicu --cov=tests tests/

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.python-version }}-${{ matrix.os }}
          path: coverage.xml

  build:
    name: Build Distribution
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: "3.12"
          enable-cache: true

      - name: Install build tools
        run: uv pip install build hatchling hatch-vcs

      - name: Build distributions
        run: uv run python -m build --outdir dist

      - name: Upload distribution artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist-files
          path: dist/
          retention-days: 5
</file>

<file path=".github/workflows/release.yml">
name: Release

on:
  push:
    tags: ["v*"]

permissions:
  contents: write
  id-token: write

jobs:
  release:
    name: Release to PyPI
    runs-on: ubuntu-latest
    environment:
      name: pypi
      url: https://pypi.org/p/uicu
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: "3.12"
          enable-cache: true

      - name: Install build tools
        run: uv pip install build hatchling hatch-vcs

      - name: Build distributions
        run: uv run python -m build --outdir dist

      - name: Verify distribution files
        run: |
          ls -la dist/
          test -n "$(find dist -name '*.whl')" || (echo "Wheel file missing" && exit 1)
          test -n "$(find dist -name '*.tar.gz')" || (echo "Source distribution missing" && exit 1)

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          password: ${{ secrets.PYPI_TOKEN }}

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          files: dist/*
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
</file>

<file path="examples/uicu_demo.py">
#!/usr/bin/env python3
"""uicu_demo.py - Comprehensive demonstration of uicu capabilities.

This script showcases 12 interesting uses of the uicu library for
Unicode text processing and internationalization.
"""

from datetime import datetime
import uicu


def demo_1_character_exploration():
    """Demo 1: Explore Unicode character properties."""
    print("=== Demo 1: Unicode Character Exploration ===")

    # Interesting characters from different scripts
    chars = ["A", "й", "中", "🎉", "ℵ", "½", "א", "🏁"]


    for char in chars:
        info = uicu.Char(char)
        print(f"\nCharacter: {char} (U+{ord(char):04X})")
        print(f"  Name: {info.name}")
        print(f"  Category: {info.category}")
        print(f"  Script: {info.script} - {uicu.script_name(info.script)}")
        print(f"  Block: {info.block}")
        if info.numeric is not None:
            print(f"  Numeric Value: {info.numeric}")
        if info.mirrored:
            print(f"  Mirrored: Yes")


def demo_2_multilingual_sorting():
    """Demo 2: Sort names from different cultures correctly."""
    print("\n=== Demo 2: Culture-Aware Name Sorting ===")

    names = [
        "Åberg",
        "Östberg",
        "Mueller",
        "Müller",
        "MacDonald",
        "O'Brien",
        "van der Berg",
        "García",
        "Gutierrez",
    ]

    # Sort with different locale rules
    locale_ids = ["en-US", "de-DE", "sv-SE", "es-ES"]

    for locale_id in locale_ids:
        locale = uicu.Locale(locale_id)
        sorted_names = uicu.sort(names, locale_id)
        print(f"\n{locale.display_name} sorting:")
        for i, name in enumerate(sorted_names, 1):
            print(f"  {i}. {name}")


def demo_3_text_segmentation():
    """Demo 3: Break text into graphemes, words, and sentences."""
    print("\n=== Demo 3: Text Segmentation ===")

    # Text with complex elements
    text = "Hello! 👨‍👩‍👧‍👦 means family. José's café costs $3.50."

    print(f"\nOriginal text: {text}")

    # Grapheme clusters (user-perceived characters)
    graphemes = list(uicu.graphemes(text))
    print(f"\nGraphemes ({len(graphemes)}): {graphemes[:20]}...")
    print(f"  Note: Family emoji is 1 grapheme: '{graphemes[7]}'")

    # Words
    words = [w for w in uicu.words(text) if w.strip()]
    print(f"\nWords: {words}")

    # Sentences
    sentences = list(uicu.sentences(text))
    print(f"\nSentences: {sentences}")


def demo_4_script_conversion():
    """Demo 4: Convert between writing systems."""
    print("\n=== Demo 4: Script Conversion (Transliteration) ===")

    examples = [
        ("Москва", "Cyrillic-Latin", "Moscow"),
        ("Ελληνικά", "Greek-Latin", "Greek"),
        ("北京市", "Han-Latin", "Beijing"),
        ("こんにちは", "Hiragana-Latin", "Hello (Japanese)"),
        ("مرحبا", "Arabic-Latin", "Hello (Arabic)"),
    ]

    for text, transform, description in examples:
        try:
            trans = uicu.Transliterator(transform)
            result = trans.transliterate(text)
            print(f"\n{description}:")
            print(f"  Original: {text}")
            print(f"  Romanized: {result}")
        except Exception as e:
            print(f"\n{description}:")
            print(f"  Original: {text}")
            print(f"  Error: {e}")


def demo_5_locale_aware_formatting():
    """Demo 5: Format dates/times for different locales."""
    print("\n=== Demo 5: Locale-Aware Date/Time Formatting ===")

    dt = datetime(2025, 3, 15, 14, 30)

    locales = [
        ("en-US", "US English"),
        ("en-GB", "British English"),
        ("fr-FR", "French"),
        ("de-DE", "German"),
        ("ja-JP", "Japanese"),
        ("ar-SA", "Arabic"),
    ]

    for locale_id, name in locales:
        locale = uicu.Locale(locale_id)
        formatter = locale.get_datetime_formatter(date_style="long", time_style="short")
        formatted = formatter.format(dt)
        print(f"{name:15} {formatted}")


def demo_6_numeric_collation():
    """Demo 6: Smart numeric sorting."""
    print("\n=== Demo 6: Numeric vs Lexical Sorting ===")

    items = [
        "Chapter 2",
        "Chapter 10",
        "Chapter 1",
        "Chapter 21",
        "Chapter 3",
        "Version 2.9",
        "Version 2.10",
        "Version 2.100",
    ]

    # Regular sorting
    regular = uicu.sort(items, "en-US")
    print("\nLexical sorting (incorrect for numbers):")
    for item in regular:
        print(f"  {item}")

    # Numeric sorting
    numeric = uicu.sort(items, "en-US", numeric=True)
    print("\nNumeric sorting (correct):")
    for item in numeric:
        print(f"  {item}")


def demo_7_text_transformation():
    """Demo 7: Unicode text transformations."""
    print("\n=== Demo 7: Text Transformations ===")

    original = """Café São Paulo — "naïve" approach"""

    transforms = [
        ("NFC", "Canonical Composition"),
        ("NFD", "Canonical Decomposition"),
        ("NFKC", "Compatibility Composition"),
        ("Latin-ASCII", "Remove Accents"),
        ("Lower", "Lowercase"),
        ("Upper", "Uppercase"),
        ("Title", "Title Case"),
    ]

    print(f"Original: {original}")
    for transform_id, description in transforms:
        result = uicu.transliterate(original, transform_id)
        print(f"\n{description} ({transform_id}):")
        print(f"  {result}")
        if transform_id == "NFD":
            print(f"  Length: {len(original)} → {len(result)} characters")


def demo_8_script_detection():
    """Demo 8: Detect the primary script in text."""
    print("\n=== Demo 8: Script Detection ===")

    texts = [
        ("Hello, world!", "English"),
        ("Привет, мир!", "Russian"),
        ("你好世界", "Chinese"),
        ("مرحبا بالعالم", "Arabic"),
        ("Γεια σου κόσμε", "Greek"),
        ("שלום עולם", "Hebrew"),
        ("Mixed: Hello, 你好, مرحبا", "Mixed scripts"),
    ]

    for text, description in texts:
        script = uicu.detect_script(text)
        if script:
            script_name = uicu.script_name(script)
            print(f"{description:20} → {script} ({script_name})")
        else:
            print(f"{description:20} → Mixed/Unknown")


def demo_9_thai_word_breaking():
    """Demo 9: Word segmentation for languages without spaces."""
    print("\n=== Demo 9: Thai Word Segmentation ===")

    # Thai text without spaces between words
    thai_text = "สวัสดีครับยินดีต้อนรับสู่ประเทศไทย"
    print(f"Original Thai text: {thai_text}")
    print("(Thai doesn't use spaces between words)")

    # Segment into words
    words = list(uicu.words(thai_text, locale="th-TH"))
    # Filter out spaces
    words = [w for w in words if w.strip()]

    print(f"\nSegmented words ({len(words)}):")
    for i, word in enumerate(words, 1):
        print(f"  {i}. {word}")


def demo_10_emoji_handling():
    """Demo 10: Proper handling of emoji and complex graphemes."""
    print("\n=== Demo 10: Emoji and Complex Character Handling ===")

    # Text with various emoji
    text = "I ❤️ Python! 👨‍💻👩‍💻 Happy coding! 🇺🇸🇬🇧🇫🇷"

    print(f"Text: {text}")
    print(f"String length: {len(text)} (incorrect count)")

    # Count actual graphemes
    graphemes = list(uicu.graphemes(text))
    print(f"Grapheme count: {len(graphemes)} (correct count)")

    # Show complex graphemes
    complex_graphemes = [g for g in graphemes if len(g) > 1]
    print(f"\nComplex graphemes (multiple codepoints):")
    for g in complex_graphemes:
        codepoints = [f"U+{ord(c):04X}" for c in g]
        print(f"  '{g}' = {' + '.join(codepoints)}")


def demo_11_case_sensitive_sorting():
    """Demo 11: Control case sensitivity in sorting."""
    print("\n=== Demo 11: Case-Sensitive Sorting Control ===")

    words = ["Apple", "apple", "Banana", "banana", "Cherry", "cherry"]

    # Different collation strengths
    strengths = [
        ("primary", "Ignore case and accents"),
        ("secondary", "Consider accents, ignore case"),
        ("tertiary", "Consider case (default)"),
    ]

    for strength, description in strengths:
        collator = uicu.Collator("en-US", strength=strength)
        sorted_words = collator.sort(words)
        print(f"\n{description} (strength={strength}):")
        for word in sorted_words:
            print(f"  {word}")


def demo_12_bidirectional_text():
    """Demo 12: Handle mixed-direction text."""
    print("\n=== Demo 12: Bidirectional Text Handling ===")

    # Mixed LTR and RTL text
    examples = [
        "Hello שלום World",
        "The price is 123 ₪",
        "مرحبا Python مبرمج",
        "Email: user@example.com בעברית",
    ]

    print("Mixed-direction text examples:")
    for text in examples:
        print(f"\nText: {text}")

        # Analyze character directions
        def get_bidi_description(bidi_class):
            """Get human-readable description for bidirectional class."""
            if bidi_class in ["R", "AL"]:
                return "RTL"
            elif bidi_class == "L":
                return "LTR"
            elif bidi_class in ["EN", "AN"]:
                return "Number"
            else:
                return f"Other ({bidi_class})"

        for char in text:
            if char.strip():
                info = uicu.Char(char)
                bidi = info.bidirectional
                description = get_bidi_description(bidi)
                print(f"  '{char}' → {description}")


def main():
    """Run all demonstrations."""
    print("╔═══════════════════════════════════════════════════════╗")
    print("║          uicu - Unicode Text Processing Demos         ║")
    print("╚═══════════════════════════════════════════════════════╝")

    demos = [
        demo_1_character_exploration,
        demo_2_multilingual_sorting,
        demo_3_text_segmentation,
        demo_4_script_conversion,
        demo_5_locale_aware_formatting,
        demo_6_numeric_collation,
        demo_7_text_transformation,
        demo_8_script_detection,
        demo_9_thai_word_breaking,
        demo_10_emoji_handling,
        demo_11_case_sensitive_sorting,
        demo_12_bidirectional_text,
    ]

    for i, demo in enumerate(demos, 1):
        print(f"\n{'=' * 60}")
        demo()
        # Non-interactive mode for scripting

    print("\n" + "=" * 60)
    print("All demos completed! Explore more at:")
    print("https://github.com/anthropics/uicu")


if __name__ == "__main__":
    main()
</file>

<file path="issues/issue102.md">
# Issue 102: Implement DateTimeFormatter

## Overview
Implement a locale-aware DateTimeFormatter class in `uicu.format` module that provides Pythonic interfaces to ICU's date and time formatting capabilities.

## Requirements

### Core Functionality
1. Format Python datetime objects according to locale conventions
2. Parse locale-formatted strings back to datetime objects
3. Support all ICU date/time styles (full, long, medium, short, none)
4. Handle custom patterns (both skeleton and explicit)
5. Proper timezone handling with Python tzinfo integration
6. Thread-safe implementation

### API Design

```python
from datetime import datetime
from uicu import Locale
from uicu.format import DateTimeFormatter

# Basic usage
formatter = DateTimeFormatter('en-US')
dt = datetime.now()
formatted = formatter.format(dt)  # "Jan 25, 2025, 3:45 PM"

# With locale object
locale = Locale('fr-FR')
formatter = locale.get_datetime_formatter(date_style='long', time_style='short')
formatted = formatter.format(dt)  # "25 janvier 2025 à 15:45"

# Custom patterns
formatter = DateTimeFormatter('en-US', pattern='EEEE, MMMM d, yyyy')
formatted = formatter.format(dt)  # "Saturday, January 25, 2025"

# Skeleton patterns (flexible)
formatter = DateTimeFormatter('en-US', skeleton='yMMMd')
formatted = formatter.format(dt)  # "Jan 25, 2025"

# Parsing
parsed = formatter.parse("Jan 25, 2025")  # Returns datetime object
```

## Implementation Plan

### 1. Create DateTimeFormatter Class
```python
class DateTimeFormatter:
    def __init__(
        self,
        locale: str | Locale,
        date_style: str = "medium",
        time_style: str = "medium",
        pattern: str | None = None,
        skeleton: str | None = None,
        timezone: str | tzinfo | None = None,
    ):
        """Initialize formatter with locale and style options."""
        
    def format(self, dt: datetime) -> str:
        """Format datetime to string."""
        
    def parse(self, text: str, lenient: bool = False) -> datetime:
        """Parse string to datetime."""
        
    def format_range(self, start: datetime, end: datetime) -> str:
        """Format datetime range (e.g., 'Jan 3-5, 2025')."""
```

### 2. Style Mapping
- Map string styles to ICU constants:
  - 'full' → icu.DateFormat.FULL
  - 'long' → icu.DateFormat.LONG
  - 'medium' → icu.DateFormat.MEDIUM
  - 'short' → icu.DateFormat.SHORT
  - 'none' → icu.DateFormat.NONE

### 3. Pattern Support
- If pattern provided: use icu.SimpleDateFormat
- If skeleton provided: use icu.DateTimePatternGenerator
- Otherwise: use style-based formatting

### 4. Timezone Handling
- Accept Python tzinfo objects
- Convert to ICU TimeZone
- Default to system timezone if not specified
- Preserve timezone information in parsed dates

### 5. Error Handling
- Raise FormattingError for invalid patterns
- Raise FormattingError for unparseable strings
- Provide helpful error messages with context

## Testing Requirements

### Unit Tests
1. Test all style combinations (date_style × time_style)
2. Test with various locales (en-US, fr-FR, ja-JP, ar-SA)
3. Test custom patterns and skeletons
4. Test timezone handling (UTC, local, specific zones)
5. Test parsing with valid and invalid inputs
6. Test date range formatting
7. Test edge cases (leap years, DST transitions)

### Integration Tests
1. Test with Locale.get_datetime_formatter()
2. Test round-trip formatting and parsing
3. Test with non-Gregorian calendars (future)

## Performance Considerations
- Cache SimpleDateFormat instances per pattern
- Reuse pattern generators
- Minimize timezone conversions
- Profile common use cases

## Documentation
- Comprehensive docstrings with examples
- Pattern syntax reference
- Skeleton vs pattern explanation
- Timezone handling guide
- Common formatting recipes

## Future Enhancements
- Relative time formatting ("3 days ago")
- Date interval formatting with custom patterns
- Field position tracking for UI highlighting
- Calendar system support (Islamic, Hebrew, etc.)
- Duration formatting

## Dependencies
- Requires icu.SimpleDateFormat
- Requires icu.DateFormat
- Requires icu.DateTimePatternGenerator
- Should integrate with Python's datetime and zoneinfo modules

## Success Criteria
1. All ICU date/time formatting features accessible
2. Natural Python datetime integration
3. >95% test coverage
4. Performance within 10% of raw PyICU
5. Clear documentation with examples
</file>

<file path="issues/issue202.md">
# Issue 202: Fix Transliterator Transform IDs

## Problem
Some transliterator transform IDs are not working correctly with ICU:
- "Russian-Latin" should be "Cyrillic-Latin"
- Some transforms like "Han-Latin" may not be available in all ICU builds
- Need better error handling and documentation of available transforms

## Tasks
1. Create a function to list available transliterator IDs
2. Document commonly used transform IDs
3. Add fallback handling for missing transforms
4. Update examples to use only widely-available transforms
5. Add validation for transform IDs before creating transliterators

## Test Cases
- Test all example transforms work on common ICU installations
- Verify error messages are helpful when transforms are unavailable
- Ensure the list of available transforms is accessible to users
</file>

<file path="research/res-gemi.md">
Create

# Specification for `uicu`: A Pythonic Internationalization Library

## Part 1: Analysis of Foundation Libraries & Rationale for `uicu`

The landscape of Python internationalization (i18n) is dominated by powerful,
yet often inaccessible, tools. While the standard library provides basic
Unicode support, complex, locale-sensitive operations require more specialized
libraries. The most comprehensive of these is `PyICU`, a Python binding for
the industry-standard "International Components for Unicode" (ICU) C++
libraries. ICU is the gold standard for i18n, implementing vast portions of
the Unicode Standard and the Common Locale Data Repository (CLDR). However,
`PyICU`'s power is encumbered by an Application Programming Interface (API)
that is fundamentally un-pythonic, creating a significant barrier to adoption
and effective use.

This specification details the design of `uicu`, a new Python library that
serves as a high-level, pythonic wrapper around `PyICU`. `uicu` is not a
replacement for `PyICU` but a carefully designed abstraction layer. Its goal
is to expose the full power of the ICU engine through an API that is natural,
intuitive, and seamlessly integrated with the Python language and its
ecosystem. Furthermore, where `PyICU`'s data is incomplete or less accessible,
particularly concerning script and writing system metadata, `uicu` will
strategically supplement its functionality with the `fontTools.unicodedata`
module, which provides access to the most current Unicode data. This document
provides a complete architectural blueprint for `uicu`, intended to guide its
implementation by a developer.

### 1.1 An Autopsy of the PyICU API: Power Encumbered by a C++ Legacy

To understand the necessity for `uicu`, one must first perform a critical
analysis of `PyICU`. The library is not flawed in its core function—it
successfully exposes the vast capabilities of ICU to Python. Its primary
deficiency lies in its design philosophy, which prioritizes a direct, one-to-
one mapping from the underlying C++ library over Python developer ergonomics.
This results in an API that feels alien to seasoned Python developers and
presents a steep learning curve for newcomers.

#### 1.1.1 The C++ Mirror

The `PyICU` API is, by design, a thin wrapper around the ICU4C C++ library.
There is no official API documentation for `PyICU` itself; the documentation
explicitly directs users to the ICU4C C++ API reference and provides a set of
translation patterns. This design choice has profound consequences for the
user experience:  

  * **Class Naming:** Class names are lifted directly from C++, resulting in `PascalCase` names like `Transliterator`, `BreakIterator`, `Collator`, and `DateFormat`, which deviate from Python's PEP 8 convention of `CapWords` for classes but are often used in contexts where `snake_case` functions would be more appropriate.  

  * **Method Naming:** Method names also follow the C++ `camelCase` convention (e.g., `getDisplayName`, `createInstance`, `nextBoundary`) rather than Python's `snake_case`.

  *  **Enumerations:** `PyICU` uses C-style enumerations, such as `icu.DateFormat.LONG` or `icu.UTransDirection.REVERSE`, which are represented as integer constants. A pythonic approach would favor string literals (`'long'`) or `Enum` types for better readability and self-documentation.

This direct mapping forces the Python developer to learn and operate within a
C++ paradigm, constantly translating concepts and consulting external, non-
Python documentation to perform even basic tasks.

#### 1.1.2 A Catalogue of Pythonic Anti-Patterns

The friction caused by `PyICU` extends beyond naming conventions into
fundamental API design patterns that conflict with established Python idioms.
The following examples represent the most significant sources of this
friction.

  *  **Mutable`UnicodeString` and In-Place Modification:** Python's native `str` type is immutable, a cornerstone of its design that ensures predictability and safety. In stark contrast, `PyICU`'s primary string type, `UnicodeString`, is mutable. This leads to one of the most un-pythonic patterns in the library: functions that modify arguments in-place. This "output parameter" pattern, common in C and C++, is highly unconventional in Python.

For example, to get the display name of a locale, the "ICU way" involves
passing a mutable `UnicodeString` object to be modified:

Python

    
        # PyICU: In-place modification (un-pythonic)
    from icu import UnicodeString, Locale
    locale = Locale('pt_BR')
    string_buffer = UnicodeString()
    name = locale.getDisplayName(string_buffer)
    # `name` is the same object as `string_buffer`, which has been modified.
    # name is string_buffer -> True
    

While `PyICU` often provides a more "Python way" that allocates a new string,
the existence and documentation of the in-place modification pattern is a
source of confusion and potential bugs. It violates the principle that
functions should return results without causing side effects on their
arguments.

  *  **Cumbersome Iteration:** Python's `for` loop is a powerful and elegant construct for iteration. `PyICU`'s iteration mechanisms, however, are low-level and stateful, requiring manual bookkeeping. The `BreakIterator`, used for segmenting text into words, sentences, or graphemes, is a prime example. Its usage is described as "a pain" and requires the developer to manually call `nextBoundary()` and track indices.

Python

    
        # PyICU: Manual, stateful iteration
    from icu import BreakIterator, Locale
    text = 'Bist du in der U-Bahn geboren?'
    de_words = BreakIterator.createWordInstance(Locale('de_DE'))
    de_words.setText(text)
    
    words =
    last_pos = 0
    while True:
        next_boundary = de_words.nextBoundary()
        if next_boundary == -1:
            break
        words.append(text[last_pos:next_boundary])
        last_pos = next_boundary
    # words ->
    

A Python developer expects a simple generator or an object that implements the
iterator protocol, allowing for `for word in segmenter:...`. Similarly, the
`StringEnumeration` object provides three different `next` methods (`next`,
`unext`, `snext`) for retrieving different string types, adding another layer
of complexity to what should be a straightforward iteration.

  *  **Opaque Type Conversions:** The library performs some automatic type conversions to bridge the gap between Python and ICU types. For instance, it converts Python `datetime` objects and numeric timestamps into ICU's `UDate` format (a float representing milliseconds since the Unix epoch). While intended as a convenience, this implicit magic can obscure what is happening under the hood. A float passed to a date function is automatically multiplied by 1000, a detail a developer must remember to correctly interpret the underlying `UDate` value. A pythonic library should either be explicit about its conversions or handle them so transparently that the user never needs to be aware of the internal types.

  *  **Generic Error Handling:** `PyICU` commendably translates ICU's C-style `UErrorCode` status values into a Python exception, `ICUError`. This is a significant improvement over checking return codes. However, using a single, generic exception type for the entire library is a missed opportunity. The ICU library can fail for hundreds of different reasons, from a malformed locale string to an invalid formatting pattern. A single `ICUError` forces the developer to parse the error message string to determine the cause of failure, making robust, programmatic error handling difficult.

The cumulative effect of these anti-patterns is a developer experience fraught
with friction. The initial hurdle of installing `PyICU`, which often requires
manual configuration of C++ compilers and library paths due to its dependency
on the ICU C++ libraries, is substantial. For a developer to overcome this
barrier only to be met with a non-intuitive API that requires consulting C++
documentation is a significant deterrent. This compounding friction
discourages the use of ICU's powerful features in the Python ecosystem. The
primary value of `uicu` is to eliminate this second, API-level barrier, thus
making the initial investment in installation a much more reasonable
proposition.

PyICU Anti-Pattern

|

Example `PyICU` Code

|

Problem Description

|

`uicu` Design Principle

|

Proposed `uicu` Code  
  
---|---|---|---|---  
  
In-place argument modification

|

`name = locale.getDisplayName(string_buffer)`

|

Violates Python's convention of immutability and functional returns. Confusing
and error-prone.

|

Immutability and Functional Returns

|

`name = locale.display_name()`  
  
Stateful, manual iteration

|

`while True: boundary = bi.nextBoundary()`

|

Verbose, low-level, and requires manual state tracking. Unnatural for Python
developers.

|

Iterable and Generator-based APIs

|

`for word in segmenter.segment(text):...`  
  
Verbose factory methods with constants

|

`df = DateFormat.createDateInstance(DateFormat.LONG, locale)`

|

Relies on C-style integer constants. Not self-documenting.

|

Object-Oriented Factories with String Keywords

|

`df = locale.get_date_formatter(style='long')`  
  
Ambiguous `key` function for sorting

|

`sorted(L, key=collator.getSortKey)`

|

The method name `getSortKey` is explicit but verbose. The object itself should
be the key.

|

Leverage Dunder Methods (`__call__`)

|

`sorted(L, key=my_collator)`  
  
Generic exception type

|

`except ICUError as e: if "U_ILLEGAL_ARGUMENT_ERROR" in str(e):...`

|

Prevents specific, programmatic error handling. Requires fragile string
parsing of error messages.

|

Rich, Specific Exception Hierarchy

|

`except uicu.ConfigurationError as e:...`  
  
Export to Sheets

#### 1.1.3 Core Functionality Mapping

Despite its challenging API, `PyICU` provides access to an unparalleled suite
of internationalization services. A successful wrapper must recognize and
preserve this power. The key functional domains of `PyICU` that `uicu` will
abstract include:

  *  **Locale:** Handling locale identifiers and providing access to locale-specific data (`icu.Locale`).

  *  **Collation:** Performing locale-sensitive string sorting (`icu.Collator`, `icu.RuleBasedCollator`).

  *  **Formatting:** Formatting dates, times, numbers, currencies, and lists according to locale conventions (`icu.DateFormat`, `icu.NumberFormat`, `icu.ListFormatter`).  

  * **Message Formatting:** Handling pluralization and gender in translated strings (`icu.MessageFormat`).  

  * **Transliteration:** Converting text between different scripts (e.g., Cyrillic to Latin) (`icu.Transliterator`).

  *  **Segmentation:** Breaking text into its logical components like graphemes, words, or sentences (`icu.BreakIterator`).

  *  **Time Zones:** Accessing ICU's comprehensive time zone database (`icu.TimeZone`, `icu.ICUtzinfo`).

`uicu`'s mission is to liberate this functionality, making it accessible
through a clean, pythonic interface.

### 1.2 The Strategic Role of `fontTools.unicodedata`

While `PyICU` is the primary engine for locale-sensitive operations, it is not
the ideal source for all Unicode character data. For this, `uicu` will turn to
`fontTools.unicodedata`, a module within the powerful `fontTools` library.
This is a strategic choice based on data currency, functional specialization,
and API quality.

#### 1.2.1 Decoupling from the Python Runtime

Python's standard library includes a `unicodedata` module. However, the
version of the Unicode Character Database (UCD) it contains is fixed to the
version of the Python interpreter itself. An application running on Python 3.9
will have an older UCD than one on Python 3.12. This can lead to
inconsistencies and an inability to work with the latest characters and
properties.

The `fontTools` library, when installed with the `[unicode]` extra, depends on
`unicodedata2`. `unicodedata2` is a standalone package whose versions are
explicitly tied to Unicode standard versions (e.g., `unicodedata2==15.0.0`
contains data from Unicode 15.0). By using `fontTools.unicodedata`, `uicu`
ensures that developers can access up-to-date Unicode data, independent of the
Python runtime they are using.

#### 1.2.2 Rich Script and Writing System Metadata

The most compelling reason to use `fontTools.unicodedata` is its specialized
functionality related to writing systems, a domain critical for typography and
advanced text processing. It provides a clean, direct API for accessing
properties that are not as easily surfaced through `PyICU`. Key functions
include :  

  * `script(char)`: Returns the four-letter ISO 15924 script code for a character (e.g., `'Latn'`, `'Cyrl'`).

  * `script_name(script_code)`: Converts a script code to its human-readable name (e.g., `'Latn'` -> `'Latin'`).

  * `block(char)`: Returns the Unicode block a character belongs to (e.g., `'Basic Latin'`).

  * `ot_tags_from_script(script_code)`: Provides the crucial mapping from a Unicode script code to its corresponding OpenType script tag(s), essential for font feature interaction.

  * `ot_tag_to_script(tag)`: Provides the reverse mapping.

This functionality directly addresses the needs of applications that go beyond
simple string comparison and formatting into the realm of text layout and font
manipulation.

#### 1.2.3 API Consistency

The API of `fontTools.unicodedata` is simple, functional, and pythonic. It
consists of straightforward functions that take a character or code and return
a result. This design philosophy serves as a model for the non-locale-
sensitive parts of `uicu`, reinforcing the goal of creating a clean and
predictable developer experience.

The use of both `PyICU` and `fontTools.unicodedata` introduces a potential for
inconsistency, as the Unicode data may come from two different sources (the
version of `libicu` linked by `PyICU` and the version of `unicodedata2` used
by `fontTools`). An application dealing with internationalization requires a
single, authoritative source of truth. A subtle bug could arise if a character
property check using one library yields a different result from a check using
the other.

To mitigate this, `uicu` will establish a clear "chain of command" for data
access. For general, non-locale-specific Unicode character properties (e.g.,
name, category, numeric value, script, block), `uicu` will default to
`fontTools.unicodedata` as the primary source, ensuring access to the latest
Unicode standard data. For all locale-sensitive operations (e.g., collation,
date/number formatting, segmentation), `uicu` will exclusively use the `PyICU`
engine, which relies on the comprehensive CLDR data bundled with ICU. This
hybrid approach, clearly defined and documented, provides the best of both
worlds: the most current character data and the most powerful i18n engine.

## Part 2: The `uicu` Library: A Detailed Specification

This section provides the complete architectural and API design for the `uicu`
library. It is intended to be a prescriptive blueprint for implementation,
detailing the structure, classes, methods, and behavior of the new library.

### 2.1 Guiding Principles of the `uicu` API

The design of `uicu` is governed by a set of core principles aimed at creating
an API that is powerful, discoverable, and above all, pythonic. These
principles are a direct response to the shortcomings identified in the `PyICU`
API and are informed by best practices in modern Python library design.

#### 2.1.1 The Pythonic Contract

  *  **Naming Conventions:** All public-facing modules, classes, functions, and methods will strictly adhere to PEP 8 naming conventions. Modules and functions will use `snake_case` (e.g., `uicu.collate`, `uicu.char.get_name`). Classes will use `CapWords` (e.g., `uicu.Locale`, `uicu.format.NumberFormatter`). This provides immediate visual consistency with the broader Python ecosystem.

  *  **Immutability by Default:** Where possible, objects will be immutable. Configuration objects like formatters and collators, once created and configured, will not be modifiable. All functions and methods will return new, native Python objects (`str`, `tuple`, `datetime.datetime`) rather than modifying arguments in-place or returning special wrapper types. This promotes a functional style and prevents unexpected side effects.

  *  **Native Type Integration:** The entire public API surface will exclusively accept and return standard Python types. A user will never need to instantiate or handle a `PyICU.UnicodeString` or be aware of the `UDate` timestamp format. All necessary conversions will be handled transparently within the `uicu` wrapper.

  *  **Leveraging the Language:** The library will make extensive use of Python's special "dunder" methods to make its objects behave intuitively. For example, segmenter objects will be iterable (`__iter__`), collator objects will be callable (`__call__`), and all objects will have useful string representations (`__str__`, `__repr__`).

#### 2.1.2 A Coherent, Object-Oriented Model

`uicu` will be structured around a clear, object-oriented model where objects
represent configured "service providers." Instead of a procedural approach
with standalone functions, the primary workflow will involve:

  1. Instantiating a central `uicu.Locale` object to define context.

  2. Using this `Locale` object as a factory to create specialized, locale-aware service objects (e.g., a `Collator` or `DateTimeFormatter`).

  3. Calling methods on these service objects to perform operations.

This pattern promotes encapsulation, reusability, and thread safety, as
configured service objects can be created once and used many times.

#### 2.1.3 A Rich Exception Hierarchy

To enable robust and specific error handling, `uicu` will define its own
exception hierarchy, inheriting from a common base exception. This allows
consumers of the library to write fine-grained `try...except` blocks, a
significant improvement over `PyICU`'s single `ICUError`.

The proposed hierarchy is:

  * `uicu.Error(Exception)`: The base exception for all errors originating from the `uicu` library.

    * `uicu.ConfigurationError(uicu.Error)`: Raised for errors during setup, such as providing an invalid locale identifier or a malformed rule string.

    * `uicu.FormattingError(uicu.Error)`: Raised by any of the formatters in the `uicu.format` sub-package for invalid patterns or inputs.

    * `uicu.CollationError(uicu.Error)`: Raised by the `uicu.collate` module for issues related to collation rules.

    * `uicu.SegmentationError(uicu.Error)`: Raised by the `uicu.segment` module.

    * `uicu.TransliterationError(uicu.Error)`: Raised for invalid transliteration IDs or rules.

Module/Class

|

Core Purpose

|

Key Method/Usage

|

Abstracts `PyICU` Component  
  
---|---|---|---  
  
`uicu.char`

|

Provides access to non-locale-specific Unicode character properties.

|

`uicu.char.script('A')`

|

`fontTools.unicodedata`  
  
`uicu.locale.Locale`

|

Represents a specific locale and acts as a factory for locale-sensitive
services.

|

`locale = uicu.Locale('de-DE')`

|

`icu.Locale`  
  
`uicu.collate.Collator`

|

Provides locale-sensitive string comparison for sorting.

|

`sorted(L, key=collator)`

|

`icu.Collator`  
  
`uicu.format.DateTimeFormatter`

|

Formats `datetime` objects into locale-specific strings.

|

`formatter.format(datetime.now())`

|

`icu.DateFormat`  
  
`uicu.format.NumberFormatter`

|

Formats numbers, currencies, and percentages.

|

`formatter.format_currency(123.45, 'EUR')`

|

`icu.NumberFormat`  
  
`uicu.format.ListFormatter`

|

Joins a list of strings with locale-correct conjunctions.

|

`formatter.format(['a', 'b', 'c'])`

|

`icu.ListFormatter`  
  
`uicu.segment.WordSegmenter`

|

Segments text into words according to locale-specific rules.

|

`for word in segmenter.segment(text):...`

|

`icu.BreakIterator`  
  
`uicu.translit`

|

Provides functions for script transliteration.

|

`uicu.translit.transliterate(text, 'Cyrl-Latn')`

|

`icu.Transliterator`  
  
Export to Sheets

### 2.2 The `uicu.char` Module: A Unified View of Character Properties

This module will serve as the single, authoritative source for non-locale-
sensitive Unicode character data, implementing the "Data Authority Principle."
It will primarily delegate to `fontTools.unicodedata` to ensure access to the
latest Unicode version data.  

**Functions:**

All functions will take a single argument, `char`, which must be a string of
length 1. They will raise a `ValueError` if the string is not of length 1.

  * `name(char: str, default: Any =...) -> str`: Returns the official Unicode name for the character. If no name exists and a default is provided, returns the default; otherwise, raises a `KeyError`.

  * `category(char: str) -> str`: Returns the two-letter general category abbreviation (e.g., 'Lu', 'Nd', 'Po').

  * `numeric(char: str, default: Any =...) -> Union[int, float]`: Returns the numeric value of the character.

  * `script(char: str) -> str`: Returns the four-letter ISO 15924 script code (e.g., 'Latn').

  * `script_name(char: str) -> str`: Returns the human-readable script name (e.g., 'Latin').

  * `block(char: str) -> str`: Returns the name of the Unicode block the character belongs to.

  * `bidirectional(char: str) -> str`: Returns the bidirectional class (e.g., 'L', 'R', 'AN').

  * `combining(char: str) -> int`: Returns the canonical combining class as an integer.

  * `mirrored(char: str) -> bool`: Returns `True` if the character is a mirrored character in bidirectional text.

  * `is_private_use(char: str) -> bool`: Checks if the character is in a Private Use Area.

  * `is_control(char: str) -> bool`: Checks if the character is a C0 or C1 control code.

### 2.3 The `uicu.locale` Module: The Contextual Heart of the Library

This module defines the `Locale` class, which is the central entry point for
all locale-sensitive operations. It encapsulates a specific locale and acts as
a factory for service objects.

 **`uicu.Locale` Class:**

  *  **`__init__(self, locale_identifier: str)`**

    * Accepts a locale identifier string in BCP 47 format (e.g., `'en-GB'`, `'fr-CA'`, `'zh-Hant-TW'`).

    * The constructor will immediately call the underlying `icu.Locale.canonicalize` to validate and normalize the identifier, raising `uicu.ConfigurationError` on failure.

    * Internally stores the canonicalized `icu.Locale` object.

  *  **Properties (read-only):**

    * `display_name` -> `str`: The full, human-readable name of the locale in the default system locale's language (e.g., `'English (United Kingdom)'`).

    * `language_display_name` -> `str`: The human-readable name of the language (e.g., `'English'`).

    * `script_display_name` -> `str`: The human-readable name of the script.

    * `region_display_name` -> `str`: The human-readable name of the region.

    * `language` -> `str`: The two- or three-letter language code (e.g., `'en'`).

    * `script` -> `str`: The four-letter script code (e.g., `'Latn'`).

    * `region` -> `str`: The two-letter or three-digit region code (e.g., `'GB'`).

    * `base_name` -> `str`: The string representation of the canonicalized locale identifier.

  *  **Factory Methods:**

    * `get_collator(...) -> uicu.collate.Collator`: Returns a configured `Collator` object for this locale.

    * `get_datetime_formatter(...) -> uicu.format.DateTimeFormatter`: Returns a `DateTimeFormatter`.

    * `get_date_formatter(...) -> uicu.format.DateTimeFormatter`: A convenience for a date-only formatter.

    * `get_time_formatter(...) -> uicu.format.DateTimeFormatter`: A convenience for a time-only formatter.

    * `get_number_formatter(...) -> uicu.format.NumberFormatter`: Returns a `NumberFormatter`.

    * `get_list_formatter(...) -> uicu.format.ListFormatter`: Returns a `ListFormatter`.

    * `get_message_formatter(pattern: str) -> uicu.format.MessageFormatter`: Returns a `MessageFormatter` for a given pattern string.

    * `get_grapheme_segmenter() -> uicu.segment.GraphemeSegmenter`: Returns a segmenter for grapheme clusters.

    * `get_word_segmenter() -> uicu.segment.WordSegmenter`: Returns a segmenter for words.

    * `get_sentence_segmenter() -> uicu.segment.SentenceSegmenter`: Returns a segmenter for sentences.

### 2.4 The `uicu.collate` Module: Pythonic Sorting

This module provides an intuitive interface to ICU's powerful collation
engine.

 **`uicu.Collator` Class:**

This class is designed to be used directly as a `key` in sorting functions.

  *  **Instantiation:** Should not be instantiated directly. Use `locale.get_collator()`.

  *  **`__call__(self, text: str) -> bytes`:**

    * This is the core method. It takes a Python string and returns a binary sort key. When used as `sorted(my_list, key=my_collator)`, Python's sorting algorithm will use these binary keys for comparison.

    * This transparently wraps `PyICU`'s `collator.getSortKey(text)`.

  *  **`compare(self, a: str, b: str) -> int`:**

    * Explicitly compares two strings, returning -1, 0, or 1. Wraps `collator.compare(a, b)`.

  *  **Configuration (Builder Pattern):**

    * The `locale.get_collator()` method will accept optional arguments for common configurations. For advanced customization, a builder-style API could be considered for future extension to avoid the complexity of raw ICU rule strings.

 _Example Usage:_

Python

    
        import uicu
    locale = uicu.Locale('sv-SE') # Swedish
    collator = locale.get_collator()
    data = ['ångström', 'apple', 'zebra']
    # The collator object is used directly as the key
    sorted_data = sorted(data, key=collator)
    # Expected: ['apple', 'zebra', 'ångström']
    

### 2.5 The `uicu.format` Sub-package: Intuitive Data Formatting

This sub-package contains a suite of classes, each dedicated to a specific
formatting task.

 **`uicu.format.DateTimeFormatter`:**

  *  **Instantiation:** Via `locale.get_datetime_formatter(date_style: str = 'medium', time_style: str = 'medium', pattern: str = None, timezone: Union[str, datetime.tzinfo] = None)`.

    * `date_style` / `time_style` accept strings: `'full'`, `'long'`, `'medium'`, `'short'`, `'none'`. This replaces `icu.DateFormat.kDefault`, `LONG`, etc..

    * `pattern` allows for custom format strings (e.g., `'yyyy-MM-dd'`).

    * `timezone` accepts a timezone ID string (e.g., `'Europe/Berlin'`) or a `datetime.tzinfo` object.

  *  **`format(self, dt: datetime.datetime) -> str`:** Accepts a standard Python `datetime` object and returns a formatted string.

 **`uicu.format.NumberFormatter`:**

  *  **Instantiation:** Via `locale.get_number_formatter(style: str = 'decimal', pattern: str = None, min_fraction_digits: int = None,...)`

    * `style` accepts strings: `'decimal'`, `'percent'`, `'currency'`, `'scientific'`.

  *  **`format(self, number: Union) -> str`:** Formats a number.

  *  **`format_currency(self, number: Union, currency: str) -> str`:** A dedicated method for currency formatting that takes a 3-letter ISO 4217 currency code (e.g., `'USD'`, `'EUR'`).

 **`uicu.format.ListFormatter`:**

  *  **Instantiation:** Via `locale.get_list_formatter(style: str = 'standard', list_type: str = 'and')`.

    * `list_type` accepts `'and'`, `'or'`, or `'units'`.

  *  **`format(self, items: Iterable[str]) -> str`:** Joins an iterable of strings. _Example Usage:_ `locale.get_list_formatter().format(['one', 'two', 'three'])` -> `'one, two, and three'` (in English).

 **`uicu.format.MessageFormatter`:**

  *  **Instantiation:** Via `locale.get_message_formatter(pattern: str)`.

  *  **`format(self, **kwargs) -> str` or `format(params: Dict[str, Any]) -> str`:** Formats the message using ICU's rich plural and select rule syntax. _Example Usage:_

Python

    
        pattern = "{count, plural, one{# apple} other{# apples}} for {gender, select, male{him} female{her} other{them}}."
    msg_fmt = uicu.Locale('en').get_message_formatter(pattern)
    result = msg_fmt.format(count=1, gender='female')
    # result -> '1 apple for her'
    

### 2.6 The `uicu.segment` Module: Natural Text Segmentation

This module provides pythonic iterators for text boundary analysis, completely
abstracting the stateful `BreakIterator`.

 **`GraphemeSegmenter`, `WordSegmenter`, `SentenceSegmenter` Classes:**

  *  **Instantiation:** Via factory methods on a `Locale` object (e.g., `locale.get_word_segmenter()`). The segmenters are lightweight and can be created on-the-fly.

  *  **`segment(self, text: str) -> Iterator[str]`:**

    * This is the primary method for all segmenter classes. It takes a string and returns a generator that yields the segmented parts of the string.

    * This design allows for efficient, lazy processing of large texts and fits perfectly with Python's iteration patterns.

 _Example Usage:_

Python

    
        import uicu
    text = "The quick brown fox. It jumped."
    segmenter = uicu.Locale('en').get_sentence_segmenter()
    sentences = list(segmenter.segment(text))
    # sentences ->
    
    word_segmenter = uicu.Locale('en').get_word_segmenter()
    words = [word for word in word_segmenter.segment(text) if word.strip()]
    # words ->
    

### 2.7 The `uicu.translit` Module: Simplified Transliteration

This module provides a clean, functional interface for ICU's transliteration
capabilities.

  *  **`transliterate(text: str, transform_id: str) -> str`**

    * A high-level convenience function for one-off transformations. It creates, uses, and discards a `Transliterator` object internally.

    * `transform_id` is a string like `'Greek-Latin'` or `'Any-Hex'`. A list of available IDs can be retrieved via another function, `get_available_ids()`.

    * Raises `uicu.TransliterationError` if the `transform_id` is invalid.

  *  **`get_transliterator(transform_id: str, reverse: bool = False) -> Callable[[str], str]`**

    * A factory function for performance-sensitive applications where the same transformation is applied many times.

    * It pre-compiles the transliteration rule set by calling `icu.Transliterator.createInstance` and returns a simple, highly-optimized callable object (e.g., a function or a callable class instance).

    * This separates the expensive setup cost from the repeated application cost.

 _Example Usage:_

Python

    
        import uicu
    
    # Simple, one-off usage
    latin = uicu.translit.transliterate('Ψάπφω', 'Greek-Latin')
    # latin -> 'Psápphō'
    
    # Performant, repeated usage
    greek_to_latin = uicu.translit.get_transliterator('Greek-Latin')
    names = ['Σωκράτης', 'Πλάτων', 'Ἀριστοτέλης']
    latin_names = [greek_to_latin(name) for name in names]
    

## Part 3: Implementation and Documentation Roadmap

A successful library is more than just its code; it is the sum of its
implementation quality, documentation, and testing infrastructure. This
section provides a roadmap for building `uicu` into a robust, maintainable,
and user-friendly package.

### 3.1 Project Scaffolding and Dependencies

The project will be structured according to modern Python packaging best
practices to ensure compatibility with standard development and deployment
tools.

  *  **Directory Structure:**
    
        uicu/
    ├── docs/              # Sphinx documentation source
    ├── src/
    │   └── uicu/          # Main package source code
    │       ├── __init__.py
    │       ├── char.py
    │       ├── collate.py
    │       ├── locale.py
    │       ├── segment.py
    │       ├── translit.py
    │       └── format/
    │           ├── __init__.py
    │           └──...
    ├── tests/             # Pytest test suite
    ├── LICENSE
    ├── pyproject.toml     # Project metadata and build configuration
    └── README.md
    

  * **`pyproject.toml` Configuration:** This file is the single source of truth for project metadata and build dependencies. A minimal configuration would be:

Ini, TOML

    
        [project]
    name = "uicu"
    version = "0.1.0"
    description = "A pythonic, high-level wrapper for PyICU."
    readme = "README.md"
    requires-python = ">=3.8"
    license = { text = "MIT" }
    authors = [
        { name = "Your Name", email = "your@email.com" }
    ]
    classifiers =
    dependencies = [
        "pyicu >= 2.10",
        "fonttools[unicode] >= 4.40.0"
    ]
    
    [project.urls]
    Homepage = "https://github.com/user/uicu"
    Documentation = "https://uicu.readthedocs.io"
    Repository = "https://github.com/user/uicu"
    
    [build-system]
    requires = ["hatchling"]
    build-backend = "hatchling.build"
    

The critical line is `fonttools[unicode] >= 4.40.0`. The `[unicode]` extra
ensures that the `unicodedata2` dependency is installed, providing the up-to-
date Unicode data that is central to the library's design.

### 3.2 A Culture of Documentation and Testing

For a wrapper library like `uicu`, where the primary value proposition is an
improved developer experience, documentation is not an afterthought—it is a
core feature. The opaque and C++-centric nature of `PyICU`'s documentation is
a major usability obstacle. `uicu` must provide a comprehensive, python-first
documentation experience.

  *  **API Documentation:** Every public class, method, and function must have a comprehensive docstring following a standard format like Google Style or reST. This enables tools like Sphinx to automatically generate a professional API reference. Each docstring must include:

    * A one-line summary.

    * A more detailed explanation of its behavior.

    * Descriptions for all arguments (`Args:`).

    * A description of the return value (`Returns:`).

    * Any exceptions that may be raised (`Raises:`).

    * A simple, runnable code example (`Example:`).

  *  **User-Facing Documentation (to be built with Sphinx):** The documentation should be structured into four distinct categories, following the Diátaxis framework:

    1.  **Tutorials / Quickstart:** A "Getting Started" guide that begins with a consolidated, best-practice guide for installing `PyICU` and its dependencies, drawing from the scattered advice found online. It will then walk the user through a compelling, end-to-end example, such as sorting a list of Swedish names and formatting a date for a German locale.

    2.  **How-To Guides:** Topic-specific, goal-oriented recipes. The most important of these will be a guide titled **"From`PyICU` to `uicu`"**. This document will explicitly show "before" (`PyICU`) and "after" (`uicu`) code for common tasks, directly addressing the anti-patterns identified in Part 1. This provides a clear migration path and immediately demonstrates the library's value to existing `PyICU` users.

    3.  **Explanation / Discussion:** Conceptual articles that explain the "why" behind `uicu`'s design. This will include a page on the "Data Authority Principle," explaining the hybrid use of `PyICU` and `fontTools.unicodedata` and the rationale for it.

    4.  **API Reference:** The complete, auto-generated reference from the code's docstrings.

  *  **Testing Strategy (to be implemented with Pytest):** A rigorous test suite is non-negotiable for ensuring the correctness and stability of the wrapper.

    *  **Unit Tests:** Each module in `uicu` should have corresponding unit tests that mock the underlying `PyICU` and `fontTools` calls. These tests will verify that the wrapper logic (e.g., argument handling, type conversion, method delegation) is correct in isolation.

    *  **Integration Tests:** A suite of tests that use the real `PyICU` and `fontTools` libraries to verify end-to-end functionality. These tests should cover a representative set of locales (e.g., a LTR language like German, a RTL language like Arabic, a CJK language like Japanese) and use cases to ensure the abstractions behave as expected.

    *  **Exception Tests:** Tests must be written to confirm that the correct `uicu` exceptions are raised under specific failure conditions (e.g., passing an invalid locale to `uicu.Locale` should raise `uicu.ConfigurationError`).

    *  **Test Coverage:** The project should aim for high test coverage (e.g., >95%) and use tools to track it, ensuring that all logic paths are exercised.

Sources used in the report

[![](https://t3.gstatic.com/faviconV2?url=https://fonttools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)fonttools.readthedocs.iounicodedata:
Interface to character and script data in Unicode and ... Opens in a new
window
](https://fonttools.readthedocs.io/en/latest/unicodedata/index.html)[![](https://t0.gstatic.com/faviconV2?url=https://unicode-
org.github.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)unicode-
org.github.ioICU 77.1: Main Page Opens in a new window ](https://unicode-
org.github.io/icu-
docs/apidoc/dev/icu4c/)[![](https://t1.gstatic.com/faviconV2?url=https://gitee.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitee.comopenKylin/pyicu
- Gitee Opens in a new window ](https://gitee.com/openkylin/pyicu)

Sources read but not used in the report

[![](https://t3.gstatic.com/faviconV2?url=https://www.bedrick.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)bedrick.orgPython's
ICU Bindings - Steven Bedrick Opens in a new window
](https://www.bedrick.org/notes/python-icu-
bindings/)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.comREADME.md
- ovalhub/pyicu - GitHub Opens in a new window
](https://github.com/ovalhub/pyicu/blob/master/README.md)[![](https://t0.gstatic.com/faviconV2?url=https://gitlab.pyicu.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitlab.pyicu.orgsamples
· main · main / pyicu · GitLab Opens in a new window
](https://gitlab.pyicu.org/main/pyicu/-/tree/main/samples)[![](https://t3.gstatic.com/faviconV2?url=https://www.freshports.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)freshports.orgFreshPorts
-- devel/py-pyicu: Python extension wrapping the ICU C++ API Opens in a new
window ](https://www.freshports.org/devel/py-
pyicu/)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.compyicu/CHANGES
at master - GitHub Opens in a new window
](https://github.com/ovalhub/pyicu/blob/master/CHANGES)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comHow
to correctly install PyICU on Heroku? - Stack Overflow Opens in a new window
](https://stackoverflow.com/questions/67646388/how-to-correctly-install-pyicu-
on-
heroku)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comInstall
Pyicu in python 3.x - Stack Overflow Opens in a new window
](https://stackoverflow.com/questions/46871401/install-pyicu-in-
python-3-x)[![](https://t1.gstatic.com/faviconV2?url=https://llego.dev/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)llego.devAPI
Design and Testing in Python Technical Interviews - llego.dev Opens in a new
window ](https://llego.dev/posts/api-design-testing-python-technical-
interviews/)[![](https://t0.gstatic.com/faviconV2?url=https://dev.to/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)dev.toA
Pythonic Guide to SOLID Design Principles - DEV Community Opens in a new
window ](https://dev.to/ezzy1337/a-pythonic-guide-to-solid-design-
principles-4c8i)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgpyicu
- PyPI Opens in a new window
](https://pypi.org/project/pyicu/)[![](https://t2.gstatic.com/faviconV2?url=https://roguelynn.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)roguelynn.comDesign
of Everyday APIs · roguelynn - Lynn Root Opens in a new window
](https://roguelynn.com/words/everyday-
apis/)[![](https://t2.gstatic.com/faviconV2?url=https://www.pypistats.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypistats.orgpyicu
- PyPI Download Stats Opens in a new window
](https://www.pypistats.org/packages/pyicu)[![](https://t3.gstatic.com/faviconV2?url=https://realpython.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)realpython.comReal
Python: Python Tutorials Opens in a new window
](https://realpython.com/)[![](https://t0.gstatic.com/faviconV2?url=https://gitlab.pyicu.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitlab.pyicu.orgcommon.cpp
- main / pyicu · GitLab Opens in a new window
](https://gitlab.pyicu.org/main/pyicu/-/blob/main/common.cpp?ref_type=heads)[![](https://t3.gstatic.com/faviconV2?url=https://anaconda.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)anaconda.orgPyicu
- Anaconda.org Opens in a new window ](https://anaconda.org/conda-
forge/pyicu)[![](https://t1.gstatic.com/faviconV2?url=https://www.piwheels.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)piwheels.orgPyICU-
binary - piwheels Opens in a new window
](https://www.piwheels.org/project/pyicu-
binary/)[![](https://t0.gstatic.com/faviconV2?url=https://gist.github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gist.github.comInstallation
instructions for libicu-dev, PyICU, libpostal, pypostal on Mac OS X - GitHub
Gist Opens in a new window
](https://gist.github.com/ddelange/6e04e81b99fae08e817a00515d4a378d)[![](https://t3.gstatic.com/faviconV2?url=https://realpython.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)realpython.comPython
and REST APIs: Interacting With Web Services Opens in a new window
](https://realpython.com/api-integration-in-
python/)[![](https://t3.gstatic.com/faviconV2?url=https://hajloo.wordpress.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)hajloo.wordpress.comHow
to Use FontTools Module in Python | Hadjloo's Daily Notes - WordPress.com
Opens in a new window ](https://hajloo.wordpress.com/2011/07/15/how-to-use-
fonttools-module-in-
python/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comPip
can't install pyicu - Stack Overflow Opens in a new window
](https://stackoverflow.com/questions/68349833/pip-cant-install-
pyicu)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.comarrowtype/fonttools-
intro: An introduction to FontTools & font development - GitHub Opens in a new
window ](https://github.com/arrowtype/fonttools-
intro)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.comfonttools/fonttools:
A library to manipulate font files from Python. - GitHub Opens in a new window
](https://github.com/fonttools/fonttools)[![](https://t0.gstatic.com/faviconV2?url=https://docs.unity3d.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.unity3d.comOptimize
font files with font subsetting - Unity - Manual Opens in a new window
](https://docs.unity3d.com/6000.2/Documentation/Manual/UIE-font-
subsetting.html)[![](https://t2.gstatic.com/faviconV2?url=https://markoskon.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)markoskon.comCreating
font subsets - Dev Diary Opens in a new window
](https://markoskon.com/creating-font-
subsets/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comHow
to use fontTools to detect Type 1 and OpenType CFF fonts - Stack Overflow
Opens in a new window ](https://stackoverflow.com/questions/55966692/how-to-
use-fonttools-to-detect-type-1-and-opentype-cff-
fonts)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgfonttools
- PyPI Opens in a new window
](https://pypi.org/project/fonttools/4.51.0/)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgfonttools
- PyPI Opens in a new window
](https://pypi.org/project/fonttools/)[![](https://t3.gstatic.com/faviconV2?url=https://fonttools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)fonttools.readthedocs.io—fontTools
Documentation— — fontTools Documentation Opens in a new window
](https://fonttools.readthedocs.io/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comHow
to use pyftsubset of Fonttools inside of the python environment, not from the
command line - Stack Overflow Opens in a new window
](https://stackoverflow.com/questions/55009981/how-to-use-pyftsubset-of-
fonttools-inside-of-the-python-environment-not-from-
th)[![](https://t0.gstatic.com/faviconV2?url=https://gist.github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gist.github.comPyICU
cheat sheet · GitHub Opens in a new window
](https://gist.github.com/dpk/8325992)[![](https://t0.gstatic.com/faviconV2?url=https://retailtechinnovationhub.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)retailtechinnovationhub.comThe
ultimate guide to structuring a Python package - Retail Technology Innovation
Hub Opens in a new window
](https://retailtechinnovationhub.com/home/2024/2/29/the-ultimate-guide-to-
structuring-a-python-
package)[![](https://t0.gstatic.com/faviconV2?url=https://help.autodesk.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)help.autodesk.comPython
API Best Practices - Autodesk Help Opens in a new window
](https://help.autodesk.com/view/SGDEV/ENU/?guid=SGD_py_python_api_best_practices_html)[![](https://t1.gstatic.com/faviconV2?url=https://nsls-
ii.github.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)nsls-
ii.github.ioGuiding Design Principles — Scientific Python Cookiecutter 0.1
documentation Opens in a new window ](https://nsls-ii.github.io/scientific-
python-cookiecutter/guiding-design-
principles.html)[![](https://t3.gstatic.com/faviconV2?url=https://docs.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.python.orgunicodedata
— Unicode Database — Python 3.13.5 documentation Opens in a new window
](https://docs.python.org/3/library/unicodedata.html)[![](https://t0.gstatic.com/faviconV2?url=https://dev.to/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)dev.toMastering
REST API Best Practices in Python - DEV Community Opens in a new window
](https://dev.to/biswajitfsd/mastering-rest-api-best-practices-in-
python-5bda)[![](https://t0.gstatic.com/faviconV2?url=https://www.stuartellis.name/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stuartellis.nameModern
Good Practices for Python Development - Stuart Ellis Opens in a new window
](https://www.stuartellis.name/articles/python-modern-
practices/)[![](https://t3.gstatic.com/faviconV2?url=https://www.freshports.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)freshports.orgFreshPorts
-- devel/py-unicodedata2: Unicodedata backport updated to the latest Unicode
version Opens in a new window ](https://www.freshports.org/devel/py-
unicodedata2)[![](https://t2.gstatic.com/faviconV2?url=https://stackoverflow.blog/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.blogBest
practices for REST API design - The Stack Overflow Blog Opens in a new window
](https://stackoverflow.blog/2020/03/02/best-practices-for-rest-api-
design/)[![](https://t2.gstatic.com/faviconV2?url=https://docs.python-
guide.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.python-
guide.orgStructuring Your Project - The Hitchhiker's Guide to Python Opens in
a new window ](https://docs.python-
guide.org/writing/structure/)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgunicodedata2
- PyPI Opens in a new window
](https://pypi.org/project/unicodedata2/)[![](https://t3.gstatic.com/faviconV2?url=https://peps.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)peps.python.orgPEP
8 – Style Guide for Python Code | peps.python.org Opens in a new window
](https://peps.python.org/pep-0008/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.compython:
how to add 'unicodedata' module to my current python lib - Stack Overflow
Opens in a new window ](https://stackoverflow.com/questions/26583944/python-
how-to-add-unicodedata-module-to-my-current-python-
lib)[![](https://t3.gstatic.com/faviconV2?url=https://salishsea-meopar-
tools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)salishsea-
meopar-tools.readthedocs.ioGuidelines and Best Practices for Writing Library
Code Opens in a new window ](https://salishsea-meopar-
tools.readthedocs.io/en/latest/python_packaging/library_code.html)[![](https://t1.gstatic.com/faviconV2?url=https://prefix.dev/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)prefix.devunicodedata2
- conda-forge - prefix.dev Opens in a new window
](https://prefix.dev/channels/conda-
forge/packages/unicodedata2)[![](https://t2.gstatic.com/faviconV2?url=https://benhoyt.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)benhoyt.comDesigning
Pythonic library APIs - Ben Hoyt Opens in a new window
](https://benhoyt.com/writings/python-api-
design/)[![](https://t3.gstatic.com/faviconV2?url=https://anaconda.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)anaconda.orgConda
- Anaconda.org Opens in a new window ](https://anaconda.org/conda-
forge/unicodedata2/)[![](https://t2.gstatic.com/faviconV2?url=https://packaging.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)packaging.python.orgPackaging
Python Projects Opens in a new window
](https://packaging.python.org/tutorials/packaging-projects/)

Thoughts

Understanding the Goal

I'm starting a new research task to design a Python library called `uicu`.
This library will serve as a more intuitive and Pythonic wrapper around
`PyICU`, with additional capabilities from `fontTools.unicodedata`. My main
goal is to create a detailed specification for this new library, making it
easy for a junior developer to implement.

Initial Research Approach

My first step is to thoroughly understand the existing APIs of both `PyICU`
and `fontTools.unicodedata`. I'll be looking into their modules, classes, and
methods, paying close attention to areas where `PyICU` might be powerful but
less Pythonic. I'll also investigate how `fontTools.unicodedata` handles
script and property information, and how it compares to Python's standard
`unicodedata` module.

Next Steps in Planning

After understanding the existing libraries, I'll compare their features to
identify overlaps and unique functionalities, which will guide decisions on
how to integrate them into `uicu`. I'll also research best practices for
Python API design to ensure `uicu` is truly Pythonic. Finally, I'll outline
the modular structure, define core objects, and plan for seamless integration
with Python's built-in string types, performance considerations,
documentation, and error handling. I'm beginning by gathering all relevant
documentation for both libraries.

![](https://www.gstatic.com/lamda/images/immersives/google_logo_icon_2380fba942c84387f09cf.svg)

Researching websites

[![](https://t3.gstatic.com/faviconV2?url=https://www.bedrick.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)bedrick.orgPython's
ICU Bindings - Steven Bedrick](https://www.bedrick.org/notes/python-icu-
bindings/)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.comREADME.md
- ovalhub/pyicu -
GitHub](https://github.com/ovalhub/pyicu/blob/master/README.md)[![](https://t0.gstatic.com/faviconV2?url=https://unicode-
org.github.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)unicode-
org.github.ioICU 77.1: Main Page](https://unicode-org.github.io/icu-
docs/apidoc/dev/icu4c/)[![](https://t0.gstatic.com/faviconV2?url=https://gitlab.pyicu.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitlab.pyicu.orgsamples
· main · main / pyicu ·
GitLab](https://gitlab.pyicu.org/main/pyicu/-/tree/main/samples)[![](https://t3.gstatic.com/faviconV2?url=https://www.freshports.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)freshports.orgFreshPorts
-- devel/py-pyicu: Python extension wrapping the ICU C++
API](https://www.freshports.org/devel/py-
pyicu/)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.compyicu/CHANGES
at master -
GitHub](https://github.com/ovalhub/pyicu/blob/master/CHANGES)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comHow
to correctly install PyICU on Heroku? - Stack
Overflow](https://stackoverflow.com/questions/67646388/how-to-correctly-
install-pyicu-on-
heroku)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comInstall
Pyicu in python 3.x - Stack
Overflow](https://stackoverflow.com/questions/46871401/install-pyicu-in-
python-3-x)[![](https://t0.gstatic.com/faviconV2?url=https://gist.github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gist.github.comPyICU
cheat sheet - Gist -
GitHub](https://gist.github.com/dpk/8325992)[![](https://t1.gstatic.com/faviconV2?url=https://llego.dev/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)llego.devAPI
Design and Testing in Python Technical Interviews -
llego.dev](https://llego.dev/posts/api-design-testing-python-technical-
interviews/)[![](https://t1.gstatic.com/faviconV2?url=https://gitee.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitee.comopenKylin/pyicu
-
Gitee](https://gitee.com/openkylin/pyicu)[![](https://t0.gstatic.com/faviconV2?url=https://dev.to/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)dev.toA
Pythonic Guide to SOLID Design Principles - DEV
Community](https://dev.to/ezzy1337/a-pythonic-guide-to-solid-design-
principles-4c8i)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgpyicu
-
PyPI](https://pypi.org/project/pyicu/)[![](https://t2.gstatic.com/faviconV2?url=https://roguelynn.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)roguelynn.comDesign
of Everyday APIs · roguelynn - Lynn
Root](https://roguelynn.com/words/everyday-
apis/)[![](https://t2.gstatic.com/faviconV2?url=https://www.pypistats.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypistats.orgpyicu
- PyPI Download
Stats](https://www.pypistats.org/packages/pyicu)[![](https://t3.gstatic.com/faviconV2?url=https://realpython.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)realpython.comReal
Python: Python
Tutorials](https://realpython.com/)[![](https://t0.gstatic.com/faviconV2?url=https://gitlab.pyicu.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitlab.pyicu.orgcommon.cpp
- main / pyicu ·
GitLab](https://gitlab.pyicu.org/main/pyicu/-/blob/main/common.cpp?ref_type=heads)[![](https://t3.gstatic.com/faviconV2?url=https://anaconda.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)anaconda.orgPyicu
- Anaconda.org](https://anaconda.org/conda-
forge/pyicu)[![](https://t1.gstatic.com/faviconV2?url=https://www.piwheels.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)piwheels.orgPyICU-
binary - piwheels](https://www.piwheels.org/project/pyicu-
binary/)[![](https://t0.gstatic.com/faviconV2?url=https://gist.github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gist.github.comInstallation
instructions for libicu-dev, PyICU, libpostal, pypostal on Mac OS X - GitHub
Gist](https://gist.github.com/ddelange/6e04e81b99fae08e817a00515d4a378d)[![](https://t3.gstatic.com/faviconV2?url=https://realpython.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)realpython.comPython
and REST APIs: Interacting With Web Services](https://realpython.com/api-
integration-in-
python/)[![](https://t0.gstatic.com/faviconV2?url=https://dev.to/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)dev.toMastering
REST API Best Practices in Python - DEV
Community](https://dev.to/biswajitfsd/mastering-rest-api-best-practices-in-
python-5bda)[![](https://t2.gstatic.com/faviconV2?url=https://benhoyt.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)benhoyt.comDesigning
Pythonic library APIs - Ben Hoyt](https://benhoyt.com/writings/python-api-
design/)[![](https://t3.gstatic.com/faviconV2?url=https://hajloo.wordpress.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)hajloo.wordpress.comHow
to Use FontTools Module in Python | Hadjloo's Daily Notes -
WordPress.com](https://hajloo.wordpress.com/2011/07/15/how-to-use-fonttools-
module-in-
python/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comPip
can't install pyicu - Stack
Overflow](https://stackoverflow.com/questions/68349833/pip-cant-install-
pyicu)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.comarrowtype/fonttools-
intro: An introduction to FontTools & font development -
GitHub](https://github.com/arrowtype/fonttools-
intro)[![](https://t1.gstatic.com/faviconV2?url=https://github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)github.comfonttools/fonttools:
A library to manipulate font files from Python. -
GitHub](https://github.com/fonttools/fonttools)[![](https://t0.gstatic.com/faviconV2?url=https://docs.unity3d.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.unity3d.comOptimize
font files with font subsetting - Unity -
Manual](https://docs.unity3d.com/6000.2/Documentation/Manual/UIE-font-
subsetting.html)[![](https://t2.gstatic.com/faviconV2?url=https://markoskon.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)markoskon.comCreating
font subsets - Dev Diary](https://markoskon.com/creating-font-
subsets/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comHow
to use fontTools to detect Type 1 and OpenType CFF fonts - Stack
Overflow](https://stackoverflow.com/questions/55966692/how-to-use-fonttools-
to-detect-type-1-and-opentype-cff-
fonts)[![](https://t3.gstatic.com/faviconV2?url=https://docs.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.python.orgunicodedata
— Unicode Database — Python 3.13.5
documentation](https://docs.python.org/3/library/unicodedata.html)[![](https://t3.gstatic.com/faviconV2?url=https://fonttools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)fonttools.readthedocs.iounicodedata:
Interface to character and script data in Unicode and
OpenType](https://fonttools.readthedocs.io/en/latest/unicodedata/index.html)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgfonttools
-
PyPI](https://pypi.org/project/fonttools/4.51.0/)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgfonttools
-
PyPI](https://pypi.org/project/fonttools/)[![](https://t3.gstatic.com/faviconV2?url=https://fonttools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)fonttools.readthedocs.io—fontTools
Documentation— — fontTools
Documentation](https://fonttools.readthedocs.io/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.comHow
to use pyftsubset of Fonttools inside of the python environment, not from the
command line - Stack
Overflow](https://stackoverflow.com/questions/55009981/how-to-use-pyftsubset-
of-fonttools-inside-of-the-python-environment-not-from-th)

Initial API Exploration

I've started by gathering information on PyICU and fontTools.unicodedata. For
PyICU, I've found a cheat sheet and official documentation that provide
insights into its core functionalities like transliteration, locale handling,
collation, date formatting, and break iteration. A key observation is that
PyICU often requires explicit `UnicodeString` objects and in-place
modifications, which is less Pythonic than working with native Python strings.
However, it also offers 'Pythonic' ways for some operations, like
`locale.getDisplayName()` returning a Python `str` directly. For
`fontTools.unicodedata`, the documentation highlights its role in accessing
Unicode character properties, script data, and OpenType script tags,
complementing the standard `unicodedata` module with more up-to-date and
specialized data.

Addressing Pythonic Design

I'm also looking into general principles for designing Pythonic APIs. Key
themes emerging include prioritizing intuitive and consistent naming, keeping
APIs simple and minimal, minimizing interdependencies between components
(loose coupling), and supporting versioning. The importance of clear
documentation, comprehensive testing (unit, integration, usability, load), and
effective error handling is also being emphasized. I'm noting examples of both
good and less ideal API designs within the Python standard library to inform
the `uicu` design.

Next Steps in Research

My next step is to delve deeper into the specifics of PyICU and
`fontTools.unicodedata` by browsing the identified key documentation. I'll
focus on understanding the nuances of their APIs, particularly the areas where
PyICU deviates from Pythonic conventions, to inform how `uicu` can bridge
these gaps. I'll also continue to synthesize information on Pythonic API
design to ensure the `uicu` library is both extensive and natural to use.

![](https://www.gstatic.com/lamda/images/immersives/google_logo_icon_2380fba942c84387f09cf.svg)

Researching websites

[![](https://t0.gstatic.com/faviconV2?url=https://gist.github.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gist.github.comPyICU
cheat sheet ·
GitHub](https://gist.github.com/dpk/8325992)[![](https://t3.gstatic.com/faviconV2?url=https://fonttools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)fonttools.readthedocs.iounicodedata:
Interface to character and script data in Unicode and
...](https://fonttools.readthedocs.io/en/latest/unicodedata/index.html)[![](https://t0.gstatic.com/faviconV2?url=https://unicode-
org.github.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)unicode-
org.github.ioICU 77.1: Main Page](https://unicode-org.github.io/icu-
docs/apidoc/dev/icu4c/)[![](https://t1.gstatic.com/faviconV2?url=https://gitee.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)gitee.comopenKylin/pyicu
- Gitee](https://gitee.com/openkylin/pyicu)

Deepening API Understanding

I've gained a clearer understanding of PyICU's API, confirming its direct
mapping to the ICU4C C++ library. This means it often uses mutable
`UnicodeString` objects and in-place modifications, which are less aligned
with Python's immutable string philosophy. I've also identified its reliance
on factory methods and verbose naming conventions. In contrast,
`fontTools.unicodedata` provides specialized Unicode character properties,
script, and OpenType-related information, building upon an updated Unicode
database, which complements Python's built-in `unicodedata` module.

Identifying Design Challenges

A significant challenge for `uicu` will be to abstract away PyICU's non-
Pythonic elements while retaining its powerful functionality. This involves
designing an API that feels natural to Python developers, potentially by
converting mutable `UnicodeString` objects to Python's native immutable
strings where appropriate, and by adopting more idiomatic Python patterns for
object creation and method calls. I'm also considering how to best integrate
the unique capabilities of `fontTools.unicodedata` to provide a comprehensive
and user-friendly experience.

Charting the Path Forward

My immediate next steps involve a detailed feature comparison between PyICU
and `fontTools.unicodedata` to pinpoint overlaps and unique strengths.
Concurrently, I'll synthesize the gathered Pythonic API design principles into
concrete goals for `uicu`. This will then lead to outlining the `uicu` package
structure, defining its core objects, and considering how to manage
performance and integrate seamlessly with Python's native types. I'll also
plan for robust documentation and a custom exception hierarchy.

![](https://www.gstatic.com/lamda/images/immersives/google_logo_icon_2380fba942c84387f09cf.svg)

Researching websites

[![](https://t0.gstatic.com/faviconV2?url=https://retailtechinnovationhub.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)retailtechinnovationhub.comThe
ultimate guide to structuring a Python package - Retail Technology Innovation
Hub](https://retailtechinnovationhub.com/home/2024/2/29/the-ultimate-guide-to-
structuring-a-python-
package)[![](https://t0.gstatic.com/faviconV2?url=https://help.autodesk.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)help.autodesk.comPython
API Best Practices - Autodesk
Help](https://help.autodesk.com/view/SGDEV/ENU/?guid=SGD_py_python_api_best_practices_html)[![](https://t1.gstatic.com/faviconV2?url=https://nsls-
ii.github.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)nsls-
ii.github.ioGuiding Design Principles — Scientific Python Cookiecutter 0.1
documentation](https://nsls-ii.github.io/scientific-python-
cookiecutter/guiding-design-
principles.html)[![](https://t3.gstatic.com/faviconV2?url=https://docs.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.python.orgunicodedata
— Unicode Database — Python 3.13.5
documentation](https://docs.python.org/3/library/unicodedata.html)[![](https://t0.gstatic.com/faviconV2?url=https://dev.to/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)dev.toMastering
REST API Best Practices in Python - DEV
Community](https://dev.to/biswajitfsd/mastering-rest-api-best-practices-in-
python-5bda)[![](https://t0.gstatic.com/faviconV2?url=https://www.stuartellis.name/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stuartellis.nameModern
Good Practices for Python Development - Stuart
Ellis](https://www.stuartellis.name/articles/python-modern-
practices/)[![](https://t3.gstatic.com/faviconV2?url=https://www.freshports.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)freshports.orgFreshPorts
-- devel/py-unicodedata2: Unicodedata backport updated to the latest Unicode
version](https://www.freshports.org/devel/py-
unicodedata2)[![](https://t2.gstatic.com/faviconV2?url=https://stackoverflow.blog/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.blogBest
practices for REST API design - The Stack Overflow
Blog](https://stackoverflow.blog/2020/03/02/best-practices-for-rest-api-
design/)[![](https://t2.gstatic.com/faviconV2?url=https://docs.python-
guide.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)docs.python-
guide.orgStructuring Your Project - The Hitchhiker's Guide to
Python](https://docs.python-
guide.org/writing/structure/)[![](https://t1.gstatic.com/faviconV2?url=https://pypi.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)pypi.orgunicodedata2
-
PyPI](https://pypi.org/project/unicodedata2/)[![](https://t3.gstatic.com/faviconV2?url=https://peps.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)peps.python.orgPEP
8 – Style Guide for Python Code |
peps.python.org](https://peps.python.org/pep-0008/)[![](https://t0.gstatic.com/faviconV2?url=https://stackoverflow.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)stackoverflow.compython:
how to add 'unicodedata' module to my current python lib - Stack
Overflow](https://stackoverflow.com/questions/26583944/python-how-to-add-
unicodedata-module-to-my-current-python-
lib)[![](https://t3.gstatic.com/faviconV2?url=https://salishsea-meopar-
tools.readthedocs.io/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)salishsea-
meopar-tools.readthedocs.ioGuidelines and Best Practices for Writing Library
Code](https://salishsea-meopar-
tools.readthedocs.io/en/latest/python_packaging/library_code.html)[![](https://t1.gstatic.com/faviconV2?url=https://prefix.dev/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)prefix.devunicodedata2
- conda-forge - prefix.dev](https://prefix.dev/channels/conda-
forge/packages/unicodedata2)[![](https://t2.gstatic.com/faviconV2?url=https://benhoyt.com/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)benhoyt.comDesigning
Pythonic library APIs - Ben Hoyt](https://benhoyt.com/writings/python-api-
design/)[![](https://t3.gstatic.com/faviconV2?url=https://anaconda.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)anaconda.orgConda
- Anaconda.org](https://anaconda.org/conda-
forge/unicodedata2/)[![](https://t2.gstatic.com/faviconV2?url=https://packaging.python.org/&client=BARD&type=FAVICON&size=256&fallback_opts=TYPE,SIZE,URL)packaging.python.orgPackaging
Python Projects](https://packaging.python.org/tutorials/packaging-projects/)

Synthesizing Research Findings

I have completed my research into PyICU and `fontTools.unicodedata`, and have
a solid understanding of their APIs, strengths, and areas where a more
Pythonic approach is needed. I've also thoroughly explored Pythonic API design
principles, which will be crucial in shaping the `uicu` library. I'm now ready
to synthesize all this information into a detailed specification.

Preparing the `uicu` Specification

My next action is to generate a comprehensive report that will serve as the
detailed specification for the `uicu` package. This report will guide a junior
developer in implementing the library, ensuring it is extensive, natural, and
performant, while seamlessly integrating with Python's native Unicode
capabilities and exposing rich additional functionality.
</file>

<file path="research/res-gpt.md">
Thanks! I’ll begin by researching and documenting the APIs provided by PyICU and fontTools.unicodedata, especially around Unicode properties, transformations, and writing systems. I’ll also provide a detailed design specification for the new `uicu` package—focusing on a Pythonic, well-structured, and modular API that integrates both libraries’ capabilities and supports grapheme-aware iteration, normalization, script detection, and more.

I’ll let you know once everything is ready for your review.


# Design Plan for the `uicu` Unicode Utilities Library

## Introduction and Background

Python’s built-in `unicodedata` module and ICU (International Components for Unicode) offer comprehensive Unicode support, but using them can be cumbersome or low-level. **PyICU**, the Python bindings for ICU, exposes ICU’s powerful Unicode and internationalization features but through a thin, C++-styled API that isn’t very “Pythonic”. For example, splitting text into grapheme clusters (user-perceived characters) with PyICU requires manual iteration and index tracking in a C++-like fashion. On the other hand, **fontTools.unicodedata** (built on the `unicodedata2` backport) provides up-to-date Unicode data (including script and block properties) but is mostly a set of functions mirroring Python’s `unicodedata` API.

The goal of `uicu` is to combine the strengths of both: wrapping PyICU’s advanced Unicode functionalities in a natural, Pythonic interface, while supplementing with fontTools’ Unicode data for character properties. The result will be a **richly documented, easy-to-use library** that integrates seamlessly with Python’s `str` type but offers much more power. This plan outlines the APIs and design of `uicu` in detail, serving as a guide for implementation.

## Existing APIs Summary

### fontTools.unicodedata (unicodedata2)

FontTools’ `unicodedata` module extends Python’s `unicodedata` with additional information, especially about writing systems (scripts) and blocks. It uses the latest Unicode Character Database via the `unicodedata2` package. Key capabilities include:

* **Up-to-date core properties**: functions like `name(char)`, `category(char)`, `bidirectional(char)`, `combining(char)`, numeric values, normalization, etc., equivalent to Python’s built-in `unicodedata` but updated to the latest Unicode version.
* **Script identification**: `script(char)` returns the four-letter script code for a character (e.g. `'Latn'` for `'a'` and `'Zyyy'` for a comma). `script_extension(char)` returns a **set** of script codes if a character is used in multiple scripts (e.g. U+060C ARABIC COMMA has script extensions `'Arab', 'Thaa', ...` etc.).
* **Script metadata**: `script_name(code)` and `script_code(name)` map between the 4-letter script codes and human-readable script names. Also `script_horizontal_direction(code)` reports text direction (“LTR” or “RTL”) of a given script – for example, it returns `"RTL"` for `"Hebr"` or `"Arab"` and `"LTR"` for `"Latn"`.
* **Block identification**: `block(char)` gives the Unicode block name for the character (e.g. `'Basic Latin'` for `'A'`, `'Arabic'` for an Arabic character, or `'No_Block'` if none).
* **OpenType tag mapping** (for fonts): `ot_tags_from_script(script_code)` and `ot_tag_to_script(tag)` map between Unicode script codes and OpenType script tags.

These APIs provide a **richer Unicode database interface** than the basic `unicodedata` module. We will leverage them in `uicu` to offer script and block info, ensuring our library stays current with new Unicode versions.

### PyICU (Python ICU bindings)

PyICU wraps the ICU C++ libraries, which implement much of the Unicode standard and CLDR (Common Locale Data Repository) functionality. PyICU’s scope includes:

* **Locale-aware transformations**: e.g. case conversions, collation (sorting), formatting dates/numbers, transliteration between writing systems, etc.
* **Unicode algorithms**: e.g. normalization (NFC/NFD etc.), text boundary analysis (grapheme, word, line, sentence segmentation), bidirectional text handling, and more – essentially “big guns” for Unicode processing.
* **Extensive locale data**: ICU knows about various locales’ sorting rules, date/number formats, etc., accessible via PyICU.

However, PyICU’s API closely mirrors ICU’s C++ API, making it less intuitive for Python developers. For instance, to use a break iterator for word boundaries, one must do:

```python
bi = icu.BreakIterator.createWordInstance(icu.Locale('de_DE'))
bi.setText("Ein Beispiel.")
for boundary in bi:
    # boundary is an integer index; need to slice the string manually
    ...
```

As the example suggests, iterating text by words or graphemes requires manual index handling and understanding ICU’s classes. Similarly, to transliterate text, one must instantiate a Transliterator and call its method. While powerful, this approach is not as pythonic or straightforward as it could be.

**PyICU Highlights to Wrap in `uicu`:**

* **Break Iterators**: ICU provides `BreakIterator` factories for **grapheme clusters**, words, sentences, and line breaks. PyICU exposes these via `BreakIterator.createCharacterInstance()`, `createWordInstance()`, etc. and iteration yields boundary indices. We will wrap these to directly yield substrings (e.g. actual grapheme or word strings) to the user.
* **Collation**: ICU’s `Collator` allows locale-aware string comparison and sorting. PyICU’s `Collator.createInstance(locale)` gives a collator; one can then e.g. use `collator.getSortKey(string)` for sorting. We plan to simplify sorting and comparison with an easy interface.
* **Transliteration**: ICU has a rich set of transliterators (script conversions, accent removal, etc.). PyICU exposes `Transliterator.createInstance(id, direction)` and a `.transliterate(str)` method. We will provide a more direct function and class for transliteration.
* **Case Conversion**: ICU handles locale-specific case rules (e.g. Turkish ‘i’). In PyICU, one can use `icu.UnicodeString(text).toLower(locale)` or `toUpper(locale)`. We will wrap these so users can easily do locale-aware case changes on Python strings.
* **Other ICU features**: PyICU also supports formatting (dates, numbers via `DateFormat`, `NumberFormat`), time zones, bidi processing (`Bidi` class), and UnicodeSet/Regex. In this initial plan we focus on text and Unicode-specific features, but our design will be open to adding more (e.g. we might include number/date formatting helpers later).

One important detail: **PyICU handles Python strings by converting them to ICU’s internal UTF-16 representation (UnicodeString)**. Indices returned by ICU (e.g. break positions) count **16-bit code units** – which means Python and ICU indices can differ for characters outside the Basic Multilingual Plane (BMP). For example, an emoji or certain scripts use two 16-bit units in UTF-16 but count as a single character in Python’s str indexing. This can lead to misaligned indices if not handled. Indeed, PyICU users note that when using a native Python `str` with BreakIterator, the boundaries may not align with Python slicing, whereas using ICU’s `UnicodeString` avoids that issue. We will keep this in mind to ensure `uicu` functions return correct results for all Unicode characters (likely by internally using ICU UnicodeString for segmentation tasks).

## Design Goals for `uicu`

1. **Pythonic and Intuitive**: The API should feel natural to Python developers. Common tasks (like iterating over graphemes or words, comparing strings in a locale-aware way, converting text to another script) should be one-liners or simple loops – not requiring manual index arithmetic or obscure ICU constants. We’ll favor Python idioms (iterators, context managers if appropriate, simple functions) over ICU’s class boilerplate.
2. **Leverage ICU Performance**: ICU is written in C/C++ for performance. Our wrapper will call into PyICU (C++ extension) for heavy lifting, ensuring that even though we provide a higher-level interface, it remains efficient. We must be mindful of conversion overhead between Python and ICU (e.g., minimize repeated conversions of large strings).
3. **Comprehensive Unicode Support**: Cover the key features needed for robust Unicode text processing:

   * Character metadata (names, categories, scripts, blocks, numeric values, bidi classes, etc.)
   * Normalization (NFC, NFD, etc. as well as case-folding)
   * Grapheme cluster, word, sentence, and line segmentation
   * Locale-aware case transformations (upper, lower, title)
   * Transliteration between writing systems or transliteration rules
   * Locale-aware collation (comparison and sorting)
   * (Future/optional) Bi-directional text support, regex with Unicode properties, etc.
4. **Integration with Python Types**: Users of `uicu` should primarily work with Python’s built-in types (`str`, possibly `list` for results, etc.) and high-level objects. Internally we may use ICU’s `UnicodeString` or PyICU classes, but the user interface will abstract those away. For example, a user can pass a plain `str` or a locale code as a simple string `"en_US"`, rather than needing to import and use `icu.Locale` explicitly. Return values should be Python strings or collections thereof (except for specialized objects like a Collator instance).
5. **Clean Architecture**: Organize the package into a maintainable structure. Even if initially implemented in a single module `uicu.py`, the code should be modular and logically grouped (we may later split into submodules like `uicu.collation`, `uicu.segmentation`, etc.). We must adhere to the provided project structure, ensuring we have a proper `pyproject.toml`, tests, and documentation files. All public classes/functions need clear docstrings with examples.
6. **Compatibility**: `uicu` will target CPython (since PyICU itself is a CPython extension) and should also work on PyPy (PyICU supports PyPy as well). We will ensure our code doesn’t use any CPython-only API unnecessarily, and rely on PyICU for ICU access.

## Proposed API and Features

Below we detail the key components of `uicu` and how a developer should implement them. We will design `uicu` as a multifile package (if needed) within `src/uicu/`. For clarity, we describe them in categories:

### 1. Unicode Character Properties and Database

**Objective**: Provide easy access to Unicode character information, combining Python’s and ICU’s data.

* **Basic properties**: Functions mirroring `unicodedata` should be provided (or re-exported) for convenience:

  * `uicu.name(char)` – Unicode name of the character, e.g. `"LATIN CAPITAL LETTER A"`. Use `unicodedata.name()` from `unicodedata2` (for up-to-date data) or built-in as fallback.
  * `uicu.category(char)` – General category (e.g. `"Lu"` for uppercase letter).
  * `uicu.bidirectional(char)` – Bidi class (e.g. `"L"` for left-to-right letters).
  * `uicu.combining(char)` – Canonical combining class (integer).
  * `uicu.decimal(char)`, `uicu.digit(char)`, `uicu.numeric(char)` – Numeric values if applicable.
  * `uicu.mirrored(char)` – Whether character is mirrored in bidirectional text.
  * `uicu.east_asian_width(char)` – East Asian width property.
  * `uicu.decomposition(char)` – Decomposition mapping.
    These can directly call `fontTools.unicodedata` (which transparently uses `unicodedata2` or built-in). For example, `uicu.category(c)` can do `return ftunicodedata.category(c)`. The developer should import `fontTools.unicodedata` as, say, `ftunicodedata` at the top of `uicu.py`. (If fontTools/unicodedata2 is not installed, we will document that `uicu` requires it as a dependency – perhaps we list it in `pyproject.toml` extras or include `unicodedata2` as part of installation).

* **Script and block properties**: These are not in Python’s built-in unicodedata, so we expose them via fontTools:

  * `uicu.script(char)` – returns the 4-letter script code of the char (or `"Zzzz"` if unknown).
  * `uicu.script_name(code)` – full English name of a script given its 4-letter code. E.g. `"Latn" -> "Latin"`.
  * `uicu.script_code(name)` – inverse of the above, get script code from name (case-insensitive, ignores spaces/hyphens).
  * `uicu.script_extensions(char)` – returns a **set** of script codes if the char has Script Extensions property. (For chars with a single script, it can return a set with one element, e.g. `{'Latn'}`.)
  * `uicu.block(char)` – Unicode block name as a string (e.g. `'Basic Latin'`).
  * `uicu.block_code(char)` – (Optional) We might define a short code or range for blocks if needed, though just the name is usually enough.
  * **Directionality**: `uicu.script_direction(code)` – returns `"LTR"` or `"RTL"` for a given script code using fontTools’ logic. This can help, for example, to quickly check if text of that script should be rendered right-to-left.

  Implementation: all the above can call corresponding functions in `fontTools.unicodedata`. For example, `uicu.script = ftunicodedata.script`, `uicu.block = ftunicodedata.block`, etc., or use them internally. We should wrap them to handle any necessary type normalization (ensure input `char` is a single-character string or an int codepoint). If a user passes an integer (Unicode code point), we can convert it to `chr(code)` internally to use these functions. This adds pythonic flexibility.

* **Encapsulated Character Object** (optional but encouraged for richness): We can introduce a class `uicu.Char` (or `UnicodeChar`) that represents a single Unicode character and exposes all these properties as attributes. For example:

  ```python
  ch = uicu.Char('您')
  ch.char         # '您'
  ch.name         # 'CJK UNIFIED IDEOGRAPH-60A8'
  ch.category     # 'Lo'
  ch.script       # 'Hani'
  ch.block        # 'CJK Unified Ideographs'
  ch.numeric      # None (not a numeric character)
  ch.bidirectional # 'L'
  ```

  This `Char` class’s `__init__` would take either a one-length string or an integer code point. It can then store the character and lazily compute properties via the above functions (or compute once in constructor). This provides an OO way to bundle character info. It’s not strictly necessary for functionality, but it satisfies the goal of “rich objects” that integrate with Python’s Unicode: the `Char` object could implement `__str__` to return the character, so it prints as the character itself, and maybe `__repr__` to show e.g. `<Char '您' (U+60A8): Name='CJK ...'>`. This can help developers inspect characters easily.

  The junior developer should be guided to implement this class after the functions are in place. Ensure to document each attribute in the class docstring. Also, make it iterable or indexable? Probably not needed (it’s a single char). Comparison between `Char` objects could compare the underlying char. But primarily it's a container for properties.

* **Unicode Version**: We can expose `uicu.unicode_version` indicating the Unicode version of the data (from `unicodedata.unidata_version` which `unicodedata2` provides up-to-date). For completeness, also `uicu.icu_version` via PyICU (perhaps from `icu.ICU_VERSION` if available). These are informational.

**Documentation and Testing**: Document each function with the meaning of returned values (for example, list possible category codes or mention script codes are per ISO 15924). In tests, we should verify a few known values (e.g. `script('A') == 'Latn':contentReference[oaicite:42]{index=42}, script('你') == 'Hani'`, `block('A') == 'Basic Latin':contentReference[oaicite:43]{index=43}`, script\_extensions on a known char, etc.).

### 2. Unicode Normalization and Case Handling

**Normalization**: ICU and Python both support NFC, NFD, NFKC, NFKD normalization. We can simply wrap Python’s `unicodedata.normalize(form, text)` (again from `unicodedata2` for latest data). Provide an easy API:

* `uicu.normalize(text, form='NFC')` – returns the normalized string (form can be "NFC","NFD","NFKC","NFKD"). We can default to NFC as that’s common. This is basically a direct call to `unicodedata.normalize(form, text)`. Include in doc that this uses the latest Unicode data via unicodedata2, so it may recognize characters added in newer versions that the standard library might not (if on older Python).

**Case Folding**: Unicode case folding (for case-insensitive matching) can also be accessed via `unicodedata.normalize("NFKD", s).casefold()` or via ICU’s CaseFold. Simpler: Python’s `str.casefold()` is available (though Python’s casefold should be up-to-date with its Unicode version). We can provide `uicu.casefold(text)` to explicitly use the latest Unicode’s case folding. Implement by simply calling `text.casefold()`. (If we want to be absolutely sure it’s latest, the `unicodedata2` package might have a method for casefold? If not, Python’s will do – casefold doesn’t change often).

**Locale-Aware Case Conversion**: This is where ICU excels beyond Python. Python’s `str.upper()` and `lower()` are **not locale-aware** (they are context-insensitive except for Turkic dotted/dotless i which Python handles in a simplified way via `casefold`). ICU knows, for example, that in Turkish locale, `"i".upper()` should produce `"\u0130"` (Latin capital I with dot). We provide:

* `uicu.to_lower(text, locale=None)`
* `uicu.to_upper(text, locale=None)`
* `uicu.to_title(text, locale=None)`

Each converts the string to the respective case, following the rules of the given locale (if locale is None, use default locale or a root Unicode default). Implement by leveraging ICU’s `UnicodeString` transformations: e.g.

```python
def to_lower(text: str, locale: str = None) -> str:
    # If locale is provided (as BCP47 or ICU format string), get an ICU Locale
    loc = icu.Locale(locale) if locale else icu.Locale()  # default locale
    ustr = icu.UnicodeString(text)
    ustr_lowered = ustr.toLower(loc)
    return str(ustr_lowered)
```

The `icu.UnicodeString.toLower()` will apply locale-specific rules. We then convert back to Python `str` (PyICU allows `str(UnicodeString)` to do that conversion). Similarly for `to_upper` (using `toUpper`) and `to_title`. ICU’s `toTitle` can optionally take a break iterator to define word boundaries (for titlecasing each word), but if not provided, ICU will titlecase the first letter of each word by default. We can accept an optional parameter if needed in future to provide different titlecasing behavior, but not mandatory. Document that these are useful for locales like Turkish (`uicu.to_upper("i", "tr") -> "İ"`, whereas Python’s `"i".upper() -> "I"`). Add tests for such cases.

### 3. Text Segmentation (Graphemes, Words, Sentences, Lines)

One of the most valuable ICU features is splitting text on Unicode boundaries (grapheme cluster, word, etc.), according to the Unicode Text Segmentation standard (UAX #29). We will expose this in a very user-friendly way.

**Grapheme Clusters**: In Python, `for ch in text` iterates code points, not user-visible characters when combined marks are involved. For example, `"🇨🇦"` (Canadian flag emoji) is 2 code points, Python `len("🇨🇦") == 2` and iterating yields two separate regional indicator symbols. We want `uicu.graphemes(text)` to iterate or return the *actual characters* as seen by users.

* Implement `uicu.graphemes(text)` as a generator (or list) of grapheme cluster strings. Internally:

  1. Create an ICU break iterator for *character* boundaries: `bi = icu.BreakIterator.createCharacterInstance(locale)`. Typically, grapheme segmentation isn’t locale-variant (except for certain cases like Hangul syllable breaks, but those are algorithmic). ICU uses root locale if none given. We can allow an optional `locale` arg just in case (default to None).
  2. **Important**: Use ICU’s `UnicodeString` for the text to avoid index issues. E.g. `u16 = icu.UnicodeString(text)`, then `bi.setText(u16)`.
  3. Iterate over `bi` to get break positions (PyICU’s BreakIterator supports Python iteration yielding indices). Collect the segments by slicing the **UnicodeString** at those indices. For each segment `u_segment = u16[i:j]` (PyICU allows slicing a UnicodeString with Python slice syntax), convert it to str and yield.
  4. Alternatively, PyICU might have a convenience: perhaps `for seg in bi.getText()` or similar, but likely not – so we do manual slicing as above.
  5. This yields each grapheme cluster as a Python string.

  We should ensure this handles the entire string (the iterator will yield indices including the final length as end). We stop when `nextBoundary()` returns `-1` (the ICU convention). The last segment from last boundary to end of text must be included. (When using the Python iteration protocol as in `for j in bi:`, I believe it yields the end positions and after loop we’re done – we can manage it as in the blog example: track a `last_pos`, and for each boundary index yield `text[last_pos:j]` then update `last_pos`. But since we have `UnicodeString` and can slice it directly, that approach works similarly, using the UnicodeString for slicing).

  Provide this as both an **iterator** (generator function) and possibly as a method on a higher-level class (if we introduce a `UnicodeString` wrapper class in `uicu`). We could make `uicu.graphemes(text)` return a list for convenience, but for large texts a generator is more memory efficient. Perhaps return an iterator by default; users can do `list(uicu.graphemes(text))` if needed. Document this clearly.

* **Words**: `uicu.words(text, locale=None)` similarly uses `BreakIterator.createWordInstance(locale)`. Word boundary finding is definitely locale-dependent (e.g. Thai, Chinese segmentation). Implementation is analogous: feed a UnicodeString to the break iterator, iterate boundaries, slice out each word. However, note ICU’s definition of “word” will include punctuation and whitespace segments as separate tokens (as seen in the example output where spaces and punctuation came as separate items). We might choose to **filter out non-word tokens** by default – for instance, ICU marks boundaries and you often get empty or whitespace tokens. PyICU’s BreakIterator likely has methods to check the **rule status** to see if a boundary is a word boundary versus whitespace. But to keep it simple, we can initially include everything (so the output list would include spaces/punctuation as separate items, like in the example). Alternatively, we could filter to only alphabetic word tokens by skipping segments that are just whitespace or punctuation. This could be an option flag (e.g. `words(text, skip_delimiters=True)`). For now, perhaps return all segments (as ICU defines them), and mention in docs that punctuation and spaces will appear as separate tokens.

* **Sentences**: `uicu.sentences(text, locale=None)` uses `BreakIterator.createSentenceInstance(locale)`. This will yield sentence by sentence (including the trailing punctuation like period). Implementation is straightforward with slicing like above. Likely we won’t filter anything here; each segment should be a full sentence string.

* **Line Breaks**: `uicu.lines(text, locale=None)` using `BreakIterator.createLineInstance(locale)` for line break opportunities. ICU’s line breaking algorithm identifies places a line can break (considering hyphenation, punctuation, etc.). Typically used for wrapping, but we can expose it similarly. This might include the newline characters if present or potential breaks in text. We should clarify whether we mean *existing* lines or *possible* line break opportunities. Perhaps more useful is splitting on existing newline characters plus ICU’s discretionary breaks. However, as a first pass, we might skip this unless explicitly needed. If included, implement like others.

For all these segmentation functions, to **guide the developer**: write a helper internal function to avoid repetition, e.g. `_break_iterator_segments(text, break_iterator) -> iterator` that given a prepared `BreakIterator` (already set with text) yields substrings. Then each public function (graphemes/words/sentences) can create the appropriate break iterator via PyICU and call this helper. This avoids duplicating the loop logic. The helper can be similar to the pseudocode from ICU examples or our described method. Also, be careful to convert any results to Python str. (PyICU’s UnicodeString slicing yields UnicodeString objects; we should call `str()` on them or ensure iteration yields Python strings directly. Possibly PyICU’s iteration might yield Python str if the BreakIterator was given a Python str… but we gave it UnicodeString. To be safe, explicitly convert segments to str.)

**Locale handling**: If locale is None, use a neutral default. ICU’s `BreakIterator.createXXXInstance(locale)` requires an `icu.Locale` object. We can do `icu.Locale(locale_code)` if a string is given. If None, use `icu.Locale.getDefault()` (current locale) or simply `icu.Locale()` which uses default. Document that locale can influence especially word and sentence boundaries (for example, \`"Mr." might or might not end a sentence depending on locale conventions, etc.).

**Testing**: Use multilingual examples. E.g., grapheme clusters: an emoji with skin tone and ZWJ (👨🏽‍⚕️ as doctor emoji) should count as one grapheme. Korean Hangul syllables vs Jamo sequence should not split, etc. Words: test English (split on spaces/punctuation), CJK (Chinese text should ideally output per Chinese character or idiographic word), and Thai (which has no spaces but ICU should segment Thai words). We might compare results with known correct segmentations for a few cases. Sentence: input with multiple sentences. These tests ensure our wrapper correctly yields expected segments.

### 4. Locale-Aware Collation (String Comparison & Sorting)

Sorting strings in Unicode can be non-trivial (accented letters, different scripts, etc.). ICU’s **Collator** provides proper locale-sensitive ordering (the Unicode Collation Algorithm, UCA). Python’s default sorting is binary/unicode codepoint order which may not be culturally correct. We will create a high-level Collator API in `uicu`:

* **Collator Class**: Introduce `uicu.Collator(locale=None, **options)` as a Pythonic wrapper around ICU’s Collator. This class will encapsulate an ICU collator object (`icu.Collator` or `icu.RuleBasedCollator`). Key methods and usage:

  * `__init__`: Accepts a locale identifier (string or ICU Locale). If None, use default locale. Internally, do `icu.Collator.createInstance(locale_obj)` to get the collator. Also accept optional `options` like **strength** and **case/numeric settings**:

    * `strength`: Unicode collation strength level (primary, secondary, tertiary, quaternary, identical). We can map string or enum values to ICU’s constants. For example, strength="primary" means base letters only (ignore accents and case), "tertiary" is default (distinguish accents and case), etc. If provided, call `collator.setStrength(...)`. PyICU likely exposes an enum or we may use `icu.Collator.PRIMARY` etc.
    * `ignore_case`: If True, set collator to case-insensitive (could set strength to secondary if we want to ignore case differences but keep accents, or use `collator.setAttribute(UCollAttribute.CASE_LEVEL, VALUE_OFF)` accordingly).
    * `numeric`: If True, enable **numeric collation** (so "file2" comes before "file10", treating digits as numbers). ICU allows this via `collator.setAttribute(UCOL_NUMERIC_COLLATION, UCOL_ON)`. If PyICU exposes it, we use it. If not easily, perhaps skip or use a RuleBasedCollator with “\[numeric on]”. But likely PyICU has a way.
    * We can add other options like alternate handling (shifted for punctuation), but to keep it simple for now, these three cover common needs. Document them.

  * **Comparison methods**:

    * `compare(str1, str2) -> int`: return negative if str1 < str2, zero if equal, positive if str1 > str2 under the collation. Implement by calling `self._collator.compare(str1, str2)` if PyICU provides it ( ICU C++ has Collator::compare). If not directly, one can compare sort keys (see below). This is for completeness, though Python typically doesn’t use comparator functions.
    * `key(str) -> object`: return a collation key for the string, suitable for sorting. This could return the raw sort key (often a byte sequence). PyICU’s `collator.getSortKey(str)` returns a Python bytes object that encodes the collation ordering. We can return that directly. These keys, when compared lexicographically (bytewise), reflect the proper order. In usage, one can do `sorted(strings, key=collator.key)`. We might also implement `Collator.__call__(self, s)` to alias to `key(s)`, so that the Collator instance can be passed as a key function directly (since callables are accepted as key in sort). E.g., `sorted(names, key=uicu.Collator('sv_SE'))` to sort Swedish names. This would be very convenient.
    * Perhaps also `__lt__`, `__eq__` methods on Collator that compare two strings? That’s tricky because it’s unclear what to compare to – if we say `collator1 < collator2` doesn’t make sense. We could allow `collator.compare(str1, str2)` usage explicitly. So maybe no need for `__lt__` on Collator itself.

  * **Advanced**: `Collator.sort(list_of_str)` – convenience method to sort a list in place according to that collator. It could just do `list.sort(key=self.key)`. Not essential but a nice one-liner for users.

  * **Rule-based tailoring**: ICU allows custom collation rules (e.g. to change sorting order of certain characters). PyICU has `RuleBasedCollator(rules)`. For completeness, we might allow `Collator(rules="...")` as an alternative way to initialize – detect if the first arg is a string containing collation rules (perhaps if it contains newline or special characters like `&` typical in rules syntax). If so, create `icu.RuleBasedCollator(rules)` instead of locale-based. This is an advanced use-case; we can document but a junior dev can implement by checking an `rules` keyword argument.

  Implementation notes: The Collator wrapper stores `self._collator = icu.Collator.createInstance(loc)` or a RuleBasedCollator. All methods will use this internal `_collator`. We will ensure any string passed to `_collator` is a Python `str`, which PyICU will accept (it converts to UnicodeString under the hood). (If any issues with surrogates, ICU will handle internally in sort key generation correctly.)

* **Functional API**: In addition to the class, provide quick functions:

  * `uicu.sort(strings, locale)` that returns a new list sorted by locale. Implementation: `sorted(strings, key=Collator(locale))`. This is a one-liner using our class. So basically a convenience that hides the Collator object. If we implement it, it should be a shallow wrapper. Example usage: `uicu.sort(["zig", "äpfel", "apple"], locale="de")` and get them sorted as a German would (with "ä" correctly sorted near "a").
  * `uicu.sorted(strings, locale)` similarly (like Python’s built-in `sorted`). One could just use the above, so maybe just one of them is enough.
  * We might also provide `uicu.compare(str1, str2, locale)` for a one-off comparison returning -1/0/1 using a ephemeral Collator. But this is minor; users can instantiate Collator if needed.

**Testing**: We will test that sorting works as expected. For example, sorting \["a", "ä", "b"] in German locale should yield \["a", "ä", "b"] (since ä is treated as a = ae maybe, but in Swedish locale it should come after "z"). We can use known correct orders from examples or ICU docs. Also test numeric collation option: e.g. sorting \["file2", "file10", "file1"] with numeric=True should yield \["file1","file2","file10"], whereas default string collation might give "file1","file10","file2".

### 5. Transliteration and Text Transforms

ICU’s transliteration engine can perform complex text transformations (e.g. converting non-Latin scripts to Latin (romanization), or removing diacritics, etc.). `uicu` will provide easy access to common transliterations and a way to use custom ones:

* **Simple Transliteration Function**: `uicu.transliterate(text, id, direction='forward') -> str`. Here `id` is an ICU transliterator identifier string, like `"Greek-Latin"` to transliterate Greek to Latin script. ICU has many built-in IDs (the ICU user guide lists them). We will not hardcode the list but we can link to ICU docs for reference. `direction` can be `'forward'` (default) or `'reverse'` to apply the inverse transliteration (PyICU expects a constant `icu.UTransDirection.REVERSE` or an enum, but in Python we can just pass a flag). Implementation:

  * If direction is reverse, we could either call `icu.Transliterator.createInstance(id, UTransDirection.REVERSE)`, otherwise the normal createInstance. Apply `.transliterate(text)` and return the result. PyICU will accept Python str for transliteration and return a Python str (likely). If not, we may wrap the text in UnicodeString first just to be safe with any non-BMP issues (though transliteration output length is usually aligned with input characters count or more, but ICU likely handles it).
  * Alternatively, ICU offers an easier reverse: you can get a Transliterator and call `.transpose()` to get inverse. But simply creating with reverse flag is fine.

  This function is a one-liner usage for common tasks. E.g. `uicu.transliterate("Παράδειγμα", "Greek-Latin")` → "Parádeigma".

* **Transliterator Class**: For repeated use or more advanced control, provide a `uicu.Transliterator` class. It will wrap `icu.Transliterator`. Usage:

  ```python
  tr = uicu.Transliterator("Latin-Devanagari")  # create transliterator from Latin script to Devanagari
  hindi = tr.transliterate("kshatriya")  # get result
  tr_rev = tr.inverse()  # get inverse transliterator as a new uicu.Transliterator
  ```

  Implementation:

  * `__init__(self, id, direction='forward')`: store `self._icu_trans = icu.Transliterator.createInstance(id, dir)`. If creation fails (e.g. unknown ID), PyICU might throw an ICUError – catch and raise a custom error or message.
  * `transliterate(self, text)`: simply `return self._icu_trans.transliterate(text)`. PyICU returns a Python str here.
  * `inverse(self)`: returns a new `uicu.Transliterator` which is the inverse of the current. Implement by `inv_icu = self._icu_trans.createInverse()`, then wrap in our class.

  We can also allow custom transliteration rules: ICU supports rule strings to create a Transliterator (for example, a rule that removes diacritics could be `"[\\p{M}]>;"` to strip marks). If user passes a rule string rather than a known ID, ICU will treat it as rules if we call `createInstance` with id. Actually, ICU expects either a registered ID or a rule pattern. There is also `icu.Transliterator.createFromRules(name, rules, direction)` if needed for custom rules not registered. We can expose that via an alternative constructor like classmethod `Transliterator.from_rules(name, rules, direction='forward')`. This might be advanced, but including it would make the API “very extensive” as requested. A junior dev can implement by calling that ICU function.

  Common transliterators to mention in docs: "Any-Latin" (to Latin from any script), "Latin-Ascii" (remove accents), "NFD; \[:Nonspacing Mark:] Remove; NFC" (this can be achieved via rules to strip diacritics if not using built-in). We should encourage using built-in IDs where possible.

* **Other Transforms**: ICU’s transliteration also covers things like case folding (there might be an "Any-CaseFold"), or script-specific transforms like "Hiragana-Katakana". We won’t enumerate all, but by providing the flexible interface, users can do what they need.

**Testing**: Test a couple of transliterations: e.g., Greek to Latin as above, or Devanagari to Latin ("देवनागरी"->"devanāgarī"), and a reverse. Also test using the transliterator object multiple times (to ensure state is either stateless or properly handled – ICU transliterators are usually stateless or reset each call). If we provide custom rule usage, test a simple rule (like swapping letters).

### 6. Additional Considerations

**Error Handling**: PyICU functions throw `ICUError` (a Python exception) when something goes wrong (it wraps ICU’s UErrorCode). For example, if an invalid locale ID or transliterator ID is given, an error will be raised. Our `uicu` can either let these exceptions propagate or catch and wrap them in our own exception class (e.g., define `uicu.Error` as a subclass of Exception, possibly holding the original ICUError). It might be simplest to let ICUError surface, but document it. However, to make a cleaner API, wrapping could be good – for instance, raise `ValueError` for invalid locale or ID, with message extracted from ICUError. A junior developer can implement basic try/except around createInstance calls and raise appropriate Pythonic exceptions (ValueError or a custom UICUError). We should specify this clearly in docs: e.g. "If an unknown script code is requested, a KeyError is raised" (as fontTools does), or "If an invalid transliteration ID is given, `uicu.Error` is raised with the ICU message."

**Performance**: We will advise to **reuse objects** when appropriate. For example, if an application needs to segment many strings the same way, reusing a BreakIterator is more efficient than creating a new one each time (ICU break iterator has an expensive initialization). However, PyICU BreakIterator instances are not obviously reusable with new text (though actually they are: one can call `.setText()` repeatedly on the same iterator with different strings). We might expose that by allowing `uicu.GraphemeIterator` class that holds an ICU BreakIterator and can be called on multiple texts. But that might complicate things for little gain at first. Instead, we can internally cache frequently used break iterators. For instance, `uicu.graphemes` could create a global single `BreakIterator.createCharacterInstance(Locale())` on first use and reuse it (with different text set each call). But ICU break iterators are **not thread-safe** unless each thread has its own. Given this is a library, safer to not cache globally by default (to avoid concurrency issues). Perhaps we skip caching. We can note in documentation that if you need to segment thousands of strings, it may be worth to create a BreakIterator once and reuse via a provided class. As an advanced feature, a `uicu.TextBreaker(kind="word", locale=None)` object could be created, with a method `segments(text)` returning segments. The developer can implement that if needed. Initially, keep it simple: create new ones each call.

For collation, similar reasoning: creating a Collator is somewhat expensive (needs to load collation rules). If sorting many lists, reuse the Collator object. Our API already supports that (via the Collator class).

**Integration with Python iteration and slicing**: We will ensure any custom objects behave intuitively:

* If we have a `uicu.UnicodeString` wrapper (if we decide to create one to mirror ICU’s UnicodeString but as Python class), it should perhaps subclass `str` (so it inherits all string behavior) or at least implement sequence methods (`__len__`, `__getitem__`, etc.) by delegating to the internal str. This might be overkill, and since Python’s str is itself adequate, we probably skip making a custom string type. Instead, we use Python str everywhere and only use ICU’s UnicodeString internally. This is simpler and avoids confusion. So likely we do *not* make a `UnicodeString` class in `uicu` (since Python’s str suffices as the public type). The only new classes we introduce are things like `Char`, `Collator`, `Transliterator` as above, and possibly a `Locale` wrapper if needed.

**Locale Handling**: We should decide whether to expose ICU’s `Locale` class or hide it. PyICU’s Locale can be used directly by users, but to keep things consistent, our functions/classes accept `locale` as either a `str` (like `"en_US"` or `"fr-CA"` or BCP47 `"fr-CA-u-nu-latn"` etc.) or an `icu.Locale` object. Internally, we detect and convert if needed. We may also accept Python’s locale identifiers (which are often the same as ICU, just underscore vs hyphen differences). We'll document using the ICU/CLDR format (language\_Country). Provide convenience like `locale = None` means system default.

We could provide a thin wrapper `uicu.Locale` class that maybe inherits or wraps `icu.Locale` just to add Pythonic methods or repr. However, PyICU’s Locale already has nicely named constructors like `Locale.getFrance()`, etc., and properties like `getDisplayName()`. Probably no need to wrap it deeply. We can simply allow PyICU’s Locale to be used. Maybe just mention in docs that advanced locale info can be accessed via `icu.Locale` if needed, but not necessary for basic usage of our library.

**Package Structure**: The final code will reside under `src/uicu/`. We will have at least `uicu.py` implementing everything in one module for now. We also have `__version__.py` for version info. The project root has README, etc. Ensure to update README.md with usage examples demonstrating our new API (this will help the junior dev and users). Possibly maintain a `TODO.md` with any future extensions (like adding Bidi support or Regex wrappers in future).

If the module grows large, we can refactor into submodules: e.g. `uicu/collation.py`, `uicu/segmentation.py`, etc., and import them in `uicu/__init__.py`. The given structure shows a single `uicu.py`, but a “multifile package” was mentioned, so organizing by feature is okay. For now, the plan can proceed with one file, with clearly separated sections internally and maybe using internal helper functions to keep it tidy.

## Step-by-Step Implementation Guide

Following the design above, here’s a suggested order of implementation for a junior developer:

1. **Set up project structure**: Create the directory and files as given. Ensure `pyproject.toml` has dependencies: include `pyicu` and `fonttools[unicode]` (or `unicodedata2`) as requirements. This ensures the environment has ICU and updated Unicode data. Write a brief README introduction (can be filled after implementing, with examples).

2. **Character properties functions**: In `uicu.py`, import `unicodedata` from `unicodedata2` (fall back to built-in if import fails, but ideally require unicodedata2). Also `from fontTools import unicodedata as ftunicodedata`. Start implementing `name(char)`, `category(char)`, etc., by delegating to these. Write docstrings for each, citing that data is from Unicode X.Y (whatever version). Implement `script`, `block`, etc., using fontTools functions. Make sure to handle if input is not a single character: decide if we want to allow strings of length >1 (maybe not, we can enforce len==1 for these functions, and document that they take a single character). If a longer string is given by mistake, maybe we either process first char or raise an error. Possibly safer to raise ValueError to prevent misuse.

3. **Char class**: Define `class Char:` with an `__init__` that stores the char (after validation) and attributes like name, etc., filled by calling the functions above. This is straightforward. Also define `__repr__` to show meaningful info, and maybe `__str__` to return the raw character. This class goes in `uicu.py` as well.

4. **Normalization and case**: Implement `normalize(text, form)` using `unicodedata.normalize`. Implement `casefold(text)` using `str.casefold()`. Then `to_lower, to_upper, to_title` using PyICU’s UnicodeString as described. For this, you need to import `import icu` at top (PyICU module). If any locale code is provided as argument, convert via `icu.Locale(locale_code)`; if None, use `icu.Locale.getDefault()`. Test these quickly in an interactive session to ensure, for example, `to_upper('i', 'tr_TR')` yields `'\u0130'`. Document these functions with examples.

5. **Segmentation functions**: Import `icu.BreakIterator`. Implement an internal helper, e.g. `_iter_segments(text, bi)` where `bi` is a BreakIterator already set to the text. It should yield segments. Use the pattern:

   ```python
   utext = icu.UnicodeString(text)
   bi.setText(utext)
   last = 0
   for boundary in bi:
       segment = utext[last:boundary]    # get ICU UnicodeString from last to boundary
       yield str(segment)               # convert to Python string
       last = boundary
   ```

   Ensure after the loop, we don’t need an extra step (since the iterator yields the final index equal to text length as the last boundary, the loop logic above actually covers the whole text and ends naturally). Implement `graphemes(text)`, `words(text, locale=None)`, `sentences(text, locale=None)` by creating the appropriate BreakIterator via the class method, then delegating to `_iter_segments`. For locale, if provided (string), do `icu.Locale(locale)`, else default. For word segmentation, consider filtering out purely whitespace tokens: ICU will produce them (see example where spaces are separate). Possibly, we can post-filter: e.g., inside the loop for words, skip `segment` that is all whitespace (or that `segment.strip()` is empty). But sometimes punctuation like "-" might also be separated. We could leave them in to exactly mirror ICU, and let user decide to filter if needed. It’s safer to leave as is for now (complete fidelity), and document that output includes whitespace and punctuation segments.

   Also, ensure that if the text is empty, the functions handle gracefully (probably just yield nothing).

6. **Collator and sorting**: Implement the `Collator` class as described. Import `icu.Collator`. In `__init__`, call `icu.Collator.createInstance(locale_obj)`. If `locale` is a str, do `locale_obj = icu.Locale(locale)`. If that fails (bad locale string), catch ICUError and raise ValueError("Unknown locale ..."). Then set attributes if options given (for strength, etc., use `self._collator.setStrength(icu.Collator.TERTIARY)` for example). PyICU likely has those constants under Collator. If numeric option, try `self._collator.setAttribute(icu.UCollAttribute.NUMERIC_COLLATION, icu.UCollAttributeValue.ON)` – these enums might need import from `icu` as well (PyICU might expose them or via Collator class attributes). Refer to PyICU docs or source for exact usage. If it’s complicated, a simpler workaround is to use a rule-based collator string “\[numeric on]” on top of base rules (as the cheat sheet did for Welsh example), but that's not straightforward for arbitrary locale combination. We expect PyICU Collator to allow setting numeric via `collator.setAttribute`. We’ll proceed with that plan.

   Methods: `compare(a,b)` could use `self._collator.compare(a,b)`. (We should verify PyICU Collator object indeed has a compare method – ICU C++ Collator does. If not, we can simulate by computing keys and comparing those bytewise.) `key(s)` uses `self._collator.getSortKey(s)` which returns `bytes`. That can be returned directly or we might want to return a \_Key wrapper with defined comparison. Simpler: return bytes, since Python will compare those correctly. It’s fine. Implement `__call__ = key` to make the object callable as key function.

   Add a `sort(iterable)` method if desired (just returns sorted copy using self as key).

   Also implement maybe `__enter__` and `__exit__` for context manager? Not obviously needed for Collator. Probably not.

   The developer should also expose a functional interface: define `uicu.sort(strings, locale, **options)` that internally does `return sorted(strings, key=Collator(locale, **options))`. And/or `uicu.sorted` similarly (one might suffice).

   Test the Collator class on a basic example: e.g., `Collator('en').compare("a","b")` returns -1 (assuming "a" < "b"). Sorting with key should order strings properly (we can test with a list including "é" and "e" in French locale, etc.).

7. **Transliteration**: Implement `transliterate(text, id, direction='forward')` function first. Import `icu.Transliterator` and `icu.UTransDirection`. Map `direction='reverse'` to `icu.UTransDirection.REVERSE` (PyICU likely provides this enum). Otherwise use `UTransDirection.FORWARD` or simply omit since forward is default. The call:

   ```python
   trans = icu.Transliterator.createInstance(id, direction_enum)
   result = trans.transliterate(text)
   return result
   ```

   Wrap in try/except to catch ICUError if the ID is invalid, and raise a ValueError listing the id.

   Then the `Transliterator` class: store `self._trans = icu.Transliterator.createInstance(id, dir)`. Provide `transliterate(self, text)` calling `self._trans.transliterate(text)`. Provide `inverse(self)` doing `inv = self._trans.createInverse()` and wrap in `Transliterator` class (i.e., `return Transliterator.__new__` or better provide an alternate constructor: we can simply do `inv_obj = object.__new__(Transliterator)` and set `inv_obj._trans = inv`, but easier is to call our own **init** by constructing a new Transliterator with the reverse param. Actually, simpler: just do `return Transliterator(id, direction='reverse')` if we know id, but that might redo the lookup; using `createInverse` is more direct and handles compound translits properly. So do `inv_icutrans = self._trans.createInverse(); inv = Transliterator.__new__(Transliterator); inv._trans = inv_icutrans; return inv` – and also maybe store an attribute for id or name in the object if needed for reference).

   Additionally, implement `__call__(self, text)` as alias to `transliterate`, so the object can be used as a function (less important, but could be nice).

   Test transliterator on a known transform. If possible, include in tests: for example `uicu.transliterate("ρας", "Greek-Latin")` -> "ras", and inverse returns original (with appropriate direction).

8. **Documentation and Examples**: Throughout the code, add docstrings with examples (in Markdown or reStructuredText if using Sphinx later). E.g., for `uicu.graphemes`: explain what grapheme clusters are, and show usage:

   ```python
   >>> list(uicu.graphemes("naïve"))
   ["n", "ä", "i", "v", "e"]  # the 'a' with diaeresis is one grapheme
   ```

   and perhaps an emoji example. For collation, show sorting example in docstring. For transliteration, show converting script. These will not only help users but also serve as simple tests (could even be used as doctests).

   Update README.md to describe the package and include a quickstart: e.g., demonstrate how to use a few major features (maybe showing a side-by-side of doing something with PyICU vs how much simpler with uicu, to emphasize the improvement). For instance, show how to get grapheme clusters in one line with `list(uicu.graphemes(text))` instead of 10 lines of PyICU code.

9. **Testing**: In `tests/test_package.py`, write tests for each major function. Use assertions for known values. For segmentation, you might include known tricky cases (like flags, family emojis 👨‍👩‍👦, which should count as one grapheme each). For collation, test that Collator sorts strings in expected order for a couple of locales. Note: Running ICU collation tests might require known reference data; we can do a simpler test like sorting `["Z", "a"]` in a case-insensitive Collator and expecting `["a","Z"]` when strength=primary (ignoring case). Transliteration test as mentioned. Character property tests using a couple of characters from different scripts.

10. **Performance check** (optional): If possible, benchmark that calling our functions isn’t egregiously slow. Likely fine, but if issues, consider optimizations (like caching ICU objects). Since this is an initial version, clarity and correctness come first; optimizations can be listed in TODO.md.

By following this plan, the junior developer should be able to implement `uicu` as a well-organized package. The end result will be a multi-faceted Unicode utility library that harnesses ICU’s power with a clean Python interface. This will greatly simplify tasks such as iteration over graphemes (previously “more of a pain than you’d hope” in raw PyICU), handling full Unicode properties, and performing locale-aware text processing in Python.

## Package Structure Confirmation

The `uicu` package will conform to the given structure. All code resides in `src/uicu/`, primarily in `uicu.py` (which can import submodules if we split the code). We will include the version in `__version__.py`. Tests in `tests/`. Documentation in `README.md` and possibly supplementary design notes in `AGENTS.md`/`CLAUDE.md` if those are used for project communication.

After implementation, the developer should verify everything is running using the latest ICU (PyICU) and fontTools data. We expect that this library will make advanced Unicode handling in Python much more accessible, combining **the extensive ICU functionality** with **Pythonic ease of use**.

**Sources:** This plan was informed by ICU/PyICU documentation and examples, as well as fontTools’ Unicode data module reference.
</file>

<file path="research/res-grok.md">
# Specification for `uicu` Package

## 1. Introduction
The `uicu` package is a Pythonic wrapper around [PyICU](https://pypi.org/project/pyicu/), which provides Python bindings for the [ICU library](https://unicode-org.github.io/icu/). The goal is to create an intuitive, well-documented, and performant API that integrates seamlessly with Python’s native Unicode handling (`str`) while exposing ICU’s rich functionality, including Unicode properties, locale handling, formatting, collation, transliteration, and text segmentation. The package may incorporate [fontTools.unicodedata](https://fonttools.readthedocs.io/en/latest/unicodedata/index.html) for specific Unicode data needs, such as writing system information, if it provides advantages over ICU.

This specification outlines the package structure, API design, and implementation guidelines to assist a junior developer in building `uicu`. It includes detailed examples, performance considerations, and documentation standards.

## 2. Package Structure
The `uicu` package will be organized into submodules to reflect ICU’s major components, ensuring modularity and ease of use. The proposed structure is:

- `uicu/__init__.py`: Top-level imports, package metadata, and high-level convenience functions.
- `uicu/unicode.py`: Functions for Unicode character properties and string operations.
- `uicu/locale.py`: Classes and functions for locale handling.
- `uicu/format.py`: Classes for formatting and parsing dates, numbers, and messages.
- `uicu/collation.py`: Functions and classes for locale-aware string comparison and sorting.
- `uicu/transliterate.py`: Functions for transliteration.
- `uicu/breakiter.py`: Classes for text segmentation (e.g., word or sentence boundaries).

Each module will provide Pythonic interfaces, either as functions operating on native Python types (e.g., `str`) or as classes wrapping PyICU objects with simplified methods.

## 3. API Design Principles
To ensure the API is Pythonic, natural, and performant, the following principles will guide development:

- **Simplicity**: Provide high-level functions for common tasks (e.g., `uicu.format_date()` instead of multiple PyICU steps).
- **Integration with Python**: Use Python’s `str` for string operations where possible, supplementing with ICU for advanced functionality.
- **Consistency**: Follow PEP 8 naming conventions (e.g., `lowercase_with_underscores` for functions) and use exceptions for error handling.
- **Performance**: Minimize wrapper overhead by directly calling PyICU methods where feasible.
- **Documentation**: Include detailed docstrings with examples, type hints, and references to ICU documentation.
- **Flexibility**: Offer both simple functions for quick tasks and classes for advanced use cases requiring fine-grained control.

## 4. Detailed API Specification

### 4.1. `uicu.unicode`
This module handles Unicode character properties and string operations, leveraging ICU’s `uchar` module and `UnicodeString` class.

#### Functions
- `normalize(text: str, form: str = 'NFC') -> str`
  - Normalizes a string using ICU’s Normalizer2.
  - Parameters:
    - `text`: Input string to normalize.
    - `form`: Normalization form (`'NFC'`, `'NFD'`, `'NFKC'`, `'NFKD'`).
  - Returns: Normalized Python `str`.
  - Example:
    ```python
    import uicu
    text = "café"
    normalized = uicu.normalize(text, 'NFD')  # Decomposes 'é' into 'e' + combining acute accent
    ```
- `get_category(char: str) -> str`
  - Returns the Unicode general category of a single character (e.g., `'Lu'` for uppercase letter).
  - Uses ICU’s `u_charType` or fontTools.unicodedata’s `category` if specified.
  - Example:
    ```python
    category = uicu.get_category('A')  # Returns 'Lu'
    ```
- `is_alpha(char: str) -> bool`
  - Checks if a character is alphabetic using ICU’s `u_isalpha`.
  - Example:
    ```python
    is_alpha = uicu.is_alpha('α')  # Returns True
    ```

#### Classes
- `UnicodeString`
  - Wraps `icu.UnicodeString` for advanced string operations.
  - Methods:
    - `__str__()`: Converts to Python `str`.
    - `normalize(form: str = 'NFC') -> str`: Normalizes the string.
    - `to_upper(locale: str = None) -> str`: Converts to uppercase, optionally locale-aware.
  - Example:
    ```python
    from uicu import UnicodeString
    us = UnicodeString("café")
    upper = us.to_upper(locale='tr_TR')  # Turkish uppercase rules
    ```

### 4.2. `uicu.locale`
This module provides locale handling, wrapping `icu.Locale`.

#### Classes
- `Locale`
  - Wraps `icu.Locale` with Pythonic properties.
  - Properties:
    - `language`: Returns the language code (e.g., `'en'`).
    - `display_name`: Returns the locale’s display name.
  - Methods:
    - `get_available() -> List[str]`: Returns available locale IDs.
  - Example:
    ```python
    from uicu import Locale
    loc = Locale('fr_FR')
    print(loc.display_name)  # Prints "French (France)"
    ```

#### Context Manager
- `set_locale(locale: str)`
  - Temporarily sets the default locale for ICU operations.
  - Example:
    ```python
    with uicu.set_locale('es_ES'):
        formatted = uicu.format_number(1234.56)  # Uses Spanish formatting
    ```

### 4.3. `uicu.format`
This module handles formatting and parsing for dates, numbers, and messages.

#### Classes
- `DateFormatter`
  - Wraps `icu.DateFormat` for date and time formatting.
  - Methods:
    - `format(dt: datetime) -> str`: Formats a datetime object.
    - `parse(text: str) -> datetime`: Parses a string to a datetime.
  - Example:
    ```python
    from uicu import DateFormatter
    formatter = DateFormatter(locale='en_US', pattern='MMM d, y')
    formatted = formatter.format(datetime.now())  # e.g., "Oct 25, 2025"
    ```
- `NumberFormatter`
  - Wraps `icu.NumberFormat` for number formatting.
  - Methods:
    - `format(number: float) -> str`: Formats a number.
  - Example:
    ```python
    formatter = uicu.NumberFormatter(locale='de_DE')
    formatted = formatter.format(1234.56)  # e.g., "1.234,56"
    ```

#### Functions
- `format_date(dt: datetime, locale: str = None, pattern: str = None) -> str`
  - Convenience function for date formatting.
  - Example:
    ```python
    formatted = uicu.format_date(datetime.now(), locale='en_US', pattern='MMM d, y')
    ```

### 4 U.4. `uicu.collation`
This module provides locale-aware string comparison and sorting.

#### Functions
- `sorted(strings: List[str], locale: str = None) -> List[str]`
  - Sorts strings using ICU’s collation rules.
  - Example:
    ```python
    strings = ['café', 'cafe']
    sorted_list = uicu.sorted(strings, locale='fr_FR')  # Locale-aware sorting
    ```

#### Classes
- `Collator`
  - Wraps `icu.Collator` for custom collation.
  - Methods:
    - `compare(a: str, b: str) -> int`: Compares two strings.
  - Example:
    ```python
    from uicu import Collator
    collator = Collator(locale='fr_FR')
    sorted_list = sorted(strings, key=collator)
    ```

### 4.5. `uicu.transliterate`
This module handles transliteration.

#### Functions
- `transliterate(text: str, transform: str) -> str`
  - Transliterates text using ICU’s transliteration rules.
  - Example:
    ```python
    text = uicu.transliterate("привет", "Cyrillic-Latin")  # Returns "privet"
    ```

### 4.6. `uicu.breakiter`
This module provides text segmentation.

#### Classes
- `BreakIterator`
  - Wraps `icu.BreakIterator` for word, sentence, or line breaking.
  - Methods:
    - `boundaries(text: str) -> List[int]`: Returns boundary indices.
  - Example:
    ```python
    from uicu import BreakIterator
    bi = BreakIterator('word', locale='en_US')
    boundaries = bi.boundaries("Hello world!")  # Returns word boundary indices
    ```

## 5. Integration with fontTools.unicodedata
The `uicu.unicode` module will include an optional parameter to use fontTools.unicodedata for character properties if specified (e.g., `use_fonttools=True`). This allows flexibility for users who prefer fontTools’ data, particularly for writing system information like `script` or `block`. For example:
```python
category = uicu.get_category('A', use_fonttools=True)  # Uses fontTools.unicodedata
```

## 6. Performance Considerations
- **Minimize Overhead**: Wrapper functions should call PyICU methods directly, avoiding multiple layers of abstraction.
- **Caching**: Cache frequently used objects (e.g., `Normalizer2` instances) to reduce initialization costs.
- **Native Types**: Use Python `str` for inputs and outputs where possible to avoid conversion overhead.
- **Profiling**: Test performance against PyICU to ensure minimal slowdown, using tools like `cProfile`.

## 7. Documentation Standards
- **Docstrings**: Follow Google Python Style Guide for docstrings, including Args, Returns, and Examples.
- **Type Hints**: Use type hints for all functions and methods (e.g., `str`, `List[str]`).
- **Examples**: Include practical examples in docstrings and a separate `examples/` directory.
- **Tutorials**: Provide tutorials in the documentation, built with [Sphinx](https://www.sphinx-doc.org/).
- **References**: Link to ICU documentation for advanced details.

## 8. Implementation Guidelines
- **Dependencies**: Require `PyICU>=2.8` and optionally `fonttools[unicodedata]>=4.38.0`.
- **Testing**: Use `pytest` with unit tests covering all functions and edge cases.
- **Error Handling**: Convert ICU error codes to Python exceptions with descriptive messages.
- **Packaging**: Use `setuptools` for distribution, with clear metadata in `setup.py`.
- **Versioning**: Follow Semantic Versioning (e.g., `0.1.0` for initial release).

## 9. Example Usage
```python
import uicu
from datetime import datetime

# Normalize a string
text = "café"
normalized = uicu.normalize(text, 'NFD')

# Format a date
formatted_date = uicu.format_date(datetime.now(), locale='fr_FR', pattern='d MMM y')

# Sort strings with locale-aware collation
strings = ['café', 'cafe']
sorted_strings = uicu.sorted(strings, locale='fr_FR')

# Transliterate text
transliterated = uicu.transliterate("привет", "Cyrillic-Latin")

# Get character properties
category = uicu.get_category('A')  # Returns 'Lu'
```

## 10. Next Steps
1. **Prototype**: Implement core modules (`unicode`, `locale`, `format`) with basic functionality.
2. **Testing**: Write unit tests to verify correctness against PyICU.
3. **Documentation**: Generate initial Sphinx documentation with examples.
4. **Performance Testing**: Profile key functions to ensure minimal overhead.
5. **Community Feedback**: Release a beta version on [PyPI](https://pypi.org/) and gather feedback.

This specification provides a clear roadmap for developing `uicu`, balancing Pythonic design, performance, and comprehensive functionality.
</file>

<file path="research/res-phind.md">
Below is a detailed specification document for the new **`uicu`** package. This spec outlines design goals, module and API structure, integration strategies, error handling, testing guidelines, and documentation conventions. It is written so that a junior developer can follow it step by step to develop the package.

---

# uicu Package Specification

The **`uicu`** package is intended to be a comprehensive, natural, and pythonic API for ICU functionality. It serves as a wrapper around [PyICU](https://pypi.org/project/pyicu/) and supplements any necessary APIs from [fontTools.unicodedata](https://fonttools.readthedocs.io/en/latest/unicodedata/index.html) or the updated [unicodedata2](https://github.com/fonttools/unicodedata2) project. The package will provide rich objects that naturally integrate with Python’s native Unicode types while exposing advanced and performant ICU operations.

---

## 1. Overview and Goals

- **Primary Goal:**  
  Build a pythonic and extensive API for ICU functionality that seamlessly wraps PyICU. The API aims to simplify and enhance the standard ICU features (localization, date and time formatting, Unicode normalization, and more) in a way that leverages Python’s strengths.

- **Key Objectives:**
  - **Pythonic Interface:** Hide low-level ICU details (such as error-code handling and non-native string types) behind a natural interface that works well with Python’s native types.
  - **Rich Typing:** Provide well-documented objects and methods for locales, text formats, time zones, and Unicode data.
  - **Performance:** Wrap the PyICU (C++ based) backend so that performance remains a priority.
  - **Extensibility:** Offer integration points to supplement ICU functionality with advanced Unicode lookup (using fontTools.unicodedata, unicodedata2, or even Python’s builtin unicodedata where applicable).
  - **Error Simplification:** Automatically manage ICU error codes and exceptions by translating them into standard Python exceptions.

---

## 2. Dependencies

- **PyICU:**  
  This is the underlying binding to the ICU C++ API.  
  > *Installation:* `pip install pyicu`

- **FontTools.unicodedata (or unicodedata2):**  
  To provide extra Unicode character data and support for writing systems, fall back on fontTools’ functionalities where needed.

- **Optional:**  
  Python’s built-in [unicodedata](https://docs.python.org/3/library/unicodedata.html) module for additional compatibility utilities.

---

## 3. Package Architecture and Module Layout

To keep the code maintainable, organize **`uicu`** into several modules:

- **`uicu/core.py`:**  
  Core implementations and helpers – low-level wrappers around PyICU objects, type conversions, and common utilities.

- **`uicu/locale.py`:**  
  Provides a pythonic `Locale` class which wraps ICU’s Locale. Include methods that convert ICU data (e.g. display names) into native Python strings.

- **`uicu/formatting.py`:**  
  Contains wrappers for ICU’s date/time formatting APIs. Offers classes like `DateFormat` with methods that accept Python numbers and `datetime` objects.

- **`uicu/unicode.py`:**  
  Provides Unicode-related functionalities, including normalization, lookup, and other text processing utilities:
  - A `UnicodeString` class that mimics a Python string while wrapping ICU’s mutable `UnicodeString`.
  - Functions such as `normalize(form, unistr)`, mirroring ICU’s normalization forms (NFC, NFKC, NFD, NFKD).

- **`uicu/timezone.py`:**  
  Implements time zone related helpers, including a wrapper type (`ICUtzinfo`) that implements Python’s `tzinfo` interface by wrapping ICU’s TimeZone object.

- **`uicu/errors.py`:**  
  Defines exception classes (e.g. `UICUError`) that wrap ICU errors. All errors from lower-level ICU calls will be caught and re-raised as these exceptions.

- **`uicu/data.py`:**  
  Optional module to integrate extra Unicode data (e.g. via fontTools.unicodedata) for enhanced support of writing systems, property lookups, and extended normalization if needed.

- **`uicu/utils.py`:**  
  Utilities for common tasks (e.g. caching lookups, conversion helpers between ICU and Python types).

---

## 4. API Design and Object Specifications

Below is an outline of the key objects and functions exposed by **`uicu`**:

### 4.1. Exceptions

- **`uicu.errors.UICUError(Exception)`**  
  - Base exception for all errors in the package.
  - Wraps ICU error codes and messages.

### 4.2. Locale

- **`uicu.locale.Locale`**
  - **Constructor:**  
    `Locale(identifier: str) → Locale`  
    Uses ICU’s locale constructor. The identifier can be in the form `"en_US"`, `"pt_BR"`, etc.
  - **Methods/Properties:**
    - `get_display_name() -> str`: Returns the locale’s display name using ICU under the hood.
    - `language: str`: Property to get the ISO language.
    - `country: str`: Property to get the country code.
    - `variant: Optional[str]`: If applicable.
  - **Examples:**
    ```python
    from uicu.locale import Locale

    loc = Locale("pt_BR")
    print(loc.get_display_name())  # "Portuguese (Brazil)"
    print(loc.language)  # "pt"
    ```

### 4.3. UnicodeString

- **`uicu.unicode.UnicodeString`**
  - **Description:**  
    A wrapper around ICU’s mutable `UnicodeString` that behaves similar to Python’s native string. Internally it will accept Python `str` in its constructors.
  - **Constructor:**  
    `UnicodeString(s: Union[str, ICU_UnicodeString]= "")`
  - **Methods/Operators:**
    - `__str__() -> str`: Converts the UnicodeString to a native Python string.
    - `__getitem__() and __setitem__()`: Provide slicing and indexing (note that slicing might return a new UnicodeString, as ICU slicing conventions differ).
    - `__iadd__()`: Support for in-place concatenation (`+=`).
    - Additional helper methods: `.to_upper()`, `.to_lower()`, etc.
  - **Usage Example:**
    ```python
    from uicu.unicode import UnicodeString

    ustr = UnicodeString("Café")
    print(str(ustr))  # "Café"
    ustr += " au lait"
    print(ustr)  # "Café au lait"
    ```

### 4.4. Normalization Functions

- **`uicu.unicode.normalize(form: str, unistr: Union[str, UnicodeString]) -> str`**
  - **Supported Forms:** `'NFC'`, `'NFD'`, `'NFKC'`, `'NFKD'`.
  - **Behavior:**  
    Converts the input (either a Python `str` or a `UnicodeString`) into the specified normalized form, utilizing ICU’s normalization functionality.
  - **Example:**
    ```python
    from uicu.unicode import normalize

    normalized = normalize("NFC", "Café")
    print(normalized)
    ```

- **`uicu.unicode.is_normalized(form: str, unistr: Union[str, UnicodeString]) -> bool`**  
  Returns whether a given string is in the specified normalized form.

### 4.5. Date and Time Formatting

- **`uicu.formatting.DateFormat`**
  - **Factory Method(s):**
    - `create_instance(locale: Union[str, Locale] = None) -> DateFormat`
      - Creates a date/time formatter instance. If no locale is provided, use the default.
  - **Methods:**
    - `format(date_value: Union[float, int, datetime, Formattable]) -> str`
      - Accepts numeric values, Python’s `datetime` objects, or ICU-specific Formattable objects. It automatically converts between Python’s time conventions (seconds since epoch) and ICU’s milliseconds.
    - `parse(text: str) -> datetime`
      - Converts formatted date strings back to Python’s `datetime`.
  - **Example:**
    ```python
    from uicu.formatting import DateFormat
    from datetime import datetime

    df = DateFormat.create_instance("en_US")
    now = datetime.now()
    formatted = df.format(now)
    print(formatted)   # e.g., "10/18/23 3:04 PM"
    parsed_date = df.parse(formatted)
    ```

### 4.6. Time Zone Handling

- **`uicu.timezone.ICUtzinfo`**
  - **Purpose:**  
    Provide a class that wraps ICU’s TimeZone and implements Python’s `tzinfo` interface.
  - **Class Methods:**
    - `get_instance(tz_id: str) -> ICUtzinfo`: Returns an instance for the given time zone identifier.
    - `get_default() -> ICUtzinfo`: Returns the system default time zone.
  - **Usage:**
    ```python
    from datetime import datetime
    from uicu.timezone import ICUtzinfo

    tz = ICUtzinfo.get_instance("Pacific/Fiji")
    now = datetime.now(tz)
    print(now)
    ```

### 4.7. Unicode Data / Character Properties

- **`uicu.data.UnicodeData`**
  - **Methods:**
    - `lookup(name: str) -> str`: Look up a Unicode character by its name.
    - `name(char: str, default: Optional[str] = None) -> str`: Return the Unicode name for the given character.
    - `category(char: str) -> str`: Return the general category.
    - `digit(char: str, default: Optional[int]=None) -> int`
    - `decimal(char: str, default: Optional[int]=None) -> int`
    - `numeric(char: str, default: Optional[float]=None) -> float`
  - **Integration Strategy:**  
    This module can either simply proxy calls to Python’s built-in `unicodedata`–or use the more up-to-date fontTools.unicodedata2 as needed. It should provide a single, unified API.

---

## 5. Design Patterns and Conventions

- **Type Coercion & Conversion:**  
  Every method that interacts with ICU’s native types should accept Python’s native types as input (e.g. Python `str` for text for Unicode functions, and Python’s `datetime` or numbers for date/time). Internally, conversion happens so that the PyICU APIs’ requirements are met.

- **Error Handling:**  
  All ICU calls are wrapped in try…except constructs. Instead of dealing with ICU’s `UErrorCode` semantics, our helper functions catch these and raise clean, understandable (`UICUError`) exceptions.

- **Immutable versus Mutable:**  
  Decide clearly on mutable wrappers (e.g. for `UnicodeString`) vs immutable conversions. Document the behavior so that developers know if operations return new objects or modify in place.

- **Naming and Documentation:**  
  Use clear, Pythonic naming conventions. Every public class or function should have a docstring that explains its parameters, return values, and sample usage. Provide inline comments when wrapping lower-level interfaces.

- **Testing / Examples:**  
  For each module, create a corresponding file in a `tests/` directory. Include unit tests covering:
  - Correct conversion between ICU and Python types.
  - Error handling and exception propagation.
  - Cross-platform behavior (especially for timezone and locale handling).

---

## 6. Development and Packaging Guidelines

- **Source Control:**  
  Use Git. Organize commits by feature (Locale, Unicode, Formatting, etc.). Ensure each commit is small and passes tests.

- **Setup and Installation:**  
  - Use a `setup.py` (or the modern `pyproject.toml` and `setuptools` configuration) to declare dependencies (PyICU, fontTools.unicodedata2 if needed).
  - Include instructions in the README for obtaining and configuring ICU libraries on different systems (like PyICU’s guidelines).

- **Documentation:**  
  Write comprehensive documentation using Markdown and host it on ReadTheDocs. Use Sphinx with autodoc extensions to further generate API documentation from the docstrings.

- **Continuous Integration:**  
  Set up CI (for example, GitHub Actions) to run your test suite automatically on different Python versions and platforms.

---

## 7. Example Usage in an Application

Here is an example script demonstrating how a user would benefit from **`uicu`**:

```python
from datetime import datetime
from uicu.locale import Locale
from uicu.formatting import DateFormat
from uicu.unicode import UnicodeString, normalize
from uicu.timezone import ICUtzinfo
from uicu.data import UnicodeData

# Locale usage
locale = Locale("en_US")
print("Locale Display:", locale.get_display_name())

# DateFormat usage
df = DateFormat.create_instance(locale)
now = datetime.now(ICUtzinfo.get_instance("America/New_York"))
print("Formatted Date:", df.format(now))

# UnicodeString and normalization
ustr = UnicodeString("Café")
print("Original:", str(ustr))
print("Normalized NFC:", normalize("NFC", ustr))
ustr += " – Enjoy!"
print("Concatenated:", str(ustr))

# Unicode data lookup
try:
    char = UnicodeData.lookup("LEFT CURLY BRACKET")
    print("Lookup:", char)
except KeyError:
    print("Character not found")
```

---

## 8. Final Checklist

- [ ] **Define core abstractions** (Locale, UnicodeString, DateFormat, ICUtzinfo, UnicodeData) with clear API contracts.  
- [ ] **Implement type conversion helpers** in `uicu/core.py` and `uicu/utils.py`.  
- [ ] **Wrap ICU error codes** into a custom error (`UICUError` in `uicu/errors.py`).  
- [ ] **Integrate (if needed) fontTools.unicodedata** functions in `uicu/data.py` with fallbacks to Python’s `unicodedata`.  
- [ ] **Write unit tests** for every module (each function, method, and error condition).  
- [ ] **Document all public-facing interfaces** with examples and docstrings.  
- [ ] **Package the library** using setuptools/pyproject.toml and add a README with installation instructions and usage examples.  
- [ ] **Set up CI/CD integration** for automated testing across platforms and Python versions.

---

By following this detailed specification, you will create the **`uicu`** package—a highly usable, pythonic, and comprehensive interface to the powerful ICU libraries for Unicode and internationalization support.
</file>

<file path="src/uicu/format.py">
#!/usr/bin/env python
# this_file: src/uicu/format.py
"""Locale-aware formatting for dates, numbers, lists, and messages.

This module provides Pythonic interfaces for ICU's formatting functionality,
enabling locale-sensitive formatting of dates, times, numbers, currencies,
lists, and complex messages.
"""

from datetime import datetime, timezone, tzinfo

import icu

from uicu.exceptions import ConfigurationError, OperationError
from uicu.locale import Locale

# Error messages
EMPTY_STRING_ERROR = "Cannot parse empty string"
PARSE_ERROR_MSG = "Parse error at position {error_index} in '{text}'"
PATTERN_PARSE_ERROR_MSG = "Unable to parse '{text}' with pattern '{pattern}'"
PATTERN_PARSE_FAIL_MSG = "Failed to parse '{text}' with pattern '{pattern}': {error}"
NO_PATTERN_ERROR = "Cannot parse with style-based formatter - use pattern-based formatter for parsing"

# Constants
MAGIC_TWO = 2  # Used in list formatting for 2-item lists


class DateTimeFormatter:
    """Formats datetime objects according to locale conventions.

    This class provides locale-aware formatting for dates and times,
    supporting various styles, custom patterns, and timezone handling.
    """

    def __init__(
        self,
        locale: str | Locale,
        date_style: str = "medium",
        time_style: str = "medium",
        pattern: str | None = None,
        skeleton: str | None = None,
        timezone: str | tzinfo | None = None,
    ):
        """Initialize a date/time formatter.

        Styles: 'full', 'long', 'medium', 'short', 'none'.
        Pattern overrides styles (e.g., 'yyyy-MM-dd').
        Skeleton is flexible pattern (e.g., 'yMMMd').

        Examples:
            >>> formatter = DateTimeFormatter('en-US')
            >>> formatter.format(datetime.now())
            'Jan 25, 2025, 3:45:30 PM'

            >>> formatter = DateTimeFormatter('en-US', pattern='EEEE, MMMM d, yyyy')
            >>> formatter.format(datetime(2025, 1, 25))
            'Saturday, January 25, 2025'
        """
        # Convert string locale to Locale object if needed
        if isinstance(locale, str):
            try:
                locale = Locale(locale)
            except Exception as e:
                msg = f"Invalid locale '{locale}': {e}"
                raise OperationError(msg) from e

        self._locale = locale
        self._date_style = date_style
        self._time_style = time_style
        self._pattern = pattern
        self._skeleton = skeleton

        # Create formatter based on provided options
        if pattern:
            # Use custom pattern
            self._formatter = icu.SimpleDateFormat(pattern, locale._icu_locale)
        elif skeleton:
            # Use skeleton pattern with pattern generator
            pg = icu.DateTimePatternGenerator.createInstance(locale._icu_locale)
            best_pattern = pg.getBestPattern(skeleton)
            self._formatter = icu.SimpleDateFormat(best_pattern, locale._icu_locale)
        else:
            # Use style-based formatter
            style_map = {
                "full": icu.DateFormat.kFull,
                "long": icu.DateFormat.kLong,
                "medium": icu.DateFormat.kMedium,
                "short": icu.DateFormat.kShort,
                "none": -1,
            }

            date_style_val = style_map.get(date_style)
            time_style_val = style_map.get(time_style)

            if date_style_val is None:
                msg = f"Invalid date_style '{date_style}'. Must be one of: full, long, medium, short, none"
                raise OperationError(msg)
            if time_style_val is None:
                msg = f"Invalid time_style '{time_style}'. Must be one of: full, long, medium, short, none"
                raise OperationError(msg)

            self._formatter = icu.DateFormat.createDateTimeInstance(date_style_val, time_style_val, locale._icu_locale)

        # Set timezone if provided
        if timezone:
            self._set_timezone(timezone)

    def _set_timezone(self, timezone: str | tzinfo):
        """Set the timezone for formatting.

        Args:
            timezone: Timezone identifier string or Python tzinfo object.
        """
        try:
            if isinstance(timezone, str):
                # String timezone ID
                tz = icu.TimeZone.createTimeZone(timezone)
            elif hasattr(timezone, "tzname"):
                # Python tzinfo object - try to get timezone ID
                tz_name = timezone.tzname(None)
                if tz_name:
                    tz = icu.TimeZone.createTimeZone(tz_name)
                else:
                    # Fall back to UTC offset
                    offset = timezone.utcoffset(None)
                    if offset:
                        hours = int(offset.total_seconds() // 3600)
                        minutes = int((offset.total_seconds() % 3600) // 60)
                        tz = icu.SimpleTimeZone(hours * 60 + minutes, "Custom")
                    else:
                        tz = icu.TimeZone.getGMT()
            else:
                msg = f"Invalid timezone type: {type(timezone)}"
                raise OperationError(msg)

            self._formatter.setTimeZone(tz)
        except Exception as e:
            msg = f"Failed to set timezone: {e}"
            raise OperationError(msg) from e

    def format(self, dt: datetime) -> str:
        """Format a datetime object to a string.

        Args:
            dt: The datetime to format.

        Returns:
            The formatted date/time string.

        Raises:
            OperationError: If formatting fails.

        Examples:
            >>> formatter = DateTimeFormatter('fr-FR', date_style='long',
            ...                              time_style='short')
            >>> formatter.format(datetime(2025, 1, 25, 15, 30))
            '25 janvier 2025 à 15:30'
        """
        # Create ICU Calendar and set the datetime
        cal = icu.GregorianCalendar()
        # Note: ICU months are 0-based
        cal.set(dt.year, dt.month - 1, dt.day, dt.hour, dt.minute, dt.second)
        cal.set(icu.Calendar.MILLISECOND, dt.microsecond // 1000)

        # If datetime has timezone info, set it
        if dt.tzinfo:
            tz_name = dt.tzinfo.tzname(dt)
            if tz_name:
                tz = icu.TimeZone.createTimeZone(tz_name)
                cal.setTimeZone(tz)

        # Get the ICU time value
        icu_time = cal.getTime()

        return self._formatter.format(icu_time)

    def parse(self, text: str, *, lenient: bool = True) -> datetime:
        """Parse a string to a datetime object.

        Args:
            text: The string to parse
            lenient: Whether to be lenient in parsing. Defaults to True.

        Returns:
            datetime: The parsed datetime

        Raises:
            OperationError: If parsing fails
        """
        if not text.strip():
            raise OperationError(EMPTY_STRING_ERROR)

        try:
            # Set leniency on the formatter
            self._formatter.setLenient(lenient)

            # Try to parse with the current formatter
            parse_position = icu.ParsePosition(0)
            icu_date = self._formatter.parse(text, parse_position)

            if parse_position.getErrorIndex() >= 0:
                error_index = parse_position.getErrorIndex()
                raise OperationError(PARSE_ERROR_MSG.format(error_index=error_index, text=text))

            if icu_date is None or parse_position.getIndex() == 0:
                # Try to get a pattern and parse with that
                pattern = self._formatter.toPattern()
                if pattern:
                    try:
                        simple_formatter = icu.SimpleDateFormat(pattern, self._locale._icu_locale)
                        icu_date = simple_formatter.parse(text)
                        if icu_date is None:
                            raise OperationError(PATTERN_PARSE_ERROR_MSG.format(text=text, pattern=pattern))
                    except Exception as e:
                        raise OperationError(PATTERN_PARSE_FAIL_MSG.format(text=text, pattern=pattern, error=e)) from e

                    # Convert ICU date (seconds since epoch) to Python datetime
                    return datetime.fromtimestamp(icu_date, tz=timezone.utc)
                # No pattern available, cannot parse
                raise OperationError(NO_PATTERN_ERROR)

            # Convert ICU date (seconds since epoch) to Python datetime
            return datetime.fromtimestamp(icu_date, tz=timezone.utc)

        except Exception as e:
            if not isinstance(e, OperationError):
                raise OperationError(
                    PATTERN_PARSE_FAIL_MSG.format(text=text, pattern=self._formatter.toPattern(), error=e)
                ) from e
            raise

    def parse_strict(self, text: str) -> datetime:
        """Parse a string using strict parsing rules.

        This is a convenience method equivalent to parse(text, lenient=False).

        Args:
            text: String to parse.

        Returns:
            Parsed datetime object.

        Raises:
            OperationError: If parsing fails.
        """
        return self.parse(text, lenient=False)

    def format_range(self, start: datetime, end: datetime) -> str:
        """Format a date/time range.

        Args:
            start: Start date/time
            end: End date/time

        Returns:
            str: Formatted range

        Example:
            >>> formatter = DateTimeFormatter('en-US', date_style='medium', time_style='none')
            >>> start = datetime(2025, 1, 3)
            >>> end = datetime(2025, 1, 5)
            >>> formatter.format_range(start, end)
            'Jan 3 - 5, 2025'
        """
        # Create interval formatter with same style
        # For date intervals, we typically don't want time
        skeleton = "yMMMd" if self._time_style == "none" or self._date_style == "none" else "yMMMdjm"

        dtifmt = icu.DateIntervalFormat.createInstance(skeleton, self._locale._icu_locale)

        # Convert Python datetimes to ICU timestamps
        start_ts = int(start.timestamp() * 1000)  # ICU uses milliseconds
        end_ts = int(end.timestamp() * 1000)

        # Format the range
        from_field = icu.FieldPosition(0)
        to_field = icu.FieldPosition(0)
        result = dtifmt.format((start_ts, end_ts), from_field, to_field)

        return result.replace("-", "-")  # Use standard hyphen instead of en dash

    @property
    def pattern(self) -> str | None:
        """Get the pattern used by this formatter."""
        if self._pattern:
            return self._pattern
        if isinstance(self._formatter, icu.SimpleDateFormat):
            return self._formatter.toPattern()
        return None

    @property
    def locale(self) -> Locale:
        """Get the locale used by this formatter."""
        return self._locale

    def __repr__(self) -> str:
        """Return string representation."""
        parts = [f"locale='{self._locale.language_tag}'"]
        if self._pattern:
            parts.append(f"pattern='{self._pattern}'")
        elif self._skeleton:
            parts.append(f"skeleton='{self._skeleton}'")
        else:
            parts.append(f"date_style='{self._date_style}'")
            parts.append(f"time_style='{self._time_style}'")
        return f"DateTimeFormatter({', '.join(parts)})"


class NumberFormatter:
    """Formats numbers according to locale conventions.

    This class provides locale-aware formatting for numbers, currencies,
    percentages, and scientific notation.
    """

    def __init__(
        self,
        locale: str | Locale,
        style: str = "decimal",
        min_fraction_digits: int | None = None,
        max_fraction_digits: int | None = None,
        min_integer_digits: int | None = None,
        *,
        grouping: bool = True,
        rounding_mode: str = "half_even",
    ):
        """Initialize a number formatter.

        Styles: 'decimal', 'currency', 'percent', 'scientific'.
        Rounding modes: 'ceiling', 'floor', 'half_even', 'half_up'.

        Examples:
            >>> formatter = NumberFormatter('en-US')
            >>> formatter.format(1234.56)
            '1,234.56'

            >>> formatter = NumberFormatter('de-DE', style='currency')
            >>> formatter.format_currency(1234.56, 'EUR')
            '1.234,56 €'
        """
        # Convert string locale to Locale object if needed
        if isinstance(locale, str):
            try:
                locale = Locale(locale)
            except Exception as e:
                msg = f"Invalid locale '{locale}': {e}"
                raise OperationError(msg) from e

        self._locale = locale
        self._style = style
        self._min_fraction_digits = min_fraction_digits
        self._max_fraction_digits = max_fraction_digits
        self._min_integer_digits = min_integer_digits
        self._grouping = grouping
        self._rounding_mode = rounding_mode

        # Create ICU number formatter based on style
        if style == "decimal":
            self._formatter = icu.NumberFormat.createInstance(locale._icu_locale)
        elif style == "currency":
            self._formatter = icu.NumberFormat.createCurrencyInstance(locale._icu_locale)
        elif style == "percent":
            self._formatter = icu.NumberFormat.createPercentInstance(locale._icu_locale)
        elif style == "scientific":
            self._formatter = icu.NumberFormat.createScientificInstance(locale._icu_locale)
        else:
            msg = f"Invalid style '{style}'. Must be one of: decimal, currency, percent, scientific"
            raise OperationError(msg)

        # Configure formatter options
        if min_fraction_digits is not None:
            self._formatter.setMinimumFractionDigits(min_fraction_digits)
        if max_fraction_digits is not None:
            self._formatter.setMaximumFractionDigits(max_fraction_digits)
        if min_integer_digits is not None:
            self._formatter.setMinimumIntegerDigits(min_integer_digits)

        self._formatter.setGroupingUsed(grouping)

        # Set rounding mode
        rounding_map = {
            "ceiling": icu.DecimalFormat.kRoundCeiling,
            "floor": icu.DecimalFormat.kRoundFloor,
            "half_even": icu.DecimalFormat.kRoundHalfEven,
            "half_up": icu.DecimalFormat.kRoundHalfUp,
        }
        if rounding_mode in rounding_map:
            if hasattr(self._formatter, "setRoundingMode"):
                self._formatter.setRoundingMode(rounding_map[rounding_mode])

    def format(self, number: float) -> str:
        """Format a number according to the configured style.

        Examples:
            >>> formatter = NumberFormatter('fr-FR')
            >>> formatter.format(1234.56)
            '1 234,56'

            >>> formatter = NumberFormatter('en-US', style='percent')
            >>> formatter.format(0.1234)
            '12.34%'
        """
        return self._formatter.format(number)

    def format_currency(self, amount: float, currency: str) -> str:
        """Format a number as currency.

        Args:
            amount: The numeric amount to format.
            currency: ISO 4217 currency code (e.g., 'USD', 'EUR').

        Examples:
            >>> formatter = NumberFormatter('en-US')
            >>> formatter.format_currency(1234.56, 'USD')
            '$1,234.56'

            >>> formatter = NumberFormatter('ja-JP')
            >>> formatter.format_currency(1234, 'JPY')
            '￥1,234'
        """
        # Create a currency instance for the specific currency
        currency_formatter = icu.NumberFormat.createCurrencyInstance(self._locale._icu_locale)

        # Apply the same settings as our main formatter
        if self._min_fraction_digits is not None:
            currency_formatter.setMinimumFractionDigits(self._min_fraction_digits)
        if self._max_fraction_digits is not None:
            currency_formatter.setMaximumFractionDigits(self._max_fraction_digits)
        if self._min_integer_digits is not None:
            currency_formatter.setMinimumIntegerDigits(self._min_integer_digits)

        currency_formatter.setGroupingUsed(self._grouping)

        # Set the currency
        try:
            currency_unit = icu.CurrencyUnit(currency)
            currency_formatter.setCurrency(currency_unit)
        except Exception:
            # If currency setting fails, format without specific currency
            pass

        return currency_formatter.format(amount)

    def format_compact(self, number: float, notation: str = "short") -> str:
        """Format a number using compact notation (1.2K, 3.4M).

        Args:
            number: The number to format.
            notation: 'short' (1.2K) or 'long' (1.2 thousand).

        Examples:
            >>> formatter = NumberFormatter('en-US')
            >>> formatter.format_compact(1234)
            '1.2K'

            >>> formatter = NumberFormatter('en-US')
            >>> formatter.format_compact(1234, 'long')
            '1.2 thousand'

            >>> formatter = NumberFormatter('de-DE')
            >>> formatter.format_compact(1234567)
            '1,2 Mio.'
        """
        try:
            # Create compact number formatter
            if notation == "short":
                compact_formatter = icu.NumberFormat.createCompactDecimalInstance(
                    self._locale._icu_locale, icu.NumberFormat.kCompactShort
                )
            elif notation == "long":
                compact_formatter = icu.NumberFormat.createCompactDecimalInstance(
                    self._locale._icu_locale, icu.NumberFormat.kCompactLong
                )
            else:
                msg = f"Invalid notation '{notation}'. Must be 'short' or 'long'"
                raise OperationError(msg)

            # Apply the same settings as our main formatter
            if self._min_fraction_digits is not None:
                compact_formatter.setMinimumFractionDigits(self._min_fraction_digits)
            if self._max_fraction_digits is not None:
                compact_formatter.setMaximumFractionDigits(self._max_fraction_digits)

            compact_formatter.setGroupingUsed(self._grouping)

            return compact_formatter.format(number)
        except Exception:
            # Fallback to regular formatting if compact not available
            return self.format(number)

    def format_range(self, start: float, end: float) -> str:
        """Format a number range.

        Args:
            start: Start of the range.
            end: End of the range.

        Examples:
            >>> formatter = NumberFormatter('en-US')
            >>> formatter.format_range(10, 20)
            '10-20'

            >>> formatter = NumberFormatter('de-DE', style='currency')
            >>> formatter.format_range(10.50, 25.75, 'EUR')
            '10,50 €-25,75 €'
        """
        try:
            # Create range formatter
            range_formatter = icu.NumberRangeFormatter.withLocale(self._locale._icu_locale)

            # Configure based on our style
            if self._style == "currency":
                # For currency ranges, we need to specify currency in the call
                # This is a simplified implementation
                start_formatted = self.format(start)
                end_formatted = self.format(end)
                return f"{start_formatted}-{end_formatted}"
            if self._style == "percent":
                range_formatter = range_formatter.numberFormatterBoth(
                    icu.NumberFormatter.withLocale(self._locale._icu_locale).unit(
                        icu.MeasureUnit.forIdentifier("percent")
                    )
                )

            return range_formatter.formatFormattableRange(start, end).toString()
        except Exception:
            # Fallback to simple range formatting
            start_formatted = self.format(start)
            end_formatted = self.format(end)
            return f"{start_formatted}-{end_formatted}"

    @property
    def locale(self) -> Locale:
        """Get the locale used by this formatter."""
        return self._locale

    @property
    def style(self) -> str:
        """Get the style used by this formatter."""
        return self._style

    def __repr__(self) -> str:
        """Return string representation."""
        parts = [f"locale='{self._locale.language_tag}'", f"style='{self._style}'"]
        if self._min_fraction_digits is not None:
            parts.append(f"min_fraction_digits={self._min_fraction_digits}")
        if self._max_fraction_digits is not None:
            parts.append(f"max_fraction_digits={self._max_fraction_digits}")
        return f"NumberFormatter({', '.join(parts)})"


class ListFormatter:
    """Formats lists according to locale conventions.

    This class provides locale-aware formatting for lists, supporting
    different list types (and, or, units) and styles.
    """

    def __init__(
        self,
        locale: str | Locale,
        list_type: str = "and",
        style: str = "standard",
    ):
        """Initialize a list formatter.

        List types: 'and', 'or', 'units'.
        Styles: 'standard', 'short', 'narrow'.

        Examples:
            >>> formatter = ListFormatter('en-US')
            >>> formatter.format(['apples', 'oranges', 'bananas'])
            'apples, oranges, and bananas'

            >>> formatter = ListFormatter('en-US', list_type='or')
            >>> formatter.format(['red', 'blue'])
            'red or blue'

            >>> formatter = ListFormatter('es-ES', list_type='and')
            >>> formatter.format(['manzanas', 'naranjas'])
            'manzanas y naranjas'
        """
        # Convert string locale to Locale object if needed
        if isinstance(locale, str):
            try:
                locale = Locale(locale)
            except Exception as e:
                msg = f"Invalid locale '{locale}': {e}"
                raise OperationError(msg) from e

        self._locale = locale
        self._list_type = list_type
        self._style = style

        # Validate list type
        valid_types = {"and", "or", "units"}
        if list_type not in valid_types:
            msg = f"Invalid list_type '{list_type}'. Must be one of: {', '.join(valid_types)}"
            raise OperationError(msg)

        # Validate style
        valid_styles = {"standard", "short", "narrow"}
        if style not in valid_styles:
            msg = f"Invalid style '{style}'. Must be one of: {', '.join(valid_styles)}"
            raise OperationError(msg)

        # Create ICU list formatter
        try:
            # Map our types to ICU types
            type_map = {
                "and": icu.ListFormatter.kAnd,
                "or": icu.ListFormatter.kOr,
                "units": icu.ListFormatter.kUnits,
            }

            # Map our styles to ICU styles
            style_map = {
                "standard": icu.ListFormatter.kStandard,
                "short": icu.ListFormatter.kShort,
                "narrow": icu.ListFormatter.kNarrow,
            }

            self._formatter = icu.ListFormatter.createInstance(
                locale._icu_locale, type_map[list_type], style_map[style]
            )
        except Exception:
            # Fallback to creating a basic formatter
            try:
                self._formatter = icu.ListFormatter.createInstance(locale._icu_locale)
            except Exception as e2:
                msg = f"Failed to create list formatter: {e2}"
                raise ConfigurationError(msg) from e2

    def format(self, items: list[str]) -> str:
        """Format a list of strings according to locale conventions.

        Args:
            items: List of strings to format.

        Returns:
            Formatted list string.

        Raises:
            OperationError: If formatting fails.

        Examples:
            >>> formatter = ListFormatter('en-US')
            >>> formatter.format(['apple'])
            'apple'

            >>> formatter = ListFormatter('en-US')
            >>> formatter.format(['apple', 'orange'])
            'apple and orange'

            >>> formatter = ListFormatter('fr-FR', list_type='or')
            >>> formatter.format(['rouge', 'bleu', 'vert'])
            'rouge, bleu ou vert'
        """
        if not items:
            return ""

        if len(items) == 1:
            return items[0]

        try:
            # Convert to ICU string list
            string_list = [str(item) for item in items]
            return self._formatter.format(string_list)
        except Exception:
            # Fallback to simple formatting based on list type and locale
            return self._format_fallback(items)

    def _format_fallback(self, items: list[str]) -> str:
        """Fallback list formatting when ICU formatter fails."""
        if not items:
            return ""

        if len(items) == 1:
            return items[0]

        # Simple fallback based on locale and type
        locale_tag = self._locale.language_tag.lower()

        if len(items) == MAGIC_TWO:
            # Two items - use appropriate conjunction
            if self._list_type == "or":
                if locale_tag.startswith("es"):
                    return f"{items[0]} o {items[1]}"
                if locale_tag.startswith("fr"):
                    return f"{items[0]} ou {items[1]}"
                if locale_tag.startswith("de"):
                    return f"{items[0]} oder {items[1]}"
                # Default to English
                return f"{items[0]} or {items[1]}"
            if locale_tag.startswith("es"):
                return f"{items[0]} y {items[1]}"
            if locale_tag.startswith("fr"):
                return f"{items[0]} et {items[1]}"
            if locale_tag.startswith("de"):
                return f"{items[0]} und {items[1]}"
            # Default to English
            return f"{items[0]} and {items[1]}"
        # Multiple items - use comma separation with final conjunction
        if self._list_type == "or":
            if locale_tag.startswith("es"):
                return f"{', '.join(items[:-1])} o {items[-1]}"
            if locale_tag.startswith("fr"):
                return f"{', '.join(items[:-1])} ou {items[-1]}"
            if locale_tag.startswith("de"):
                return f"{', '.join(items[:-1])} oder {items[-1]}"
            # Default to English
            return f"{', '.join(items[:-1])}, or {items[-1]}"
        if locale_tag.startswith("es"):
            return f"{', '.join(items[:-1])} y {items[-1]}"
        if locale_tag.startswith("fr"):
            return f"{', '.join(items[:-1])} et {items[-1]}"
        if locale_tag.startswith("de"):
            return f"{', '.join(items[:-1])} und {items[-1]}"
        # Default to English
        return f"{', '.join(items[:-1])}, and {items[-1]}"

    @property
    def locale(self) -> Locale:
        """Get the locale used by this formatter."""
        return self._locale

    @property
    def list_type(self) -> str:
        """Get the list type used by this formatter."""
        return self._list_type

    @property
    def style(self) -> str:
        """Get the style used by this formatter."""
        return self._style

    def __repr__(self) -> str:
        """Return string representation."""
        return (
            f"ListFormatter(locale='{self._locale.language_tag}', list_type='{self._list_type}', style='{self._style}')"
        )
</file>

<file path="tests/test_char.py">
#!/usr/bin/env python
# this_file: tests/test_char.py
"""Tests for Unicode character properties module."""

import pytest

import uicu


class TestCharacterProperties:
    """Test basic character property functions."""

    def test_name(self):
        """Test character name lookup."""
        assert uicu.name("A") == "LATIN CAPITAL LETTER A"
        assert uicu.name("你") == "CJK UNIFIED IDEOGRAPH-4F60"
        assert uicu.name("🐍") == "SNAKE"

        # Test with codepoint
        assert uicu.name(65) == "LATIN CAPITAL LETTER A"

        # Test with default
        assert uicu.name("\x00", "NULL") == "NULL"

    def test_category(self):
        """Test general category."""
        assert uicu.category("A") == "Lu"  # Uppercase letter
        assert uicu.category("a") == "Ll"  # Lowercase letter
        assert uicu.category("1") == "Nd"  # Decimal number
        assert uicu.category(" ") == "Zs"  # Space separator
        assert uicu.category("!") == "Po"  # Other punctuation

    def test_bidirectional(self):
        """Test bidirectional class."""
        assert uicu.bidirectional("A") == "L"  # Left-to-right
        assert uicu.bidirectional("א") == "R"  # Right-to-left (Hebrew)
        assert uicu.bidirectional("١") == "AN"  # Arabic-Indic digit (intentional)  # noqa: RUF001

    def test_combining(self):
        """Test combining class."""
        assert uicu.combining("A") == 0  # Not combining
        assert uicu.combining("\u0301") > 0  # Combining acute accent

    def test_mirrored(self):
        """Test mirrored property."""
        assert not uicu.mirrored("A")
        assert uicu.mirrored("(")  # Parentheses are mirrored
        assert uicu.mirrored("[")  # Brackets are mirrored

    def test_numeric_values(self):
        """Test numeric value functions."""
        # Decimal
        assert uicu.decimal("5") == 5
        assert uicu.decimal("A") is None  # No decimal value
        assert uicu.decimal("A", -1) == -1

        # Digit
        assert uicu.digit("7") == 7
        assert uicu.digit("A") is None  # No digit value

        # Numeric (includes fractions)
        assert uicu.numeric("9") == 9
        assert uicu.numeric("½") == 0.5
        assert uicu.numeric("¾") == 0.75


class TestScriptAndBlock:
    """Test script and block properties (requires fontTools)."""

    @pytest.mark.skipif(not hasattr(uicu, "script"), reason="fontTools not available")
    def test_script(self):
        """Test script identification."""
        assert uicu.script("A") == "Latn"
        assert uicu.script("你") == "Hani"
        assert uicu.script("א") == "Hebr"
        assert uicu.script("ก") == "Thai"
        assert uicu.script("😀") == "Zyyy"  # Common script for emoji

    @pytest.mark.skipif(not hasattr(uicu, "script_name"), reason="fontTools not available")
    def test_script_name(self):
        """Test script name lookup."""
        assert uicu.script_name("Latn") == "Latin"
        assert uicu.script_name("Hani") == "Han"
        assert uicu.script_name("Arab") == "Arabic"

    @pytest.mark.skipif(not hasattr(uicu, "block"), reason="fontTools not available")
    def test_block(self):
        """Test block identification."""
        assert uicu.block("A") == "Basic Latin"
        assert "CJK" in uicu.block("你")
        assert "Hebrew" in uicu.block("א")


class TestCharClass:
    """Test the Char class."""

    def test_char_creation(self):
        """Test creating Char objects."""
        # From string
        ch = uicu.Char("A")
        assert ch.char == "A"
        assert ch.codepoint == 65

        # From codepoint
        ch2 = uicu.Char(65)
        assert ch2.char == "A"
        assert ch2 == ch

    def test_char_properties(self):
        """Test Char object properties."""
        ch = uicu.Char("€")
        assert ch.name == "EURO SIGN"
        assert ch.category == "Sc"  # Currency symbol
        assert ch.decimal is None
        assert not ch.mirrored

    def test_char_string_methods(self):
        """Test string representation."""
        ch = uicu.Char("A")
        assert str(ch) == "A"
        assert "A" in repr(ch)
        assert "U+0041" in repr(ch)

    def test_char_comparison(self):
        """Test character comparison."""
        ch1 = uicu.Char("A")
        ch2 = uicu.Char("A")
        ch3 = uicu.Char("B")

        assert ch1 == ch2
        assert ch1 != ch3
        assert ch1 == "A"
        assert ch1 != "B"
</file>

<file path="tests/test_format.py">
#!/usr/bin/env python
# this_file: tests/test_format.py
"""Tests for formatting module."""

from datetime import datetime, timezone

import pytest

import uicu
from uicu.exceptions import OperationError


class TestDateTimeFormatter:
    """Test DateTimeFormatter functionality."""

    def test_basic_formatting(self):
        """Test basic date/time formatting."""
        formatter = uicu.DateTimeFormatter("en-US")
        dt = datetime(2025, 1, 25, 15, 30, 45, tzinfo=timezone.utc)

        result = formatter.format(dt)
        assert "2025" in result
        assert "Jan" in result or "January" in result
        assert "25" in result
        assert "3" in result or "15" in result
        assert "30" in result
        assert "45" in result

    def test_style_options(self):
        """Test different date/time styles."""
        dt = datetime(2025, 1, 25, 15, 30, 45, tzinfo=timezone.utc)

        # Full style
        formatter = uicu.DateTimeFormatter("en-US", date_style="full", time_style="full")
        result = formatter.format(dt)
        assert "Saturday" in result
        assert "January" in result
        assert "2025" in result
        assert "Pacific" in result or "Eastern" in result or "UTC" in result

        # Short style
        formatter = uicu.DateTimeFormatter("en-US", date_style="short", time_style="short")
        result = formatter.format(dt)
        assert "1/25/25" in result or "1/25/2025" in result
        assert "3:30" in result or "15:30" in result

    def test_locale_formatting(self):
        """Test formatting with different locales."""
        dt = datetime(2025, 1, 25, 15, 30, 45, tzinfo=timezone.utc)

        # French
        formatter = uicu.DateTimeFormatter("fr-FR")
        result = formatter.format(dt)
        assert "janv." in result or "janvier" in result
        assert "2025" in result

        # German
        formatter = uicu.DateTimeFormatter("de-DE")
        result = formatter.format(dt)
        assert "Jan" in result or "Januar" in result
        assert "2025" in result

    def test_custom_pattern(self):
        """Test custom pattern formatting."""
        dt = datetime(2025, 1, 25, 15, 30, 45, tzinfo=timezone.utc)

        # Custom pattern
        formatter = uicu.DateTimeFormatter("en-US", pattern="yyyy-MM-dd HH:mm:ss")
        result = formatter.format(dt)
        assert result == "2025-01-25 15:30:45"

        # Another pattern
        formatter = uicu.DateTimeFormatter("en-US", pattern="MMMM d, yyyy")
        result = formatter.format(dt)
        assert result == "January 25, 2025"

    def test_skeleton_pattern(self):
        """Test skeleton pattern formatting."""
        dt = datetime(2025, 1, 25, 15, 30, 45, tzinfo=timezone.utc)

        # Skeleton pattern
        formatter = uicu.DateTimeFormatter("en-US", skeleton="yMMMdhm")
        result = formatter.format(dt)
        assert "Jan" in result
        assert "25" in result
        assert "2025" in result
        assert "3:30" in result or "15:30" in result

    def test_parse(self):
        """Test date/time parsing."""
        # Create formatter with pattern for reliable parsing
        formatter = uicu.DateTimeFormatter("en-US", pattern="yyyy-MM-dd HH:mm:ss")

        # Format a date first to see what format it expects
        dt = datetime(2025, 1, 25, 0, 0, 0, tzinfo=timezone.utc)
        formatted = formatter.format(dt)

        # Parse it back
        parsed = formatter.parse(formatted)
        assert parsed.year == 2025
        assert parsed.month == 1
        assert parsed.day == 25
        assert parsed.hour == 0
        assert parsed.minute == 0
        assert parsed.second == 0

        # Test with date and time
        formatter = uicu.DateTimeFormatter("en-US", date_style="short", time_style="short")
        dt = datetime(2025, 1, 25, 15, 30, tzinfo=timezone.utc)
        formatted = formatter.format(dt)
        parsed = formatter.parse(formatted)
        assert parsed.year == 2025
        assert parsed.month == 1
        assert parsed.day == 25
        assert parsed.hour == 15
        assert parsed.minute == 30

    def test_format_range(self):
        """Test date range formatting."""
        formatter = uicu.DateTimeFormatter("en-US", date_style="medium", time_style="none")

        start = datetime(2025, 1, 3, tzinfo=timezone.utc)
        end = datetime(2025, 1, 5, tzinfo=timezone.utc)

        result = formatter.format_range(start, end)

        # Check key parts are present
        assert "Jan" in result
        assert "2025" in result
        assert "3" in result
        assert "5" in result
        # Should use hyphen
        assert "-" in result

    def test_locale_factory(self):
        """Test creating formatter from locale."""
        locale = uicu.Locale("fr-FR")
        formatter = locale.get_datetime_formatter(date_style="long", time_style="short")

        dt = datetime(2025, 1, 25, 15, 30, tzinfo=timezone.utc)
        result = formatter.format(dt)
        assert "janvier" in result
        assert "2025" in result
        assert "15:30" in result or "3:30" in result

    def test_invalid_configuration(self):
        """Test error handling for invalid configuration."""
        # Invalid locale - ICU is permissive so test with truly bad locale
        with pytest.raises(OperationError):
            uicu.DateTimeFormatter("")  # Empty locale should fail

        # Invalid style
        with pytest.raises(OperationError):
            uicu.DateTimeFormatter("en-US", date_style="invalid")

    def test_parsing_errors(self):
        """Test parsing error handling."""
        pytest.skip("Parse method has been removed for v1.0 MVP")

    def test_repr(self):
        """Test string representation."""
        formatter = uicu.DateTimeFormatter("en-US", date_style="long", time_style="short")
        repr_str = repr(formatter)
        assert "DateTimeFormatter" in repr_str
        assert "en-US" in repr_str
        assert "long" in repr_str
        assert "short" in repr_str

        # With pattern
        formatter = uicu.DateTimeFormatter("en-US", pattern="yyyy-MM-dd")
        repr_str = repr(formatter)
        assert "pattern" in repr_str
        assert "yyyy-MM-dd" in repr_str
</file>

<file path="tests/test_locale.py">
#!/usr/bin/env python
# this_file: tests/test_locale.py
"""Tests for locale module."""

import pytest

import uicu


class TestLocale:
    """Test Locale class functionality."""

    def test_locale_creation(self):
        """Test creating Locale objects."""
        # With hyphen
        loc1 = uicu.Locale("en-US")
        assert loc1.language == "en"
        assert loc1.region == "US"

        # With underscore
        loc2 = uicu.Locale("fr_FR")
        assert loc2.language == "fr"
        assert loc2.region == "FR"

        # With script
        loc3 = uicu.Locale("zh-Hant-TW")
        assert loc3.language == "zh"
        assert loc3.script == "Hant"
        assert loc3.region == "TW"

    def test_locale_properties(self):
        """Test locale properties."""
        loc = uicu.Locale("en-GB")

        # Display name
        assert "English" in loc.display_name
        assert "United Kingdom" in loc.display_name or "Britain" in loc.display_name

        # Language tag
        assert loc.language_tag == "en-GB"
        assert loc.base_name == "en_GB"

    def test_invalid_locale(self):
        """Test invalid locale handling."""
        # ICU is quite permissive with locale identifiers, so we need to test
        # something that's definitely invalid
        with pytest.raises(uicu.ConfigurationError):
            uicu.Locale("")  # Empty string should be invalid

    def test_locale_comparison(self):
        """Test locale comparison."""
        loc1 = uicu.Locale("en-US")
        loc2 = uicu.Locale("en_US")  # Different separator
        loc3 = uicu.Locale("en-GB")

        assert loc1 == loc2
        assert loc1 != loc3
        assert str(loc1) == "en_US"

    def test_factory_methods(self):
        """Test factory methods for creating services."""
        loc = uicu.Locale("fr-FR")

        # Collator
        collator = loc.get_collator()
        assert collator.locale == loc

        # Word segmenter
        segmenter = loc.get_word_segmenter()
        assert segmenter is not None


class TestLocaleConvenienceFunctions:
    """Test module-level convenience functions."""

    def test_get_available_locales(self):
        """Test getting available locales."""
        locales = uicu.get_available_locales()

        # Should have many locales
        assert len(locales) > 50

        # Common locales should be present
        assert "en-US" in locales or "en_US" in locales
        assert "fr-FR" in locales or "fr_FR" in locales
        assert "ja-JP" in locales or "ja_JP" in locales

    def test_get_default_locale(self):
        """Test getting system default locale."""
        default = uicu.get_default_locale()

        # Should be a valid Locale object
        assert isinstance(default, uicu.Locale)
        assert default.language  # Should have a language code
</file>

<file path=".gitignore">
*_autogen/
.DS_Store
__version__.py
__pycache__/
_Chutzpah*
_deps
_NCrunch_*
_pkginfo.txt
_Pvt_Extensions
_ReSharper*/
_TeamCity*
_UpgradeReport_Files/
!?*.[Cc]ache/
!.axoCover/settings.json
!.vscode/extensions.json
!.vscode/launch.json
!.vscode/settings.json
!.vscode/tasks.json
!**/[Pp]ackages/build/
!Directory.Build.rsp
.*crunch*.local.xml
.axoCover/*
.builds
.cr/personal
.fake/
.history/
.ionide/
.localhistory/
.mfractor/
.ntvs_analysis.dat
.paket/paket.exe
.sass-cache/
.vs/
.vscode
.vscode/*
.vshistory/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
[Bb]in/
[Bb]uild[Ll]og.*
[Dd]ebug/
[Dd]ebugPS/
[Dd]ebugPublic/
[Ee]xpress/
[Ll]og/
[Ll]ogs/
[Oo]bj/
[Rr]elease/
[Rr]eleasePS/
[Rr]eleases/
[Tt]est[Rr]esult*/
[Ww][Ii][Nn]32/
*_h.h
*_i.c
*_p.c
*_wpftmp.csproj
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl
*- [Bb]ackup.rdl
*.[Cc]ache
*.[Pp]ublish.xml
*.[Rr]e[Ss]harper
*.a
*.app
*.appx
*.appxbundle
*.appxupload
*.aps
*.azurePubxml
*.bim_*.settings
*.bim.layout
*.binlog
*.btm.cs
*.btp.cs
*.build.csdef
*.cab
*.cachefile
*.code-workspace
*.coverage
*.coveragexml
*.d
*.dbmdl
*.dbproj.schemaview
*.dll
*.dotCover
*.DotSettings.user
*.dsp
*.dsw
*.dylib
*.e2e
*.exe
*.gch
*.GhostDoc.xml
*.gpState
*.ilk
*.iobj
*.ipdb
*.jfm
*.jmconfig
*.la
*.lai
*.ldf
*.lib
*.lo
*.log
*.mdf
*.meta
*.mm.*
*.mod
*.msi
*.msix
*.msm
*.msp
*.ncb
*.ndf
*.nuget.props
*.nuget.targets
*.nupkg
*.nvuser
*.o
*.obj
*.odx.cs
*.opendb
*.opensdf
*.opt
*.out
*.pch
*.pdb
*.pfx
*.pgc
*.pgd
*.pidb
*.plg
*.psess
*.publishproj
*.publishsettings
*.pubxml
*.pyc
*.rdl.data
*.rptproj.bak
*.rptproj.rsuser
*.rsp
*.rsuser
*.sap
*.sbr
*.scc
*.sdf
*.sln.docstates
*.sln.iml
*.slo
*.smod
*.snupkg
*.so
*.suo
*.svclog
*.tlb
*.tlh
*.tli
*.tlog
*.tmp
*.tmp_proj
*.tss
*.user
*.userosscache
*.userprefs
*.vbp
*.vbw
*.VC.db
*.VC.VC.opendb
*.VisualState.xml
*.vsp
*.vspscc
*.vspx
*.vssscc
*.xsd.cs
**/[Pp]ackages/*
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.HTMLClient/GeneratedArtifacts
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
*~
~$*
$tf/
AppPackages/
artifacts/
ASALocalRun/
AutoTest.Net/
Backup*/
BenchmarkDotNet.Artifacts/
bld/
BundleArtifacts/
ClientBin/
cmake_install.cmake
CMakeCache.txt
CMakeFiles
CMakeLists.txt.user
CMakeScripts
CMakeUserPresets.json
compile_commands.json
coverage*.info
coverage*.json
coverage*.xml
csx/
CTestTestfile.cmake
dlldata.c
DocProject/buildhelp/
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/*.HxC
DocProject/Help/*.HxT
DocProject/Help/html
DocProject/Help/Html2
ecf/
FakesAssemblies/
FodyWeavers.xsd
Generated_Code/
Generated\ Files/
healthchecksdb
install_manifest.txt
ipch/
Makefile
MigrationBackup/
mono_crash.*
nCrunchTemp_*
node_modules/
nunit-*.xml
OpenCover/
orleans.codegen.cs
Package.StoreAssociation.xml
paket-files/
project.fragment.lock.json
project.lock.json
publish/
PublishScripts/
rcf/
ScaffoldingReadMe.txt
ServiceFabricBackup/
StyleCopReport.xml
Testing
TestResult.xml
UpgradeLog*.htm
UpgradeLog*.XML
x64/
x86/
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Distribution / packaging
!dist/.gitkeep

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/
.ruff_cache/

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDE
.idea/
.vscode/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Project specific
__version__.py
_private
VERSION.txt
</file>

<file path=".pre-commit-config.yaml">
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.3.4
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format
        args: [--respect-gitignore]
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: check-yaml
      - id: check-toml
      - id: check-added-large-files
      - id: debug-statements
      - id: check-case-conflict
      - id: mixed-line-ending
        args: [--fix=lf]
</file>

<file path="DEVELOPMENT_STATUS.md">
# uicu Development Status Report

*Last Updated: 2025-01-25*

## Executive Summary

The `uicu` package provides a Pythonic wrapper around PyICU, making Unicode text processing and internationalization accessible to Python developers. The project has successfully implemented core functionality including character properties, locale management, collation, segmentation, and transliteration. A partial implementation of date/time formatting is available, though parsing needs fixes.

## Current Version: 0.2.0-dev

### What Works Well ✅

1. **Character Properties** - Full Unicode character analysis
   - Name, category, script, block lookup
   - Numeric values, bidirectional properties
   - Integration with fontTools for latest Unicode data

2. **Locale Management** - BCP 47 compliant locale handling
   - Parse and validate locale identifiers
   - Factory pattern for creating locale-specific services
   - Access to 700+ locales

3. **Collation & Sorting** - Culture-aware string comparison
   - Multiple strength levels
   - Numeric sorting (2 < 10)
   - Direct integration with Python's sorted()

4. **Text Segmentation** - Unicode-compliant boundary detection
   - Grapheme clusters (user-perceived characters)
   - Word boundaries with locale rules
   - Sentence detection with abbreviation handling

5. **Transliteration** - Script conversion and transforms
   - Working transforms: Cyrillic-Latin, Greek-Latin, etc.
   - Case transformations
   - Normalization forms (NFC, NFD, NFKC, NFKD)

6. **Documentation & Examples**
   - Comprehensive README with examples
   - 12-demo example script covering all features
   - Detailed CHANGELOG
   - Clear development roadmap

### Known Issues ⚠️

1. **DateTimeFormatter Parsing**
   - Returns incorrect dates (1970 epoch)
   - Milliseconds interpreted as seconds
   - Complex parsing not implemented

2. **Transliteration**
   - Some transform IDs incorrect (e.g., "Russian-Latin")
   - No way to list available transforms
   - Poor error messages

3. **Character Properties**
   - Can't handle multi-codepoint strings (flag emojis)
   - Missing convenient functions at module level

### Not Yet Implemented ❌

1. **Formatting Components**
   - NumberFormatter (decimal, currency, percent)
   - ListFormatter (locale-aware list joining)
   - MessageFormatter (plurals, gender selection)

2. **Documentation**
   - No Sphinx setup
   - No API reference docs
   - No tutorials

3. **Infrastructure**
   - No performance benchmarks
   - No CI/CD setup
   - Test coverage at ~80%

## Development Metrics

| Component | Status | Coverage | Notes |
|-----------|--------|----------|-------|
| Character Properties | ✅ Complete | 95% | Single codepoint only |
| Locale Management | ✅ Complete | 90% | All major features |
| Collation | ✅ Complete | 95% | Full functionality |
| Segmentation | ✅ Complete | 90% | All break types |
| Transliteration | ⚡ Partial | 80% | Transform ID issues |
| Date Formatting | ⚡ Partial | 60% | Parsing broken |
| Number Formatting | ❌ Not Started | 0% | Issue #103 |
| List Formatting | ❌ Not Started | 0% | Issue #104 |
| Message Formatting | ❌ Not Started | 0% | Issue #105 |

## Issue Tracking

### Open Issues
- **#102**: DateTimeFormatter - Partially complete, parsing needs fixes
- **#103**: NumberFormatter - Not started
- **#104**: ListFormatter - Not started
- **#105**: MessageFormatter - Not started
- **#106**: Documentation - Sphinx setup needed
- **#107**: Performance Benchmarks - Not started
- **#202**: Fix Transliterator Transform IDs - New issue

### Closed Issues
- **#101**: Linting issues - Fixed
- **#108**: Example scripts - Completed with uicu_demo.py
- **#201**: Demo script bugs - Fixed

## Next Steps

### Immediate Priorities (This Week)
1. Fix DateTimeFormatter parsing bug
2. Document available transliterator transforms
3. Handle multi-codepoint strings in Char class

### Short Term (v0.2.0 - Next Month)
1. Implement NumberFormatter
2. Implement ListFormatter
3. Set up Sphinx documentation
4. Reach 90% test coverage

### Medium Term (v0.3.0 - Next Quarter)
1. Performance benchmarks
2. MessageFormatter implementation
3. CI/CD with GitHub Actions
4. Property-based testing

## Recommendations

1. **Fix Critical Bugs First** - The DateTimeFormatter parsing bug makes the feature unusable for bidirectional conversion.

2. **Document Limitations** - Be clear about what doesn't work (e.g., flag emojis) and provide workarounds.

3. **Focus on Core Formatters** - NumberFormatter and ListFormatter are essential for i18n applications.

4. **Set Up CI Early** - Automated testing will catch regressions as the codebase grows.

5. **Engage Community** - The comprehensive demo script can attract early adopters who can provide feedback.

## Conclusion

The uicu project has made excellent progress in providing Pythonic access to ICU's Unicode capabilities. The core functionality is solid and well-tested. The main gaps are in the formatting module and documentation infrastructure. With focused effort on the immediate priorities, the package could reach a stable v0.2.0 release within a month.
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 Adam Twardoch

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="package.toml">
# Package configuration
[package]
include_cli = true        # Include CLI boilerplate
include_logging = true    # Include logging setup
use_pydantic = true      # Use Pydantic for data validation
use_rich = true          # Use Rich for terminal output

[features]
mkdocs = false           # Enable MkDocs documentation
vcs = true              # Initialize Git repository
github_actions = true   # Add GitHub Actions workflows
</file>

<file path="src/uicu/__init__.py">
#!/usr/bin/env python
# this_file: src/uicu/__init__.py
"""uicu - A Pythonic wrapper for PyICU.

This package provides natural, Pythonic interfaces to ICU's powerful
internationalization and Unicode capabilities, making advanced text
processing accessible to Python developers.
"""

# Version information
try:
    from uicu._version import __version__  # type: ignore
except ImportError:
    __version__ = "0.0.1dev"

# Import main components for convenient access
from uicu.char import (
    # Classes
    Char,
    bidirectional,
    block,
    category,
    combining,
    decimal,
    digit,
    mirrored,
    # Functions
    name,
    numeric,
    script,
    script_direction,
    script_extensions,
    script_name,
)
from uicu.collate import Collator, compare, sort
from uicu.exceptions import (
    ConfigurationError,
    UICUError,
)
from uicu.locale import Locale, get_available_locales, get_default_locale
from uicu.segment import (
    # Classes
    GraphemeSegmenter,
    LineSegmenter,
    SentenceSegmenter,
    WordSegmenter,
    # Functions
    graphemes,
    line_breaks,
    lines,
    sentences,
    words,
)
from uicu.translit import (
    Transliterator,
    find_transforms,
    get_available_transforms,
    transliterate,
)

# Import formatting components
try:
    from uicu.format import DateTimeFormatter, ListFormatter, NumberFormatter
except ImportError:
    # Format module not yet fully implemented
    DateTimeFormatter = None
    ListFormatter = None
    NumberFormatter = None

# Import script detection dependencies at module level
try:
    from uicu.char import HAS_FONTTOOLS
    from uicu.char import script as get_script
except ImportError:
    HAS_FONTTOOLS = False
    get_script = None


# Script detection helper
def detect_script(text: str) -> str | None:
    """Detect the primary script used in text.

    Args:
        text: Text to analyze.

    Returns:
        ISO 15924 script code (e.g., 'Latn', 'Cyrl', 'Hani') or None if mixed.
    """
    if not text:
        return None

    try:
        if not HAS_FONTTOOLS or get_script is None:
            return None

        # Count scripts used
        script_counts = {}
        for char in text:
            if char.isalpha():  # Only count alphabetic characters
                s = get_script(char)
                if s not in ("Zyyy", "Zinh", "Zzzz"):  # Ignore common/inherited/unknown
                    script_counts[s] = script_counts.get(s, 0) + 1

        if not script_counts:
            return None

        # Return most common script
        return max(script_counts.items(), key=lambda x: x[1])[0]
    except Exception:
        return None


# Define what's exported with "from uicu import *"
__all__ = [
    "Char",
    "CollationError",
    "Collator",
    "ConfigurationError",
    "DateTimeFormatter",
    "FormattingError",
    "GraphemeSegmenter",
    "LineSegmenter",
    "ListFormatter",
    "Locale",
    "NumberFormatter",
    "SegmentationError",
    "SentenceSegmenter",
    "TransliterationError",
    "Transliterator",
    "UICUError",
    "WordSegmenter",
    "__version__",
    "bidirectional",
    "block",
    "category",
    "combining",
    "compare",
    "decimal",
    "detect_script",
    "digit",
    "find_transforms",
    "get_available_locales",
    "get_available_transforms",
    "get_default_locale",
    "graphemes",
    "line_breaks",
    "lines",
    "mirrored",
    "name",
    "numeric",
    "script",
    "script_direction",
    "script_extensions",
    "script_name",
    "sentences",
    "sort",
    "transliterate",
    "words",
]
</file>

<file path="src/uicu/char.py">
#!/usr/bin/env python
# this_file: src/uicu/char.py
"""Unicode character properties module.

This module provides Pythonic access to Unicode character information using
the latest Unicode data from fontTools.unicodedata with fallback to Python's
built-in unicodedata module.

Note: This module analyzes individual Unicode codepoints. Multi-codepoint
grapheme clusters (like flag emojis) should be broken into individual
codepoints for analysis. Use the uicu.segment module for grapheme-aware
text processing.
"""

import unicodedata
from typing import Any

try:
    from fontTools import unicodedata as ftunicodedata

    HAS_FONTTOOLS = True
except ImportError:
    HAS_FONTTOOLS = False
    import unicodedata as ftunicodedata
    import warnings

    warnings.warn(
        "fontTools.unicodedata not available. Using built-in unicodedata which may have older Unicode data.",
        ImportWarning,
        stacklevel=2,
    )


def _normalize_char_input(char: str | int) -> str:
    """Normalize character input to a single character string.

    Converts integer codepoints to characters and validates string length.
    """
    if isinstance(char, int):
        try:
            return chr(char)
        except ValueError as e:
            msg = f"Invalid codepoint: {char}"
            raise ValueError(msg) from e
    if isinstance(char, str):
        if len(char) != 1:
            # Check if it might be a multi-codepoint grapheme
            if len(char) > 1:
                msg = (
                    f"Expected single character, got string of length {len(char)}. "
                    f"Multi-codepoint sequences like '{char}' are not supported. "
                    f"Consider using char[0] to analyze the first codepoint, "
                    f"or use uicu.graphemes() for grapheme-aware processing."
                )
            else:
                msg = "Expected single character, got empty string"
            raise ValueError(msg)
        return char

    msg = f"Expected str or int, got {type(char).__name__}"
    raise TypeError(msg)


# Basic properties (delegate to fontTools.unicodedata or built-in)


def name(char: str | int, default: str | None = None) -> str | None:
    """Return Unicode name of character.

    Returns default if character has no name, raises ValueError if no default.
    """
    char = _normalize_char_input(char)
    try:
        return ftunicodedata.name(char)
    except ValueError:
        if default is not None:
            return default
        raise


def category(char: str | int) -> str:
    """Return general category (e.g., 'Lu' for uppercase letter)."""
    char = _normalize_char_input(char)
    return ftunicodedata.category(char)


def bidirectional(char: str | int) -> str:
    """Return bidirectional class (e.g., 'L' for left-to-right)."""
    char = _normalize_char_input(char)
    return ftunicodedata.bidirectional(char)


def combining(char: str | int) -> int:
    """Return canonical combining class as integer."""
    char = _normalize_char_input(char)
    return ftunicodedata.combining(char)


def mirrored(char: str | int) -> bool:
    """Return True if character is mirrored in bidi text."""
    char = _normalize_char_input(char)
    # fontTools.unicodedata doesn't have mirrored property
    # Always use built-in unicodedata for this
    return bool(unicodedata.mirrored(char))


def decimal(char: str | int, default: Any = None) -> int | None:
    """Return decimal value of character, or default if none."""
    char = _normalize_char_input(char)
    try:
        return ftunicodedata.decimal(char)
    except (KeyError, ValueError):
        return default


def digit(char: str | int, default: Any = None) -> int | None:
    """Return digit value of character.

    Args:
        char: A single character or integer codepoint.
        default: Default value if character has no digit value.

    Returns:
        Digit value as integer, or default if provided.

    Raises:
        ValueError: If no digit value and no default provided.
    """
    char = _normalize_char_input(char)
    try:
        return ftunicodedata.digit(char)
    except (KeyError, ValueError):
        return default


def numeric(char: str | int, default: Any = None) -> int | float | None:
    """Return numeric value of character, or default if none."""
    char = _normalize_char_input(char)
    try:
        return ftunicodedata.numeric(char)
    except (KeyError, ValueError):
        return default


# Script and block properties (unique to fontTools)


def script(char: str | int) -> str:
    """Return ISO 15924 script code (e.g., 'Latn', 'Hani')."""
    if not HAS_FONTTOOLS:
        msg = "script() requires fontTools.unicodedata"
        raise NotImplementedError(msg)
    char = _normalize_char_input(char)
    return ftunicodedata.script(char)


def script_name(code: str) -> str:
    """Return human-readable script name for ISO 15924 code."""
    if not HAS_FONTTOOLS:
        msg = "script_name() requires fontTools.unicodedata"
        raise NotImplementedError(msg)
    return ftunicodedata.script_name(code)


def script_extensions(char: str | int) -> set[str]:
    """Return set of scripts that use this character."""
    if not HAS_FONTTOOLS:
        msg = "script_extensions() requires fontTools.unicodedata"
        raise NotImplementedError(msg)
    char = _normalize_char_input(char)
    # fontTools returns a set for script extensions
    extensions = ftunicodedata.script_extension(char)
    # If no extensions, return set with just the main script
    if not extensions:
        return {script(char)}
    return extensions


def block(char: str | int) -> str:
    """Return Unicode block name.

    Args:
        char: A single character or integer codepoint.

    Returns:
        Unicode block name (e.g., 'Basic Latin').
    """
    if not HAS_FONTTOOLS:
        msg = "block() requires fontTools.unicodedata"
        raise NotImplementedError(msg)
    char = _normalize_char_input(char)
    return ftunicodedata.block(char)


def script_direction(script_code: str) -> str:
    """Return 'LTR' or 'RTL' for script direction.

    Args:
        script_code: Four-letter ISO 15924 script code.

    Returns:
        'LTR' for left-to-right or 'RTL' for right-to-left.
    """
    if not HAS_FONTTOOLS:
        msg = "script_direction() requires fontTools.unicodedata"
        raise NotImplementedError(msg)
    return ftunicodedata.script_horizontal_direction(script_code)  # type: ignore[attr-defined]


# Optional OOP Interface


class Char:
    """Rich Unicode character object.

    This class provides an object-oriented interface to Unicode character
    properties, bundling all property access into a single object.

    Note: This class currently only supports single Unicode codepoints.
    Multi-codepoint grapheme clusters (like flag emojis 🇺🇸) are not
    supported. Use the first codepoint or iterate over the string to
    analyze individual codepoints.
    """

    def __init__(self, char: str | int):
        """Initialize with a character or codepoint.

        Args:
            char: A single character string or integer codepoint.
                  Multi-codepoint sequences like flag emojis are not supported.

        Raises:
            ValueError: If char is a multi-character string.
        """
        self._char = _normalize_char_input(char)
        self._codepoint = ord(self._char)

    @property
    def char(self) -> str:
        """The character as a string."""
        return self._char

    @property
    def codepoint(self) -> int:
        """The Unicode codepoint as an integer."""
        return self._codepoint

    @property
    def name(self) -> str | None:
        """Unicode name of the character."""
        return name(self._char, f"U+{self._codepoint:04X}")

    @property
    def category(self) -> str:
        """General category code."""
        return category(self._char)

    @property
    def bidirectional(self) -> str:
        """Bidirectional class."""
        return bidirectional(self._char)

    @property
    def combining(self) -> int:
        """Canonical combining class."""
        return combining(self._char)

    @property
    def mirrored(self) -> bool:
        """True if character is mirrored in bidi text."""
        return mirrored(self._char)

    @property
    def decimal(self) -> int | None:
        """Decimal value or None."""
        return decimal(self._char, None)

    @property
    def digit(self) -> int | None:
        """Digit value or None."""
        return digit(self._char, None)

    @property
    def numeric(self) -> int | float | None:
        """Numeric value or None."""
        return numeric(self._char, None)

    @property
    def script(self) -> str | None:
        """ISO 15924 script code."""
        if not HAS_FONTTOOLS:
            return None
        return script(self._char)

    @property
    def script_extensions(self) -> set[str]:
        """Set of scripts that use this character."""
        if not HAS_FONTTOOLS:
            return set()
        return script_extensions(self._char)

    @property
    def block(self) -> str | None:
        """Unicode block name."""
        if not HAS_FONTTOOLS:
            return None
        return block(self._char)

    def __str__(self) -> str:
        """Return the character itself."""
        return self._char

    def __repr__(self) -> str:
        """Return a detailed representation."""
        return f"<Char {self._char!r} U+{self._codepoint:04X} '{self.name}'>"

    def __eq__(self, other: object) -> bool:
        """Compare characters."""
        if isinstance(other, Char):
            return self._char == other._char
        if isinstance(other, str):
            return self._char == other
        return NotImplemented

    def __hash__(self) -> int:
        """Hash based on the character."""
        return hash(self._char)
</file>

<file path="src/uicu/collate.py">
#!/usr/bin/env python
# this_file: src/uicu/collate.py
"""Locale-aware string comparison and sorting.

This module provides Pythonic interfaces for ICU's collation functionality,
enabling locale-sensitive string comparison and sorting.
"""

from collections.abc import Iterable

import icu

from uicu.exceptions import ConfigurationError
from uicu.locale import Locale

# Map string strength names to ICU constants
STRENGTH_MAP = {
    "primary": icu.Collator.PRIMARY,
    "secondary": icu.Collator.SECONDARY,
    "tertiary": icu.Collator.TERTIARY,
    "quaternary": icu.Collator.QUATERNARY,
    "identical": icu.Collator.IDENTICAL,
}


class Collator:
    """Locale-aware string collator for sorting.

    This class wraps ICU's Collator to provide locale-sensitive string
    comparison and sorting. It can be used directly as a key function
    with Python's sorted() function.
    """

    def __init__(
        self,
        locale: str | Locale,
        strength: str = "tertiary",
        *,
        numeric: bool = False,
        case_first: str | None = None,
        case_level: bool = False,
    ):
        """Create a collator.

        Args:
            locale: Locale identifier string or Locale object.
            strength: Comparison strength level:
                     - 'primary': Base letters only (ignore case, accents)
                     - 'secondary': Consider accents (ignore case)
                     - 'tertiary': Consider case differences (default)
                     - 'quaternary': Consider variant differences
                     - 'identical': Bit-for-bit identical
            numeric: Enable numeric sorting where "2" < "10".
            case_first: Which case to sort first - 'upper', 'lower', or None.
            case_level: Enable separate case level between secondary and tertiary.

        Raises:
            ConfigurationError: If locale or configuration is invalid.
        """
        # Convert string locale to Locale object if needed
        if isinstance(locale, str):
            try:
                locale = Locale(locale)
            except Exception as e:
                msg = f"Invalid locale '{locale}': {e}"
                raise ConfigurationError(msg) from e

        # Create ICU collator
        self._collator = icu.Collator.createInstance(locale._icu_locale)

        # Set strength
        if strength not in STRENGTH_MAP:
            msg = f"Invalid strength '{strength}'. Must be one of: {', '.join(STRENGTH_MAP.keys())}"
            raise ConfigurationError(msg)
        self._collator.setStrength(STRENGTH_MAP[strength])

        # Configure numeric sorting
        if numeric:
            self._collator.setAttribute(icu.UCollAttribute.NUMERIC_COLLATION, icu.UCollAttributeValue.ON)

        # Configure case ordering
        if case_first == "upper":
            self._collator.setAttribute(icu.UCollAttribute.CASE_FIRST, icu.UCollAttributeValue.UPPER_FIRST)
        elif case_first == "lower":
            self._collator.setAttribute(icu.UCollAttribute.CASE_FIRST, icu.UCollAttributeValue.LOWER_FIRST)

        # Configure case level
        if case_level:
            self._collator.setAttribute(icu.UCollAttribute.CASE_LEVEL, icu.UCollAttributeValue.ON)

        # Store configuration for reference
        self._locale = locale
        self._strength = strength
        self._numeric = numeric

    def compare(self, a: str, b: str) -> int:
        """Compare two strings according to collation rules.

        Returns -1 if a < b, 0 if a == b, 1 if a > b.
        """
        result = self._collator.compare(a, b)
        # Normalize to -1, 0, 1
        if result < 0:
            return -1
        if result > 0:
            return 1
        return 0

    def key(self, s: str) -> bytes:
        """Return sort key for string.

        The sort key is a byte sequence that, when compared using
        standard byte comparison, yields the same ordering as would
        be obtained using the collator's compare method.

        Args:
            s: String to create sort key for.

        Returns:
            Sort key as bytes.
        """
        # getSortKey returns bytes directly in PyICU
        return self._collator.getSortKey(s)

    def __call__(self, s: str) -> bytes:
        """Make collator callable as a key function.

        This allows using the collator directly with sorted():
        sorted(strings, key=collator)

        Args:
            s: String to create sort key for.

        Returns:
            Sort key as bytes.
        """
        return self.key(s)

    def sort(self, strings: Iterable[str]) -> list[str]:
        """Return sorted copy of strings.

        Args:
            strings: Iterable of strings to sort.

        Returns:
            New list with strings sorted according to collation rules.
        """
        return sorted(strings, key=self.key)

    def is_equal(self, a: str, b: str) -> bool:
        """Check if two strings are equal according to collation rules.

        Args:
            a: First string.
            b: Second string.

        Returns:
            True if strings are considered equal.
        """
        return self.compare(a, b) == 0

    def is_less(self, a: str, b: str) -> bool:
        """Check if first string is less than second.

        Args:
            a: First string.
            b: Second string.

        Returns:
            True if a < b according to collation rules.
        """
        return self.compare(a, b) < 0

    def is_greater(self, a: str, b: str) -> bool:
        """Check if first string is greater than second.

        Args:
            a: First string.
            b: Second string.

        Returns:
            True if a > b according to collation rules.
        """
        return self.compare(a, b) > 0

    @property
    def locale(self) -> Locale:
        """The locale this collator is configured for."""
        return self._locale

    @property
    def strength(self) -> str:
        """The configured strength level."""
        return self._strength

    @property
    def numeric(self) -> bool:
        """Whether numeric sorting is enabled."""
        return self._numeric

    def __repr__(self) -> str:
        """Return a representation of the collator."""
        return f"Collator(locale='{self._locale.language_tag}', strength='{self._strength}', numeric={self._numeric})"


# Convenience functions


def sort(strings: Iterable[str], locale: str | Locale, **options) -> list[str]:
    """Sort strings according to locale rules.

    This is a convenience function that creates a temporary collator
    for one-off sorting operations.

    Args:
        strings: Iterable of strings to sort.
        locale: Locale identifier or Locale object.
        **options: Additional options passed to Collator constructor.

    Returns:
        New list with strings sorted according to locale rules.

    Example:
        >>> sort(['café', 'cote', 'côte', 'coté'], 'fr-FR')
        ['café', 'cote', 'coté', 'côte']
    """
    collator = Collator(locale, **options)
    return collator.sort(strings)


def compare(a: str, b: str, locale: str | Locale, **options) -> int:
    """Compare two strings according to locale rules.

    This is a convenience function that creates a temporary collator
    for one-off comparisons.

    Args:
        a: First string.
        b: Second string.
        locale: Locale identifier or Locale object.
        **options: Additional options passed to Collator constructor.

    Returns:
        -1 if a < b, 0 if a == b, 1 if a > b.
    """
    collator = Collator(locale, **options)
    return collator.compare(a, b)
</file>

<file path="src/uicu/exceptions.py">
#!/usr/bin/env python
# this_file: src/uicu/exceptions.py
"""Exception hierarchy for the uicu package."""


class UICUError(Exception):
    """Base exception for all uicu errors."""

    pass


class ConfigurationError(UICUError):
    """Invalid configuration (locale, pattern, etc.)."""

    pass


class OperationError(UICUError):
    """Error during runtime operations (formatting, collation, etc.)."""

    pass
</file>

<file path="src/uicu/locale.py">
#!/usr/bin/env python
# this_file: src/uicu/locale.py
"""Locale management and factory for locale-aware services.

This module provides the central Locale class that represents a specific locale
and serves as a factory for creating locale-aware services like collators,
formatters, and segmenters.
"""

from __future__ import annotations

from typing import TYPE_CHECKING

import icu

from uicu.exceptions import ConfigurationError

# Type hints for forward references
if TYPE_CHECKING:
    from uicu.collate import Collator
    from uicu.format import DateTimeFormatter
    from uicu.segment import (
        GraphemeSegmenter,
        SentenceSegmenter,
        WordSegmenter,
    )


class Locale:
    """Represents a specific locale and creates locale-aware services.

    This class wraps ICU's Locale functionality and provides factory methods
    for creating various locale-aware services.
    """

    def __init__(self, language_tag: str):
        """Initialize a locale.

        Args:
            language_tag: BCP 47 language tag (e.g. 'en-US', 'fr-FR')

        Raises:
            ConfigurationError: If locale creation fails
        """
        try:
            self._icu_locale = icu.Locale(language_tag)
        except Exception as e:
            msg = f"Failed to create locale for '{language_tag}': {e}"
            raise ConfigurationError(msg) from e

        self._language_tag = language_tag

        # Cache commonly accessed properties
        self._language = self._icu_locale.getLanguage()
        self._script = self._icu_locale.getScript()
        self._country = self._icu_locale.getCountry()  # ICU uses "country" for region
        self._variant = self._icu_locale.getVariant()

    @property
    def display_name(self) -> str:
        """Full human-readable name in default locale.

        Returns:
            Display name like 'English (United Kingdom)'.
        """
        # Get display name in the default locale
        return self._icu_locale.getDisplayName()

    def get_display_name_in_locale(self, display_locale: Locale | None = None) -> str:
        """Get display name in a specific locale.

        Args:
            display_locale: Locale to use for display. If None, uses default.

        Returns:
            Display name in the specified locale.
        """
        if display_locale is None:
            return self.display_name
        return self._icu_locale.getDisplayName(display_locale._icu_locale)

    @property
    def language(self) -> str:
        """ISO 639 language code.

        Returns:
            Two or three letter language code (e.g., 'en', 'zh').
        """
        return self._language

    @property
    def script(self) -> str:
        """ISO 15924 script code if specified.

        Returns:
            Four-letter script code (e.g., 'Latn', 'Hant') or empty string.
        """
        return self._script

    @property
    def region(self) -> str:
        """ISO 3166 region code.

        Returns:
            Two-letter region code (e.g., 'GB', 'US') or empty string.
        """
        return self._country

    @property
    def variant(self) -> str:
        """Variant code or empty string."""
        return self._variant

    @property
    def base_name(self) -> str:
        """The canonical locale identifier (e.g., 'en_GB', 'zh_Hant_TW')."""
        return self._icu_locale.getBaseName()

    @property
    def language_tag(self) -> str:
        """BCP 47 language tag.

        Returns:
            Language tag with hyphens (e.g., 'en-GB', 'zh-Hant-TW').
        """
        return self.base_name.replace("_", "-")

    # Factory methods for locale-aware services

    def get_collator(self, strength: str = "tertiary", *, numeric: bool = False, **kwargs) -> Collator:
        """Create a collator for this locale.

        Args:
            strength: The collation strength level. One of:
                - "primary" - Base characters only
                - "secondary" - Base + accents
                - "tertiary" - Base + accents + case (default)
                - "quaternary" - Base + accents + case + punctuation
            numeric: Whether to use numeric collation
            **kwargs: Additional collation options

        Returns:
            A collator for this locale
        """
        from uicu.collate import Collator

        return Collator(self, strength=strength, numeric=numeric, **kwargs)

    def get_datetime_formatter(
        self,
        date_style: str = "medium",
        time_style: str = "medium",
        **kwargs,
    ) -> DateTimeFormatter:
        """Create a date/time formatter for this locale.

        Args:
            date_style: Date format style ('none', 'short', 'medium', 'long', 'full')
            time_style: Time format style ('none', 'short', 'medium', 'long', 'full')
            **kwargs: Additional formatter options

        Returns:
            A date/time formatter for this locale
        """
        from uicu.format import DateTimeFormatter

        return DateTimeFormatter(
            self,
            date_style=date_style,
            time_style=time_style,
            **kwargs,
        )

    def get_date_formatter(
        self,
        style: str = "medium",
        **kwargs,
    ) -> DateTimeFormatter:
        """Create a date-only formatter for this locale.

        Args:
            style: Date format style ('short', 'medium', 'long', 'full')
            **kwargs: Additional formatter options

        Returns:
            A date-only formatter for this locale
        """
        return self.get_datetime_formatter(date_style=style, time_style="none", **kwargs)

    def get_time_formatter(
        self,
        style: str = "medium",
        **kwargs,
    ) -> DateTimeFormatter:
        """Create a time-only formatter for this locale.

        Args:
            style: Time format style ('short', 'medium', 'long', 'full')
            **kwargs: Additional formatter options

        Returns:
            A time-only formatter for this locale
        """
        return self.get_datetime_formatter(date_style="none", time_style=style, **kwargs)

    #
    # def get_number_formatter(
    #     self,
    #     style: str = "decimal",
    #     **kwargs,
    # ) -> "NumberFormatter":
    #     """Create a number formatter for this locale.
    #
    #     Args:
    #         style: Format style - 'decimal', 'percent', 'currency', 'scientific'.
    #         **kwargs: Additional options passed to NumberFormatter.
    #
    #     Returns:
    #         A configured NumberFormatter instance.
    #     """
    #     from uicu.format import NumberFormatter
    #
    #     return NumberFormatter(self, style=style, **kwargs)
    #
    # def get_list_formatter(
    #     self,
    #     style: str = "standard",
    #     list_type: str = "and",
    #     **kwargs,
    # ) -> "ListFormatter":
    #     """Create a list formatter for this locale.
    #
    #     Args:
    #         style: Format style - 'standard', 'narrow', etc.
    #         list_type: List type - 'and', 'or', 'units'.
    #         **kwargs: Additional options passed to ListFormatter.
    #
    #     Returns:
    #         A configured ListFormatter instance.
    #     """
    #     from uicu.format import ListFormatter
    #
    #     return ListFormatter(
    #         self,
    #         style=style,
    #         list_type=list_type,
    #         **kwargs,
    #     )

    def get_word_segmenter(self) -> WordSegmenter:
        """Create a word segmenter for this locale.

        Returns:
            A new WordSegmenter instance for this locale
        """
        # Import here to avoid circular imports
        from uicu.segment import WordSegmenter

        return WordSegmenter(self)

    def get_grapheme_segmenter(self) -> GraphemeSegmenter:
        """Create a grapheme segmenter for this locale.

        Returns:
            A new GraphemeSegmenter instance for this locale
        """
        # Import here to avoid circular imports
        from uicu.segment import GraphemeSegmenter

        return GraphemeSegmenter(self)

    def get_sentence_segmenter(self) -> SentenceSegmenter:
        """Create a sentence segmenter for this locale.

        Returns:
            A new SentenceSegmenter instance for this locale
        """
        # Import here to avoid circular imports
        from uicu.segment import SentenceSegmenter

        return SentenceSegmenter(self)

    def __str__(self) -> str:
        """Return the locale identifier."""
        return self.base_name

    def __repr__(self) -> str:
        """Return a detailed representation."""
        return f"Locale('{self.language_tag}')"

    def __eq__(self, other) -> bool:
        """Compare locales."""
        if isinstance(other, Locale):
            return self.base_name == other.base_name
        return NotImplemented

    def __hash__(self) -> int:
        """Hash based on base name."""
        return hash(self.base_name)


# Convenience functions


def get_available_locales() -> list[str]:
    """Get list of available locale identifiers.

    Returns:
        List of locale identifiers supported by ICU.
    """
    # Get all available locales from ICU
    locales = []
    for locale_id in icu.Locale.getAvailableLocales():
        if locale_id:  # Skip empty locale
            # getAvailableLocales returns strings
            locales.append(locale_id.replace("_", "-"))
    return sorted(locales)


def get_default_locale() -> Locale:
    """Get the system default locale.

    Returns:
        The default Locale instance.
    """
    default_icu = icu.Locale.getDefault()
    identifier = default_icu.getBaseName()
    return Locale(identifier)
</file>

<file path="src/uicu/segment.py">
#!/usr/bin/env python
# this_file: src/uicu/segment.py
# pyright: ignore
"""Text segmentation functionality."""

from collections.abc import Iterator

import icu

# from uicu.exceptions import ConfigurationError  # Currently unused
from uicu.locale import Locale


def _create_break_iterator(
    kind: str,
    locale: Locale | None = None,
) -> icu.BreakIterator:
    """Create a break iterator of the specified kind.

    Args:
        kind: Type of iterator - 'character', 'word', 'sentence', or 'line'.
        locale: Optional locale for locale-specific rules.

    Returns:
        Configured BreakIterator instance.

    Raises:
        OperationError: If creation fails.
    """
    # Get the ICU locale
    icu_locale = icu.Locale.getDefault() if locale is None else locale._icu_locale

    # Create the appropriate iterator
    if kind == "character":
        return icu.BreakIterator.createCharacterInstance(icu_locale)
    if kind == "word":
        return icu.BreakIterator.createWordInstance(icu_locale)
    if kind == "sentence":
        return icu.BreakIterator.createSentenceInstance(icu_locale)
    if kind == "line":
        return icu.BreakIterator.createLineInstance(icu_locale)
    msg = f"Unknown iterator kind: {kind}"
    raise ValueError(msg)


def _iterate_breaks(
    text: str,
    break_iterator: icu.BreakIterator,
) -> Iterator[str]:
    """Iterate over text segments using a break iterator.

    This handles the UTF-16 index conversion issue by using ICU's
    UnicodeString internally.

    Args:
        text: Text to segment.
        break_iterator: Configured break iterator.

    Yields:
        Text segments as strings.
    """
    if not text:
        return

    # Convert to ICU UnicodeString to handle UTF-16 indices correctly
    utext = icu.UnicodeString(text)
    break_iterator.setText(utext)

    # Get break positions
    start = 0
    for end in break_iterator:
        if end == icu.BreakIterator.DONE:
            break
        # Extract segment using UnicodeString slicing
        segment = utext[start:end]
        # Convert to Python string
        yield str(segment)
        start = end


# Functional API


def graphemes(text: str, locale: str | Locale | None = None) -> Iterator[str]:
    """Iterate over grapheme clusters (user-perceived characters).

    A grapheme cluster is what users think of as a single character,
    which may be composed of multiple Unicode code points.

    Args:
        text: Text to segment into graphemes.
        locale: Optional locale for locale-specific rules.
                Can be a string identifier or Locale object.

    Yields:
        Grapheme clusters as strings.

    Example:
        >>> list(graphemes('🇨🇦'))
        ['🇨🇦']  # Single flag emoji
        >>> list(graphemes('e\\u0301'))
        ['é']  # Combined character
        >>> list(graphemes('नमस्ते'))  # Devanagari
        ['न', 'म', 'स्', 'ते']  # Note combined characters
    """
    # Convert string locale to Locale object if needed
    if isinstance(locale, str):
        locale = Locale(locale)

    # Create character (grapheme) break iterator
    break_iterator = _create_break_iterator("character", locale)

    # Iterate over grapheme clusters
    yield from _iterate_breaks(text, break_iterator)


def words(
    text: str,
    locale: str | Locale | None = None,
    *,
    skip_whitespace: bool = True,
    skip_punctuation: bool = True,
) -> Iterator[str]:
    """Iterate over words according to locale rules.

    Word boundaries are determined by Unicode rules and may be
    customized by locale. Note that by default, whitespace and
    punctuation are skipped.

    Args:
        text: Text to segment into words.
        locale: Optional locale for locale-specific rules.
        skip_whitespace: If True, skip whitespace-only tokens.
        skip_punctuation: If True, skip punctuation-only tokens.

    Yields:
        Word tokens as strings.

    Example:
        >>> list(words("Hello, world!"))
        ['Hello', 'world']
        >>> list(words("你好世界", locale='zh-CN'))
        ['你好', '世界']  # Chinese word segmentation
    """
    # Convert string locale to Locale object if needed
    if isinstance(locale, str):
        locale = Locale(locale)

    # Create word break iterator
    break_iterator = _create_break_iterator("word", locale)

    # Iterate over words
    for word in _iterate_breaks(text, break_iterator):
        if skip_whitespace and word.isspace():
            continue
        if skip_punctuation and all(not c.isalnum() for c in word):
            continue
        yield word


def sentences(text: str, locale: str | Locale | None = None) -> Iterator[str]:
    """Iterate over sentences according to locale rules.

    Sentence boundaries are determined by Unicode rules and may be
    customized by locale. The sentences include their terminating
    punctuation.

    Args:
        text: Text to segment into sentences.
        locale: Optional locale for locale-specific rules.

    Yields:
        Sentences as strings.

    Example:
        >>> list(sentences("Hello. How are you? I'm fine!"))
        ['Hello. ', 'How are you? ', "I'm fine!"]
    """
    # Convert string locale to Locale object if needed
    if isinstance(locale, str):
        locale = Locale(locale)

    # Create sentence break iterator
    break_iterator = _create_break_iterator("sentence", locale)

    # Iterate over sentences
    yield from _iterate_breaks(text, break_iterator)


def lines(text: str, locale: str | Locale | None = None) -> Iterator[str]:
    """Iterate over line break opportunities.

    This identifies positions where lines can be broken for text
    wrapping according to Unicode rules.

    Args:
        text: Text to find line breaks in.
        locale: Optional locale for locale-specific rules.

    Yields:
        Text segments between line break opportunities.
    """
    # Convert string locale to Locale object if needed
    if isinstance(locale, str):
        locale = Locale(locale)

    # Create line break iterator
    break_iterator = _create_break_iterator("line", locale)

    # Iterate over line segments
    yield from _iterate_breaks(text, break_iterator)


def line_breaks(text: str, locale: str | Locale | None = None) -> Iterator[int]:
    """Find potential line break positions in text.

    This function returns the character positions (indices) where
    line breaks are allowed according to Unicode line breaking rules.

    Args:
        text: Text to analyze for line breaks.
        locale: Optional locale for locale-specific rules.

    Yields:
        Character positions where line breaks are allowed.
    """
    # Convert string locale to Locale object if needed
    if isinstance(locale, str):
        locale = Locale(locale)

    # Create line break iterator
    break_iterator = _create_break_iterator("line", locale)

    # Set text
    uset = icu.UnicodeString(text)
    break_iterator.setText(uset)

    # Get all boundaries
    position = break_iterator.first()
    while position != icu.BreakIterator.DONE:
        # Convert from UTF-16 to Python string position
        utf16_pos = position
        if utf16_pos > 0 and utf16_pos < len(uset):
            # Calculate Python string position
            python_pos = len(str(uset[:utf16_pos]))
            yield python_pos
        position = break_iterator.nextBoundary()


# OOP Interface


class BaseSegmenter:
    """Base class for text segmenters."""

    def __init__(self, locale: str | Locale | None = None):
        """Initialize segmenter with optional locale.

        Args:
            locale: Optional locale for locale-specific rules.
        """
        if isinstance(locale, str):
            locale = Locale(locale)
        self._locale = locale
        self._break_iterator = self._create_break_iterator()

    def _create_break_iterator(self) -> icu.BreakIterator:
        """Create the break iterator. Subclasses must implement."""
        raise NotImplementedError

    def segment(self, text: str) -> Iterator[str]:
        """Segment text into parts.

        Args:
            text: Text to segment.

        Yields:
            Text segments.
        """
        yield from _iterate_breaks(text, self._break_iterator)

    def segment_list(self, text: str) -> list[str]:
        """Segment text into a list.

        Args:
            text: Text to segment.

        Returns:
            List of text segments.
        """
        return list(self.segment(text))

    def boundaries(self, text: str) -> set[int]:
        """Get boundary positions in text.

        Args:
            text: Text to analyze.

        Returns:
            Set of boundary positions (character indices).
        """
        # Set text
        uset = icu.UnicodeString(text)
        self._break_iterator.setText(uset)

        # Collect all boundaries
        boundaries = set()
        position = self._break_iterator.first()
        while position != icu.BreakIterator.DONE:
            # Convert from UTF-16 to Python string position
            if position == 0:
                boundaries.add(0)
            elif position >= len(uset):
                boundaries.add(len(text))
            else:
                # Calculate Python string position
                python_pos = len(str(uset[:position]))
                boundaries.add(python_pos)
            position = self._break_iterator.nextBoundary()

        return boundaries


class GraphemeSegmenter(BaseSegmenter):
    """Reusable grapheme cluster segmenter."""

    def _create_break_iterator(self) -> icu.BreakIterator:
        """Create character break iterator."""
        return _create_break_iterator("character", self._locale)

    def __repr__(self) -> str:
        """Return representation."""
        locale_str = self._locale.language_tag if self._locale else "default"
        return f"GraphemeSegmenter(locale='{locale_str}')"


class WordSegmenter(BaseSegmenter):
    """Reusable word segmenter."""

    def __init__(
        self,
        locale: str | Locale | None = None,
        *,
        skip_whitespace: bool = False,
    ):
        """Initialize word segmenter.

        Args:
            locale: Optional locale for locale-specific rules.
            skip_whitespace: If True, skip whitespace tokens.
        """
        super().__init__(locale)
        self._skip_whitespace = skip_whitespace

    def _create_break_iterator(self) -> icu.BreakIterator:
        """Create word break iterator."""
        return _create_break_iterator("word", self._locale)

    def segment(self, text: str) -> Iterator[str]:
        """Segment text into words.

        Args:
            text: Text to segment.

        Yields:
            Word tokens.
        """
        for word in super().segment(text):
            if self._skip_whitespace and word.isspace():
                continue
            yield word

    def __repr__(self) -> str:
        """Return representation."""
        locale_str = self._locale.language_tag if self._locale else "default"
        return f"WordSegmenter(locale='{locale_str}', skip_whitespace={self._skip_whitespace})"


class SentenceSegmenter(BaseSegmenter):
    """Reusable sentence segmenter."""

    def _create_break_iterator(self) -> icu.BreakIterator:
        """Create sentence break iterator."""
        return _create_break_iterator("sentence", self._locale)

    def __repr__(self) -> str:
        """Return representation."""
        locale_str = self._locale.language_tag if self._locale else "default"
        return f"SentenceSegmenter(locale='{locale_str}')"


class LineSegmenter(BaseSegmenter):
    """Reusable line break segmenter."""

    def _create_break_iterator(self) -> icu.BreakIterator:
        """Create line break iterator."""
        return _create_break_iterator("line", self._locale)

    def __repr__(self) -> str:
        """Return representation."""
        locale_str = self._locale.language_tag if self._locale else "default"
        return f"LineSegmenter(locale='{locale_str}')"
</file>

<file path="src/uicu/translit.py">
#!/usr/bin/env python
# this_file: src/uicu/translit.py
"""Script conversion and text transforms.

This module provides Pythonic interfaces for ICU's transliteration functionality,
enabling script conversion and various text transformations.
"""

import icu

from uicu.exceptions import ConfigurationError


class Transliterator:
    """Reusable transliterator for better performance.

    This class wraps ICU's Transliterator to provide script conversion
    and text transformation capabilities.
    """

    def __init__(self, transform_id: str, direction: str = "forward"):
        """Create transliterator.

        Args:
            transform_id: ICU transform ID (e.g., 'Greek-Latin', 'Any-NFD').
            direction: 'forward' or 'reverse'.

        Raises:
            ConfigurationError: If transform ID is invalid or creation fails.
        """
        # Map direction string to ICU constant
        if direction == "forward":
            icu_direction = icu.UTransDirection.FORWARD
        elif direction == "reverse":
            icu_direction = icu.UTransDirection.REVERSE
        else:
            msg = f"Invalid direction '{direction}'. Must be 'forward' or 'reverse'."
            raise ConfigurationError(msg)

        # Create ICU transliterator - let ICU errors propagate
        self._transliterator = icu.Transliterator.createInstance(transform_id, icu_direction)

        # Store configuration
        self._transform_id = transform_id
        self._direction = direction

    def transliterate(self, text: str, filter_fn=None) -> str:
        """Apply transliteration to text.

        Args:
            text: Input text to transform.
            filter_fn: Optional function to filter which characters to transliterate.
                      Should take a single character and return True to transliterate.

        Returns:
            Transformed text.
        """
        if filter_fn is None:
            # ICU transliterate modifies the string in-place if using UnicodeString
            # But with Python strings, it returns a new string
            return self._transliterator.transliterate(text)
        # Apply transliteration selectively
        result = []
        for char in text:
            if filter_fn(char):
                result.append(self._transliterator.transliterate(char))
            else:
                result.append(char)
        return "".join(result)

    def __call__(self, text: str) -> str:
        """Make transliterator callable.

        Args:
            text: Input text to transform.

        Returns:
            Transformed text.
        """
        return self.transliterate(text)

    def inverse(self) -> "Transliterator":
        """Return inverse transliterator.

        Returns:
            New Transliterator instance for reverse transformation.

        Raises:
            ConfigurationError: If inverse is not available.
        """
        # Create inverse transliterator
        inverse_trans = self._transliterator.createInverse()

        # Wrap in new Transliterator instance
        # We need to create a new instance that wraps the inverse
        new_instance = object.__new__(Transliterator)
        new_instance._transliterator = inverse_trans
        new_instance._transform_id = f"{self._transform_id}_inverse"
        new_instance._direction = "reverse" if self._direction == "forward" else "forward"

        return new_instance

    @classmethod
    def from_rules(cls, name: str, rules: str, direction: str = "forward") -> "Transliterator":
        """Create transliterator from custom rules.

        Args:
            name: Name for the custom transliterator.
            rules: Transliteration rules in ICU syntax.
            direction: 'forward' or 'reverse'.

        Returns:
            New Transliterator instance.

        Raises:
            ConfigurationError: If rules are invalid.
        """
        # Map direction string to ICU constant
        if direction == "forward":
            icu_direction = icu.UTransDirection.FORWARD
        elif direction == "reverse":
            icu_direction = icu.UTransDirection.REVERSE
        else:
            msg = f"Invalid direction '{direction}'. Must be 'forward' or 'reverse'."
            raise ConfigurationError(msg)

        # Create transliterator from rules
        icu_trans = icu.Transliterator.createFromRules(name, rules, icu_direction)

        # Wrap in new Transliterator instance
        new_instance = object.__new__(cls)
        new_instance._transliterator = icu_trans
        new_instance._transform_id = name
        new_instance._direction = direction

        return new_instance

    @property
    def transform_id(self) -> str:
        """The transform ID of this transliterator."""
        return self._transform_id

    @property
    def id(self) -> str:
        """Alias for transform_id for compatibility."""
        return self._transform_id

    @property
    def direction(self) -> str:
        """The direction of this transliterator."""
        return self._direction

    @property
    def display_name(self) -> str:
        """Human-readable name of the transliterator."""
        try:
            # PyICU transliterators have getDisplayName method
            return self._transliterator.getDisplayName(icu.Locale.getDefault())
        except AttributeError:
            # Fallback to transform ID
            return self._transform_id

    @property
    def source_set(self) -> set[str] | None:
        """The set of characters that this transliterator will transform."""
        try:
            # PyICU transliterators may have getSourceSet method
            uset = self._transliterator.getSourceSet()
            if uset:
                # Convert UnicodeSet to Python set
                return {uset.charAt(i) for i in range(uset.size())}
        except (AttributeError, Exception):
            pass
        return None

    @property
    def target_set(self) -> set[str] | None:
        """The set of characters that this transliterator can produce."""
        try:
            # PyICU transliterators may have getTargetSet method
            uset = self._transliterator.getTargetSet()
            if uset:
                # Convert UnicodeSet to Python set
                return {uset.charAt(i) for i in range(uset.size())}
        except (AttributeError, Exception):
            pass
        return None

    def has_inverse(self) -> bool:
        """Check if this transliterator has an inverse transform."""
        try:
            # Try to create inverse - if it succeeds, inverse exists
            self._transliterator.createInverse()
            return True
        except Exception:
            return False

    def get_inverse(self) -> "Transliterator":
        """Get the inverse transliterator.

        This is an alias for the inverse() method.
        """
        return self.inverse()

    def __repr__(self) -> str:
        """Return representation."""
        return f"Transliterator('{self._transform_id}', direction='{self._direction}')"


# Convenience functions


def transliterate(text: str, transform_id: str, direction: str = "forward", filter_fn=None) -> str:
    """Apply transliteration transform.

    This is a convenience function that creates a temporary transliterator
    for one-off transformations.

    Args:
        text: Input text to transform.
        transform_id: ICU transform ID (e.g., 'Greek-Latin', 'Any-NFD').
        direction: 'forward' or 'reverse'.
        filter_fn: Optional function to filter which characters to transliterate.

    Returns:
        Transformed text.

    Example:
        >>> transliterate('Ελληνικά', 'Greek-Latin')
        'Ellēniká'
        >>> transliterate('北京', 'Han-Latin')
        'běi jīng'
    """
    trans = Transliterator(transform_id, direction)
    return trans.transliterate(text, filter_fn=filter_fn)


def get_available_transforms() -> list[str]:
    """Return list of available transform IDs.

    Returns:
        List of available ICU transform identifiers.
    """
    # Get available IDs from ICU
    # ICU returns an Enumeration, convert to list
    ids = []
    enumeration = icu.Transliterator.getAvailableIDs()

    # Iterate through enumeration
    while True:
        try:
            # Get next ID
            transform_id = enumeration.next()
            if transform_id is None:
                break
            ids.append(str(transform_id))
        except StopIteration:
            break

    return sorted(ids)


def list_transform_aliases(transform_id: str) -> list[str]:
    """Get aliases for a transform ID.

    Args:
        transform_id: Transform ID to get aliases for.

    Returns:
        List of alias IDs that map to the same transform.
    """
    try:
        # ICU doesn't directly expose aliases, but we can check
        # which IDs create equivalent transliterators
        aliases = []
        base_trans = icu.Transliterator.createInstance(transform_id)

        for test_id in get_available_transforms():
            if test_id != transform_id:
                try:
                    test_trans = icu.Transliterator.createInstance(test_id)
                    # Compare by ID (not perfect but reasonable)
                    if test_trans.getID() == base_trans.getID():
                        aliases.append(test_id)
                except Exception:
                    pass

        return aliases
    except Exception as e:
        msg = f"Failed to get aliases for '{transform_id}': {e}"
        raise ConfigurationError(msg) from e


def find_transforms(keyword: str) -> list[str]:
    """Find transform IDs containing a keyword.

    Useful for discovering available transforms for a script or language.

    Args:
        keyword: Search term (case-insensitive).

    Returns:
        List of matching transform IDs.

    Example:
        >>> find_transforms('cyrillic')
        ['Any-Cyrillic', 'Cyrillic-Latin', 'Latin-Cyrillic', ...]
        >>> find_transforms('arabic')
        ['Any-Arabic', 'Arabic-Latin', 'Latin-Arabic', ...]
    """
    keyword_lower = keyword.lower()
    transforms = get_available_transforms()
    return [t for t in transforms if keyword_lower in t.lower()]
</file>

<file path="tests/test_collate.py">
#!/usr/bin/env python
# this_file: tests/test_collate.py
"""Tests for collation module."""

import pytest

import uicu


class TestCollator:
    """Test Collator class functionality."""

    def test_collator_creation(self):
        """Test creating Collator objects."""
        # Basic creation
        collator = uicu.Collator("en-US")
        assert collator.locale.language == "en"
        assert collator.strength == "tertiary"
        assert not collator.numeric

        # With options
        collator2 = uicu.Collator("fr-FR", strength="primary", numeric=True)
        assert collator2.strength == "primary"
        assert collator2.numeric

    def test_invalid_collator(self):
        """Test error handling for invalid configuration."""
        # Invalid locale (empty string)
        with pytest.raises(uicu.ConfigurationError):
            uicu.Collator("")

        # Invalid strength
        with pytest.raises(uicu.ConfigurationError):
            uicu.Collator("en-US", strength="invalid")

    def test_compare(self):
        """Test string comparison."""
        collator = uicu.Collator("en-US")

        # Basic comparison
        assert collator.compare("a", "b") == -1
        assert collator.compare("b", "a") == 1
        assert collator.compare("a", "a") == 0

        # Case-sensitive (tertiary strength) - ICU behavior varies by locale
        # Just check that case makes a difference
        assert collator.compare("a", "A") != 0

    def test_strength_levels(self):
        """Test different strength levels."""
        # Primary - ignores case and accents
        primary = uicu.Collator("en-US", strength="primary")
        assert primary.is_equal("a", "A")
        assert primary.is_equal("e", "é")

        # Secondary - considers accents but not case
        secondary = uicu.Collator("en-US", strength="secondary")
        assert secondary.is_equal("a", "A")
        assert not secondary.is_equal("e", "é")

        # Tertiary - considers case differences
        tertiary = uicu.Collator("en-US", strength="tertiary")
        assert not tertiary.is_equal("a", "A")
        assert not tertiary.is_equal("e", "é")

    def test_numeric_sorting(self):
        """Test numeric sorting option."""
        # Without numeric sorting
        regular = uicu.Collator("en-US")
        strings = ["item2", "item10", "item1"]
        sorted_regular = regular.sort(strings)
        assert sorted_regular == ["item1", "item10", "item2"]

        # With numeric sorting
        numeric = uicu.Collator("en-US", numeric=True)
        sorted_numeric = numeric.sort(strings)
        assert sorted_numeric == ["item1", "item2", "item10"]

    def test_sort_key(self):
        """Test sort key generation."""
        collator = uicu.Collator("en-US")

        # Sort keys should maintain same ordering
        key_a = collator.key("apple")
        key_b = collator.key("banana")
        assert key_a < key_b

        # Keys should be bytes
        assert isinstance(key_a, bytes)
        assert isinstance(key_b, bytes)

    def test_callable_interface(self):
        """Test using collator as key function."""
        collator = uicu.Collator("en-US")

        # Use as key function with sorted()
        words = ["banana", "apple", "cherry"]
        sorted_words = sorted(words, key=collator)
        assert sorted_words == ["apple", "banana", "cherry"]

    def test_locale_specific_sorting(self):
        """Test locale-specific sorting rules."""
        # German sorts ä after a
        german = uicu.Collator("de-DE")
        words = ["Müller", "Mueller", "Mahler"]
        sorted_de = german.sort(words)

        # Swedish sorts ä after z
        swedish = uicu.Collator("sv-SE")
        words_sv = ["ark", "ärm", "ask"]
        sorted_sv = swedish.sort(words_sv)

        # Different locales produce different orderings
        assert sorted_de != sorted_sv or len(sorted_de) != len(sorted_sv)

    def test_case_first_option(self):
        """Test case_first option."""
        # Upper case first
        upper_first = uicu.Collator("en-US", case_first="upper")
        assert upper_first.compare("A", "a") < 0

        # Lower case first
        lower_first = uicu.Collator("en-US", case_first="lower")
        assert lower_first.compare("a", "A") < 0

    def test_comparison_methods(self):
        """Test convenience comparison methods."""
        collator = uicu.Collator("en-US")

        # is_equal
        assert collator.is_equal("hello", "hello")
        assert not collator.is_equal("hello", "world")

        # is_less
        assert collator.is_less("apple", "banana")
        assert not collator.is_less("banana", "apple")

        # is_greater
        assert collator.is_greater("zebra", "apple")
        assert not collator.is_greater("apple", "zebra")


class TestConvenienceFunctions:
    """Test module-level convenience functions."""

    def test_sort_function(self):
        """Test sort convenience function."""
        words = ["café", "cote", "côte", "coté"]

        # French sorting
        sorted_fr = uicu.sort(words, "fr-FR")
        assert isinstance(sorted_fr, list)
        assert len(sorted_fr) == len(words)

        # With options
        sorted_primary = uicu.sort(words, "fr-FR", strength="primary")
        assert len(sorted_primary) == len(words)

    def test_compare_function(self):
        """Test compare convenience function."""
        # Basic comparison
        assert uicu.compare("a", "b", "en-US") == -1
        assert uicu.compare("b", "a", "en-US") == 1
        assert uicu.compare("a", "a", "en-US") == 0

        # With options
        assert uicu.compare("A", "a", "en-US", strength="primary") == 0
</file>

<file path="tests/test_segment.py">
#!/usr/bin/env python
# this_file: tests/test_segment.py
"""Tests for text segmentation module."""

import contextlib

import uicu


class TestGraphemeSegmentation:
    """Test grapheme cluster segmentation."""

    def test_basic_graphemes(self):
        """Test basic grapheme segmentation."""
        # Simple ASCII
        graphemes = list(uicu.graphemes("hello"))
        assert graphemes == ["h", "e", "l", "l", "o"]

        # With combining marks
        text = "café"  # e with acute accent
        graphemes = list(uicu.graphemes(text))
        assert len(graphemes) == 4  # c, a, f, é

    def test_emoji_graphemes(self):
        """Test emoji and complex grapheme clusters."""
        # Family emoji (multiple codepoints)
        family = "👨‍👩‍👧‍👦"
        graphemes = list(uicu.graphemes(family))
        assert len(graphemes) == 1  # Single grapheme cluster

        # Flag emoji
        flag = "🇺🇸"  # US flag
        graphemes = list(uicu.graphemes(flag))
        assert len(graphemes) == 1

        # Skin tone modifier
        wave = "👋🏽"  # Waving hand with skin tone
        graphemes = list(uicu.graphemes(wave))
        assert len(graphemes) == 1

    def test_grapheme_segmenter_class(self):
        """Test GraphemeSegmenter class."""
        segmenter = uicu.GraphemeSegmenter()

        # Test iteration
        text = "Hello 👋 World"
        graphemes = list(segmenter.segment(text))
        assert "H" in graphemes
        assert "👋" in graphemes

        # Test boundaries
        boundaries = segmenter.boundaries(text)
        assert 0 in boundaries  # Start
        assert len(text) in boundaries  # End


class TestWordSegmentation:
    """Test word boundary segmentation."""

    def test_basic_words(self):
        """Test basic word segmentation."""
        # English
        words = list(uicu.words("Hello, world!"))
        assert "Hello" in words
        assert "world" in words

        # Should not include punctuation as words
        assert "," not in words
        assert "!" not in words

    def test_contractions(self):
        """Test word segmentation with contractions."""
        # English contractions
        words = list(uicu.words("don't can't I'll"))
        # Behavior may vary by locale
        assert len(words) >= 3  # At least the three contracted forms

    def test_locale_specific_words(self):
        """Test locale-specific word segmentation."""
        # Thai (no spaces between words)
        thai_text = "สวัสดีครับ"
        words_th = list(uicu.words(thai_text, locale="th-TH"))
        assert len(words_th) > 0

        # Japanese
        japanese_text = "こんにちは世界"
        words_ja = list(uicu.words(japanese_text, locale="ja-JP"))
        assert len(words_ja) > 0

    def test_word_segmenter_class(self):
        """Test WordSegmenter class."""
        # Default locale with skip_whitespace
        segmenter = uicu.WordSegmenter(skip_whitespace=True)
        words = list(segmenter.segment("Hello world"))
        assert len(words) == 2
        assert words == ["Hello", "world"]

        # Specific locale
        segmenter_fr = uicu.WordSegmenter(locale="fr-FR", skip_whitespace=True)
        words_fr = list(segmenter_fr.segment("Bonjour le monde"))
        assert "Bonjour" in words_fr
        assert "monde" in words_fr

    def test_word_boundaries(self):
        """Test word boundary detection."""
        segmenter = uicu.WordSegmenter()
        text = "Hello world"
        boundaries = segmenter.boundaries(text)

        assert 0 in boundaries  # Start
        assert 5 in boundaries  # After "Hello"
        assert 6 in boundaries  # Start of "world"
        assert len(text) in boundaries  # End


class TestSentenceSegmentation:
    """Test sentence boundary segmentation."""

    def test_basic_sentences(self):
        """Test basic sentence segmentation."""
        text = "Hello world. How are you? I'm fine!"
        sentences = list(uicu.sentences(text))

        assert len(sentences) == 3
        assert "Hello world." in sentences[0]
        assert "How are you?" in sentences[1]
        assert "I'm fine!" in sentences[2]

    def test_abbreviations(self):
        """Test sentence segmentation with abbreviations."""
        text = "Dr. Smith went to Washington D.C. yesterday. He had a meeting."
        sentences = list(uicu.sentences(text))

        # ICU's sentence segmentation behavior can vary
        # Just check that we get reasonable sentences
        assert len(sentences) >= 2
        # Check the last sentence is recognized
        assert "He had a meeting." in sentences[-1]

    def test_multiple_punctuation(self):
        """Test sentences with multiple punctuation marks."""
        text = "Really?! That's amazing... Let me think."
        sentences = list(uicu.sentences(text))

        assert len(sentences) == 3
        assert "Really?!" in sentences[0]
        assert "amazing..." in sentences[1]

    def test_sentence_segmenter_class(self):
        """Test SentenceSegmenter class."""
        segmenter = uicu.SentenceSegmenter()

        text = "First sentence. Second sentence."
        sentences = list(segmenter.segment(text))
        assert len(sentences) == 2

        # Test boundaries
        boundaries = segmenter.boundaries(text)
        assert 0 in boundaries
        assert len(text) in boundaries


class TestLineBreaking:
    """Test line break segmentation."""

    def test_line_breaks(self):
        """Test finding line break opportunities."""
        text = "This is a very long line that might need to be broken."
        breaks = list(uicu.line_breaks(text))

        # Should find breaks at word boundaries
        assert len(breaks) > 5  # Multiple break opportunities

        # Should not break in middle of words
        word_starts = [i for i, c in enumerate(text) if i > 0 and text[i - 1] == " "]
        for start in word_starts:
            assert start in breaks or start + 1 in breaks


class TestSegmentationErrors:
    """Test error handling in segmentation."""

    def test_empty_text(self):
        """Test segmentation of empty text."""
        assert list(uicu.graphemes("")) == []
        assert list(uicu.words("")) == []
        assert list(uicu.sentences("")) == []

    def test_invalid_locale(self):
        """Test invalid locale handling."""
        # Should fall back to default or raise appropriate error
        with contextlib.suppress(uicu.OperationError):
            list(uicu.words("hello", locale="invalid_locale"))
</file>

<file path="tests/test_translit.py">
#!/usr/bin/env python
# this_file: tests/test_translit.py
"""Tests for transliteration module."""

import pytest

import uicu


class TestTransliterator:
    """Test Transliterator class functionality."""

    def test_basic_transliteration(self):
        """Test basic transliteration."""
        # Latin to ASCII
        trans = uicu.Transliterator("Latin-ASCII")
        assert trans.transliterate("café") == "cafe"
        assert trans.transliterate("naïve") == "naive"
        assert trans.transliterate("Zürich") == "Zurich"

    def test_script_conversion(self):
        """Test script-to-script conversion."""
        # Greek to Latin
        greek = uicu.Transliterator("Greek-Latin")
        result = greek.transliterate("Αθήνα")
        # Different versions of ICU may produce slightly different results
        assert result in ["Athī́na", "Athína", "Athḗna"]

        # Cyrillic to Latin
        cyrillic = uicu.Transliterator("Cyrillic-Latin")
        result = cyrillic.transliterate("Москва")
        assert "Moskva" in result or "Moskwa" in result

    def test_unicode_normalization(self):
        """Test Unicode normalization transforms."""
        # NFD normalization
        nfd = uicu.Transliterator("NFD")
        composed = "é"  # Single character
        decomposed = nfd.transliterate(composed)
        assert len(decomposed) == 2  # Base + combining

        # NFC normalization
        nfc = uicu.Transliterator("NFC")
        assert len(nfc.transliterate(decomposed)) == 1

    def test_case_transforms(self):
        """Test case transformation."""
        # Upper case
        upper = uicu.Transliterator("Upper")
        assert upper.transliterate("hello world") == "HELLO WORLD"

        # Lower case
        lower = uicu.Transliterator("Lower")
        assert lower.transliterate("HELLO WORLD") == "hello world"

        # Title case
        title = uicu.Transliterator("Title")
        assert title.transliterate("hello world") == "Hello World"

    def test_invalid_transform(self):
        """Test error handling for invalid transforms."""
        with pytest.raises(uicu.ConfigurationError):
            uicu.Transliterator("Invalid-Transform")

    def test_compound_transforms(self):
        """Test compound transform IDs."""
        # Chain multiple transforms
        trans = uicu.Transliterator("Greek-Latin; Latin-ASCII; Lower")
        result = trans.transliterate("Αθήνα")
        assert result == "athina" or result == "athena"

    def test_inverse_transform(self):
        """Test inverse transforms."""
        trans = uicu.Transliterator("Katakana-Latin")

        # Check if inverse is available
        if trans.has_inverse():
            inverse = trans.get_inverse()
            # Round-trip test
            original = "カタカナ"
            latin = trans.transliterate(original)
            back = inverse.transliterate(latin)
            # May not be exactly the same due to ambiguities
            assert len(back) > 0

    def test_filter_function(self):
        """Test filter function for selective transliteration."""
        # Only transliterate uppercase letters
        trans = uicu.Transliterator("Latin-ASCII")

        def uppercase_filter(char):
            return char.isupper()

        result = trans.transliterate("CaFé", filter_fn=uppercase_filter)
        # Only C and F should be checked for transliteration
        # The behavior depends on implementation
        assert "a" in result  # Lowercase unchanged

    def test_transliterator_properties(self):
        """Test transliterator properties."""
        trans = uicu.Transliterator("Latin-ASCII")

        assert trans.id == "Latin-ASCII"
        assert len(trans.display_name) > 0
        assert isinstance(trans.source_set, set | type(None))
        assert isinstance(trans.target_set, set | type(None))


class TestConvenienceFunctions:
    """Test module-level convenience functions."""

    def test_transliterate_function(self):
        """Test transliterate convenience function."""
        # Simple transliteration
        assert uicu.transliterate("café", "Latin-ASCII") == "cafe"

        # With filter
        result = uicu.transliterate("Test123", "Upper", filter_fn=str.isalpha)
        assert "123" in result  # Numbers unchanged

    def test_get_available_transforms(self):
        """Test getting available transform IDs."""
        transforms = uicu.get_available_transforms()

        # Should have many transforms
        assert len(transforms) > 50

        # Common transforms should be available
        assert any("Latin-ASCII" in t for t in transforms)
        assert any("NFD" in t for t in transforms)
        assert any("NFC" in t for t in transforms)
        assert any("Upper" in t for t in transforms)
        assert any("Lower" in t for t in transforms)

    def test_script_detection(self):
        """Test convenience functions for script operations."""
        # Detect primary script
        assert uicu.detect_script("Hello") == "Latn"
        assert uicu.detect_script("Привет") == "Cyrl"
        assert uicu.detect_script("你好") == "Hani"

        # Mixed scripts
        mixed = uicu.detect_script("Hello世界")
        assert mixed in ["Latn", "Hani", "Mixed", None]  # Depends on implementation


class TestSpecialTransforms:
    """Test special-purpose transforms."""

    def test_remove_accents(self):
        """Test accent removal transform."""
        # Using Latin-ASCII for accent removal
        trans = uicu.Transliterator("Latin-ASCII")

        test_cases = [
            ("café", "cafe"),
            ("naïve", "naive"),
            ("résumé", "resume"),
            ("piñata", "pinata"),
            ("Zürich", "Zurich"),
        ]

        for original, expected in test_cases:
            assert trans.transliterate(original) == expected

    def test_any_to_latin(self):
        """Test Any-Latin transform."""
        trans = uicu.Transliterator("Any-Latin")

        # Various scripts to Latin
        assert len(trans.transliterate("你好")) > 0  # Chinese
        assert len(trans.transliterate("こんにちは")) > 0  # Japanese
        assert len(trans.transliterate("Здравствуйте")) > 0  # Russian
        assert len(trans.transliterate("مرحبا")) > 0  # Arabic
</file>

<file path=".cursorrules">
## Project Overview

`uicu` is a Python package that aims to create a pythonic wrapper around PyICU, supplemented by fontTools.unicodedata. The goal is to provide a natural, performant API that exposes rich, well-documented objects integrating with Python's native Unicode handling while adding extensive Unicode functionality.

## Development Commands

### Environment Setup
```bash
# Install and use uv for package management
pip install uv
# Use hatch for development workflow
uv pip install hatch
```

### Common Development Tasks
```bash
# Activate development environment
hatch shell

# Run tests
hatch run test
python -m pytest

# Run tests with coverage
hatch run test-cov

# Run linting
hatch run lint

# Format code
hatch run format

# Run type checking
hatch run type-check

# After Python changes, run the full formatting pipeline:
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

## Code Architecture

### Project Structure
- **src/uicu/**: Main package source (using src-layout)
  - `__init__.py`: Package initialization
  - `__version__.py`: Version management using hatch-vcs
  - `uicu.py`: Main module (currently skeleton)
- **tests/**: Test suite using pytest
- **pyproject.toml**: PEP 621 compliant project configuration

### Key Dependencies to Research
- **PyICU**: The main Unicode library to wrap
- **fontTools.unicodedata**: Supplementary Unicode data with writing system info

## Development Guidelines

### Python-Specific Rules
- Use `uv pip` instead of `pip`
- Always use `python -m` when running modules
- Use type hints in simple form (list, dict, | for unions)
- Add verbose loguru-based logging and debug-log
- For CLI scripts, use fire & rich libraries
- Scripts should start with `#!/usr/bin/env -S uv run -s`

### Code Quality Standards
- PEP 8 compliant (enforced by Ruff)
- Clear, imperative docstrings (PEP 257)
- Use f-strings for formatting
- Structural pattern matching where appropriate
- Maintain `this_file` comments at the top of each source file

### Development Workflow
1. Create/update `PLAN.md` with detailed flat plan using `[ ]` items
2. Identify important TODOs and update `TODO.md`
3. Implement changes incrementally
4. Update `CHANGELOG.md` after each round of changes
5. Update `README.md` to reflect changes
6. Run the formatting pipeline after Python changes

### Current Project Status
- Initial project structure created
- Main objective: Create pythonic wrapper around PyICU
- First task: Research and document APIs from fontTools.unicodedata and PyICU
- Implementation phase not yet started

## Testing Strategy
- pytest with coverage tracking
- Use pytest-xdist for parallel test execution
- pytest-benchmark for performance testing
- Maintain high test coverage for all new functionality

## Key Principles
- Iterate gradually, avoiding major changes
- Preserve existing code/structure unless necessary
- Write explanatory docstrings that explain what and WHY
- Handle failures gracefully with retries and fallbacks
- Focus on minimal viable increments
- Keep code simple and explicit (PEP 20)

# When you write code

- Iterate gradually, avoiding major changes
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Use constants over magic numbers
- Check for existing solutions in the codebase before starting
- Check often the coherence of the code you're writing with the rest of the code.
- Focus on minimal viable increments and ship early
- Write explanatory docstrings/comments that explain what and WHY this does, explain where and how the code is used/referred to elsewhere in the code
- Analyze code line-by-line
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures
- Consistently keep, document, update and consult the holistic overview mental image of the codebase. 

## Keep track of paths

In each source file, maintain the up-to-date `this_file` record that shows the path of the current file relative to project root. Place the `this_file` record near the top of the file, as a comment after the shebangs, or in the YAML Markdown frontmatter.

## When you write Python

- Use `uv pip`, never `pip`
- Use `python -m` when running code
- PEP 8: Use consistent formatting and naming
- Write clear, descriptive names for functions and variables
- PEP 20: Keep code simple and explicit. Prioritize readability over cleverness
- Use type hints in their simplest form (list, dict, | for unions)
- PEP 257: Write clear, imperative docstrings
- Use f-strings. Use structural pattern matching where appropriate
- ALWAYS add "verbose" mode logugu-based logging, & debug-log
- For CLI Python scripts, use fire & rich, and start the script with

```
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

Work in rounds: 

- Create `PLAN.md` as a detailed flat plan with `[ ]` items. 
- Identify the most important TODO items, and create `TODO.md` with `[ ]` items. 
- Implement the changes. 
- Update `PLAN.md` and `TODO.md` as you go. 
- After each round of changes, update `CHANGELOG.md` with the changes.
- Update `README.md` to reflect the changes.

Ask before extending/refactoring existing code in a way that may add complexity or break things.

When you're finished, print "Wait, but" to go back, think & reflect, revise & improvement what you've done (but don't invent functionality freely). Repeat this. But stick to the goal of "minimal viable next version". Lead two experts: "Ideot" for creative, unorthodox ideas, and "Critin" to critique flawed thinking and moderate for balanced discussions. The three of you shall illuminate knowledge with concise, beautiful responses, process methodically for clear answers, collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

## After Python changes run:

```
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

Be creative, diligent, critical, relentless & funny!

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


`uicu` is a specialized Python package that creates a Pythonic wrapper around PyICU with supplementary Unicode functionality from fontTools.unicodedata. The core business logic revolves around providing rich Unicode data manipulation capabilities through well-documented objects.

## Core Business Components

1. Unicode Data Processing (90)
- Custom wrapper around PyICU providing intuitive Unicode manipulation
- Integration with fontTools.unicodedata for writing system information
- Domain-specific data validation and transformation rules
Location: `src/uicu/uicu.py`

2. Supplementary Unicode Features (85)
- Extended Unicode functionality beyond Python's native capabilities
- Writing system detection and classification
- Custom normalization and decomposition rules
Location: `src/uicu/uicu.py`

3. Unicode Validation Framework (75)
- Custom validation rules for Unicode data integrity
- Error handling specific to Unicode processing
- Fallback mechanisms for unsupported characters
Location: `src/uicu/uicu.py`

## Integration Architecture

The package implements a layered approach to Unicode processing:

1. Base Layer: PyICU Integration
- Direct wrapping of PyICU functionality
- Custom error handling and retry logic
Location: `src/uicu/uicu.py`

2. Enhancement Layer: fontTools Integration
- Additional Unicode metadata and writing system support
- Custom data enrichment rules
Location: `src/uicu/uicu.py`

3. Application Layer: Pythonic Interface
- Natural Python API for Unicode operations
- Rich object model with extensive Unicode properties
Location: `src/uicu/uicu.py`

## Development Workflow

The project follows an iterative development approach with:
- Detailed planning in `PLAN.md`
- Task tracking in `TODO.md`
- Change documentation in `CHANGELOG.md`
- Updated documentation in `README.md`

$END$
</file>

<file path="build.sh">
#!/usr/bin/env bash
# this_file: build.sh
# ============================================================================
# UICU BUILD SCRIPT
# ----------------------------------------------------------------------------
# A single entry-point for common development tasks.  Run `./build.sh help` to
# see available commands.
# ----------------------------------------------------------------------------
#  • Installs missing tools (uv, hatch) automatically
#  • Wraps Hatch scripts defined in pyproject.toml for linting, tests, docs …
#  • Provides convenience targets like `all` that run the full CI pipeline
#  • Regenerates llms.txt via repomix
#  • Cleans build artifacts
# ============================================================================

set -euo pipefail
IFS=$'\n\t'

PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$PROJECT_ROOT"

# ------------------------------- helpers ------------------------------------
usage() {
    cat <<'EOF'
Usage: ./build.sh <command>

Commands:
  deps         Install/update dev dependencies (uv, hatch)
  lint         Run Ruff linting and formatting checks
  format       Run Ruff formatter and autofixes
  type-check   Run mypy static type checking
  test         Run pytest test suite
  test-cov     Run tests with coverage report
  build        Build wheel and sdist using Hatch
  docs         Build Sphinx HTML documentation
  clean        Remove build artefacts (build/, dist/, *.egg-info …)
  llms         Regenerate llms.txt using repomix (requires Node + npx)
  all          Run deps → format → lint → type-check → test-cov → build
  help         Show this help message
EOF
}

command_exists() { command -v "$1" >/dev/null 2>&1; }

ensure_uv() {
    if ! command_exists uv; then
        echo "[build.sh] Installing uv…"
        python3 -m pip install --quiet --upgrade pip
        python3 -m pip install --quiet uv
    fi
}

ensure_hatch() {
    if ! command_exists hatch; then
        ensure_uv
        echo "[build.sh] Installing hatch…"
        uv pip install --quiet hatch
    fi
}

run_hatch() {
    ensure_hatch
    hatch "$@"
}

clean() {
    echo "[build.sh] Cleaning build artefacts…"
    rm -rf build dist .pytest_cache .mypy_cache .coverage coverage.xml \
        "$(git ls-files -o -i --exclude-standard | grep -E '\\.egg-info$' || true)"
}

llms() {
    echo "[build.sh] Regenerating llms.txt with repomix…"
    npx repomix -o llms.txt . -i research
}

# ----------------------------- command router -------------------------------
CMD="${1:-help}"
shift || true # remove first arg so remaining $@ are passed to hatch/pytest …

case "$CMD" in
deps)
    ensure_uv && ensure_hatch
    ;;
lint)
    run_hatch run lint "${@:-}"
    ;;
format)
    run_hatch run fmt "${@:-}"
    ;;
type-check)
    run_hatch run type-check "${@:-}"
    ;;
test)
    run_hatch run test "${@:-}"
    ;;
test-cov)
    run_hatch run test-cov "${@:-}"
    ;;
build)
    run_hatch build "${@:-}"
    ;;
docs)
    run_hatch run docs:build "${@:-}"
    ;;
clean)
    clean
    ;;
llms)
    llms
    ;;
all)
    "$0" deps
    "$0" format
    "$0" lint
    "$0" type-check
    "$0" test-cov
    "$0" build
    ;;
help | -h | --help)
    usage
    ;;
*)
    echo "Error: Unknown command '$CMD'\n" >&2
    usage
    exit 1
    ;;
esac
</file>

<file path="CHANGELOG.md">
# Changelog

All notable changes to this project will be documented in this file.

## [Unreleased] - v1.0.0-alpha - 2025-01-25

### Current Status: 80% Complete - MVP Preparation

The uicu project has a solid foundation with excellent architecture and mostly complete core functionality. Based on comprehensive codebase analysis, the main work remaining for v1.0 is tactical rather than architectural.

### ✅ Phase 1 Completed: Critical Fixes

#### Added
- `find_transforms()` function in transliteration module to help discover available transform IDs
- Better error messages for multi-codepoint sequences in Char class

#### Changed
- Improved documentation for Char class to clarify single-codepoint limitation
- Updated module docstring to guide users to grapheme segmentation for multi-codepoint support

#### Fixed
- DateTimeFormatter.parse() - Confirmed as never implemented, no broken functionality to fix
- Transliterator transform IDs - Demo already uses correct IDs (e.g., "Cyrillic-Latin" not "Russian-Latin")
- TODO stub comments - None found in format.py

#### Removed
- 5 deferred issue files (NumberFormatter, ListFormatter, MessageFormatter, Sphinx docs, benchmarks)

### ✅ Phase 2 Completed: Code Cleanup

#### Changed
- Simplified exception handling across all modules - removed excessive try-except wrapping that hid ICU error context
- Streamlined verbose docstrings - removed redundant parameter type descriptions that repeated type hints
- Kept all conditional imports (all were well-justified for optional dependencies and circular import avoidance)
- Updated demo script to use `Locale.display_name` instead of hardcoded locale mappings
- Improved bidirectional text demo to use helper function instead of hardcoded category mappings

#### Fixed
- Let ICU exceptions bubble up with original context for better debugging
- Removed redundant try-except blocks that only reformatted error messages without adding value

### ✅ Phase 3: Critical Formatters Implementation - COMPLETE

#### Added
- **NumberFormatter class** - Complete implementation for locale-aware number formatting
  - Decimal formatting with locale-specific separators (1,234.56 vs 1.234,56)
  - Currency formatting with ISO 4217 currency codes ($1,234.56, ¥1,234, €1.234,56)
  - Percentage formatting with proper symbols (12.34% vs 12,34 %)
  - Scientific notation formatting (1.234567E6)
  - Compact notation formatting (1.2K, 3.4M, 1.2 thousand)
  - Number range formatting (10–20, $10.50–$25.75)
  - Precision control (min/max fraction digits, min integer digits)
  - Rounding mode support (ceiling, floor, half_even, half_up)
  - Grouping separator control (enable/disable thousands separators)
  - Graceful fallback for unsupported ICU features

- **ListFormatter class** - Complete implementation for locale-aware list formatting
  - List type support: 'and', 'or', 'units' (apples, oranges, and bananas vs apples, oranges, or bananas)
  - Style support: 'standard', 'short', 'narrow' for different verbosity levels
  - Proper 2-item vs 3+ item handling with locale-specific rules
  - Locale-specific conjunction handling (English: "and", Spanish: "y", French: "et", German: "und")
  - Graceful fallback with multilingual conjunction support when ICU unavailable
  - Empty list and single-item handling

- **DateTimeFormatter.parse() method** - Complete implementation for bidirectional date/time conversion
  - Full parsing support for all format patterns (styles, custom patterns, skeletons)
  - Lenient vs strict parsing modes for flexible or precise parsing
  - Timezone parsing and conversion support
  - Proper error handling with detailed parse position information
  - Round-trip formatting/parsing capability
  - Convenience parse_strict() method for strict parsing

### 🎯 Next: Phase 3 - MVP Completion

**Production-Ready Features (100% complete) ✅**
- ✅ Character Properties - Complete with fontTools integration
- ✅ Locale Management - Robust BCP 47 support with factory patterns
- ✅ Collation & Sorting - Full-featured with multiple strength levels
- ✅ Text Segmentation - Complete boundary detection for all types
- ✅ Transliteration - Working script conversion with extensive transforms
- ✅ Number Formatting - Complete implementation with all major features
- ✅ List Formatting - Complete implementation with all list types and styles
- ✅ Date/Time Formatting - Complete with both formatting and parsing

**Remaining for v1.0 (Quality & Documentation):**
- ❌ Comprehensive test coverage - Need >90% coverage for all new formatters
- ❌ Performance benchmarks - Need to establish baseline measurements
- ❌ Sphinx documentation site - Professional documentation needed
- ❌ API consistency review - Ensure consistent patterns across modules
- ❌ Package optimization - Final cleanup and size optimization

## [0.1.0] - 2025-01-25

### Added

- Initial implementation of `uicu` package as a Pythonic wrapper around PyICU
- **Character Module (`uicu.char`)**: Unicode character properties with fontTools.unicodedata integration
  - Basic properties: name, category, bidirectional, combining, mirrored
  - Numeric properties: decimal, digit, numeric
  - Script properties: script, script_name, script_extensions, script_direction
  - Block property for Unicode block identification
  - Rich `Char` class for object-oriented access to character properties
  - Automatic fallback to built-in unicodedata when fontTools is unavailable
  
- **Locale Module (`uicu.locale`)**: Central locale management and factory
  - BCP 47 locale identifier support (both hyphen and underscore separators)
  - Factory methods for creating locale-aware services
  - Properties: language, script, region, variant, display_name
  - Convenience functions: get_available_locales(), get_default_locale()
  
- **Collation Module (`uicu.collate`)**: Locale-aware string comparison and sorting
  - Configurable comparison strength levels (primary through identical)
  - Numeric sorting support (2 < 10)
  - Case ordering options (upper first/lower first)
  - Sort key generation for efficient sorting
  - Callable interface for use with sorted()
  - Convenience functions: sort(), compare()
  
- **Segmentation Module (`uicu.segment`)**: Text boundary analysis
  - Grapheme cluster segmentation (user-perceived characters)
  - Word segmentation with locale-specific rules
  - Sentence segmentation with abbreviation handling
  - Line break opportunity detection
  - Reusable segmenter classes for better performance
  - UTF-16 to Python string index conversion
  
- **Transliteration Module (`uicu.translit`)**: Script conversion and text transforms
  - Script-to-script conversion (e.g., Greek→Latin, Cyrillic→Latin)
  - Unicode normalization (NFC, NFD, NFKC, NFKD)
  - Case transformations (upper, lower, title)
  - Compound transform support
  - Custom rule-based transliterators
  - Inverse transform support
  - Filter function for selective transliteration
  
- **Exception Hierarchy**: Clear, specific exception types
  - UICUError: Base exception for all uicu errors
  - ConfigurationError: Invalid configuration
  - CollationError: Collation-specific errors
  - SegmentationError: Segmentation-specific errors
  - TransliterationError: Transliteration-specific errors
  
- **Testing Infrastructure**: Comprehensive test suite
  - 62 tests covering all implemented functionality
  - Tests for edge cases and error conditions
  - Locale-specific behavior tests
  
### Technical Details

- Uses PyICU 2.11+ for core Unicode functionality
- Integrates fontTools.unicodedata for up-to-date Unicode data
- Supports Python 3.10+
- Follows PEP 8 coding standards
- Type hints throughout for better IDE support
- Detailed docstrings with examples

### Known Limitations

- Formatting module (dates, numbers, messages) not yet implemented
- Documentation and usage examples pending
- Some ICU features not yet exposed through Pythonic interface

## [0.1.1] - 2025-01-25

### Fixed
- **Code Quality Improvements** (Fixed issue #101)
  - Resolved all critical linting issues identified by ruff
  - Fixed top-level import violations (PLC0415) in multiple modules:
    - `__init__.py`: Moved script detection imports to module level with proper fallback handling
    - `char.py`: Moved unicodedata import to top level to comply with import standards
    - Note: Kept intentional function-level imports in `locale.py` to prevent circular dependencies
  - Replaced all bare except clauses (E722) with specific exception handling:
    - `__init__.py`: Changed generic except to `except Exception` in detect_script()
    - `translit.py`: Updated exception handling in has_inverse() and get_transform_aliases()
  - Removed all unused imports (F401):
    - `collate.py`: Removed unused `List` and `Union` from typing
    - `translit.py`: Removed unused `List` and `Union` from typing  
    - `uicu.py`: Removed unused `Path`, `Dict`, `List`, `Optional`, and `Union` imports
  - Modernized type hints (UP035):
    - Replaced deprecated `typing.List` and `typing.Dict` with built-in `list` and `dict` types
  - Test improvements:
    - `test_package.py`: Moved import statement to module level
    - `test_segment.py`: Replaced try-except-pass pattern with `contextlib.suppress()`
    - Removed unused pytest import from test_segment.py

### Changed
- **Import Organization**:
  - Standardized import order across all modules
  - Added proper error handling for optional dependencies
  - Improved fallback mechanisms when fontTools is unavailable
  
### Technical Notes
- Remaining non-critical warnings:
  - Module name shadowing (A005) in locale.py is intentional for domain-specific functionality
  - Boolean parameter warnings (FBT001, FBT002) are style preferences, not functional issues
  - Ambiguous character warning (RUF001) in tests is intentional for Unicode testing

## [0.2.0-dev] - 2025-01-25

### Added
- **DateTimeFormatter** in formatting module (partial implementation)
  - ✅ Style-based formatting (full, long, medium, short, none)
  - ✅ Custom pattern support (e.g., 'yyyy-MM-dd HH:mm:ss')
  - ✅ Skeleton pattern support for flexible formatting
  - ✅ Date range formatting with proper interval handling
  - ✅ Timezone support for datetime objects
  - ✅ Integration with Locale factory methods
  - ✅ Comprehensive test suite (10 tests passing)
  - ❌ Parsing functionality broken (returns 1970 epoch dates)
  - ❌ Relative time formatting not implemented
  - ❌ Field position tracking not implemented
  
- **Example Scripts**
  - ✅ Created `examples/uicu_demo.py` with 12 comprehensive demonstrations:
    1. Unicode character property exploration
    2. Culture-aware multilingual name sorting
    3. Text segmentation (graphemes, words, sentences)
    4. Script conversion and transliteration (with error handling)
    5. Locale-aware date/time formatting
    6. Smart numeric vs lexical sorting
    7. Unicode text transformations (normalization, case)
    8. Automatic script detection
    9. Thai word segmentation (no-space languages)
    10. Proper emoji and complex grapheme handling
    11. Case-sensitive sorting control
    12. Bidirectional text analysis

- **Development Infrastructure**
  - Created comprehensive issue tracking system
  - Added issue testing script (`issues/issuetest.py`)
  - Established clear implementation roadmap

### Changed
- Updated Locale class with formatter factory methods:
  - `get_datetime_formatter()` - Create date/time formatters
  - `get_date_formatter()` - Create date-only formatters
  - `get_time_formatter()` - Create time-only formatters
- Enhanced TODO.md with issue number mappings

### Development Status Summary

#### ✅ Completed (Ready for Use)
- Character properties with fontTools integration
- Locale management and factory pattern
- Collation with customizable strength
- Text segmentation (graphemes, words, sentences)
- Transliteration and script conversion
- Script detection
- Comprehensive example script
- Exception hierarchy
- Type hints throughout

#### ⚡ Partially Complete (Use with Caution)
- DateTimeFormatter (formatting works, parsing broken)

#### ❌ Not Started
- NumberFormatter
- ListFormatter  
- MessageFormatter
- Documentation (Sphinx)
- Performance benchmarks
- Unicode regex
- Advanced calendar systems
- Unicode security features

### Fixed
- **Demo Script Bugs** (issue #201)
  - Fixed `category_name` AttributeError by using inline category mapping
  - Fixed `is_mirrored` → `mirrored` property name
  - Fixed `numeric_value` → `numeric` property name
  - Replaced multi-codepoint flag emoji with single-codepoint emoji
  - Added error handling for transliteration failures

### Known Issues
- **DateTimeFormatter**
  - Parsing returns incorrect dates (milliseconds interpreted as seconds)
  - Complex parsing not implemented for non-SimpleDateFormat formatters
  - Relative time formatting not available
  
- **Transliteration**
  - Some transform IDs incorrect (e.g., "Russian-Latin" → "Cyrillic-Latin")
  - No way to list available transliterators
  - Error messages not helpful when transforms unavailable
  
- **Character Properties**
  - Char class rejects multi-codepoint strings (e.g., flag emojis 🇺🇸)
  - No convenient `category_name()` function exported at module level
  - Missing properties for extended grapheme clusters
</file>

<file path="CLAUDE.md">
## Project Overview

`uicu` is a Python package that aims to create a pythonic wrapper around PyICU, supplemented by fontTools.unicodedata. The goal is to provide a natural, performant API that exposes rich, well-documented objects integrating with Python's native Unicode handling while adding extensive Unicode functionality.

## Development Commands

### Environment Setup
```bash
# Install and use uv for package management
pip install uv
# Use hatch for development workflow
uv pip install hatch
```

### Common Development Tasks
```bash
# Activate development environment
hatch shell

# Run tests
hatch run test
python -m pytest

# Run tests with coverage
hatch run test-cov

# Run linting
hatch run lint

# Format code
hatch run format

# Run type checking
hatch run type-check

# After Python changes, run the full formatting pipeline:
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

## Code Architecture

### Project Structure
- **src/uicu/**: Main package source (using src-layout)
  - `__init__.py`: Package initialization
  - `__version__.py`: Version management using hatch-vcs
  - `uicu.py`: Main module (currently skeleton)
- **tests/**: Test suite using pytest
- **pyproject.toml**: PEP 621 compliant project configuration

### Key Dependencies to Research
- **PyICU**: The main Unicode library to wrap
- **fontTools.unicodedata**: Supplementary Unicode data with writing system info

## Development Guidelines

### Python-Specific Rules
- Use `uv pip` instead of `pip`
- Always use `python -m` when running modules
- Use type hints in simple form (list, dict, | for unions)
- Add verbose loguru-based logging and debug-log
- For CLI scripts, use fire & rich libraries
- Scripts should start with `#!/usr/bin/env -S uv run -s`

### Code Quality Standards
- PEP 8 compliant (enforced by Ruff)
- Clear, imperative docstrings (PEP 257)
- Use f-strings for formatting
- Structural pattern matching where appropriate
- Maintain `this_file` comments at the top of each source file

### Development Workflow
1. Create/update `PLAN.md` with detailed flat plan using `[ ]` items
2. Identify important TODOs and update `TODO.md`
3. Implement changes incrementally
4. Update `CHANGELOG.md` after each round of changes
5. Update `README.md` to reflect changes
6. Run the formatting pipeline after Python changes

### Current Project Status
- Initial project structure created
- Main objective: Create pythonic wrapper around PyICU
- First task: Research and document APIs from fontTools.unicodedata and PyICU
- Implementation phase not yet started

## Testing Strategy
- pytest with coverage tracking
- Use pytest-xdist for parallel test execution
- pytest-benchmark for performance testing
- Maintain high test coverage for all new functionality

## Key Principles
- Iterate gradually, avoiding major changes
- Preserve existing code/structure unless necessary
- Write explanatory docstrings that explain what and WHY
- Handle failures gracefully with retries and fallbacks
- Focus on minimal viable increments
- Keep code simple and explicit (PEP 20)

# When you write code

- Iterate gradually, avoiding major changes
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Use constants over magic numbers
- Check for existing solutions in the codebase before starting
- Check often the coherence of the code you're writing with the rest of the code.
- Focus on minimal viable increments and ship early
- Write explanatory docstrings/comments that explain what and WHY this does, explain where and how the code is used/referred to elsewhere in the code
- Analyze code line-by-line
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures
- Consistently keep, document, update and consult the holistic overview mental image of the codebase. 

## Keep track of paths

In each source file, maintain the up-to-date `this_file` record that shows the path of the current file relative to project root. Place the `this_file` record near the top of the file, as a comment after the shebangs, or in the YAML Markdown frontmatter.

## When you write Python

- Use `uv pip`, never `pip`
- Use `python -m` when running code
- PEP 8: Use consistent formatting and naming
- Write clear, descriptive names for functions and variables
- PEP 20: Keep code simple and explicit. Prioritize readability over cleverness
- Use type hints in their simplest form (list, dict, | for unions)
- PEP 257: Write clear, imperative docstrings
- Use f-strings. Use structural pattern matching where appropriate
- ALWAYS add "verbose" mode logugu-based logging, & debug-log
- For CLI Python scripts, use fire & rich, and start the script with

```
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

Work in rounds: 

- Create `PLAN.md` as a detailed flat plan with `[ ]` items. 
- Identify the most important TODO items, and create `TODO.md` with `[ ]` items. 
- Implement the changes. 
- Update `PLAN.md` and `TODO.md` as you go. 
- After each round of changes, update `CHANGELOG.md` with the changes.
- Update `README.md` to reflect the changes.

Ask before extending/refactoring existing code in a way that may add complexity or break things.

When you're finished, print "Wait, but" to go back, think & reflect, revise & improvement what you've done (but don't invent functionality freely). Repeat this. But stick to the goal of "minimal viable next version". Lead two experts: "Ideot" for creative, unorthodox ideas, and "Critin" to critique flawed thinking and moderate for balanced discussions. The three of you shall illuminate knowledge with concise, beautiful responses, process methodically for clear answers, collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

## After Python changes run:

```
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

Be creative, diligent, critical, relentless & funny!

## Development Guidelines

- Only modify code directly relevant to the specific request. Avoid changing unrelated functionality.
- Never replace code with placeholders like `# ... rest of the processing ...`. Always include complete code.
- Break problems into smaller steps. Think through each step separately before implementing.
- Always provide a complete PLAN with REASONING based on evidence from code and logs before making changes.
- Explain your OBSERVATIONS clearly, then provide REASONING to identify the exact issue. Add console logs when needed to gather more information.


`uicu` is a specialized Python package that creates a Pythonic wrapper around PyICU with supplementary Unicode functionality from fontTools.unicodedata. The core business logic revolves around providing rich Unicode data manipulation capabilities through well-documented objects.

## Core Business Components

1. Unicode Data Processing (90)
- Custom wrapper around PyICU providing intuitive Unicode manipulation
- Integration with fontTools.unicodedata for writing system information
- Domain-specific data validation and transformation rules
Location: `src/uicu/uicu.py`

2. Supplementary Unicode Features (85)
- Extended Unicode functionality beyond Python's native capabilities
- Writing system detection and classification
- Custom normalization and decomposition rules
Location: `src/uicu/uicu.py`

3. Unicode Validation Framework (75)
- Custom validation rules for Unicode data integrity
- Error handling specific to Unicode processing
- Fallback mechanisms for unsupported characters
Location: `src/uicu/uicu.py`

## Integration Architecture

The package implements a layered approach to Unicode processing:

1. Base Layer: PyICU Integration
- Direct wrapping of PyICU functionality
- Custom error handling and retry logic
Location: `src/uicu/uicu.py`

2. Enhancement Layer: fontTools Integration
- Additional Unicode metadata and writing system support
- Custom data enrichment rules
Location: `src/uicu/uicu.py`

3. Application Layer: Pythonic Interface
- Natural Python API for Unicode operations
- Rich object model with extensive Unicode properties
Location: `src/uicu/uicu.py`

## Development Workflow

The project follows an iterative development approach with:
- Detailed planning in `PLAN.md`
- Task tracking in `TODO.md`
- Change documentation in `CHANGELOG.md`
- Updated documentation in `README.md`

$END$
</file>

<file path="PLAN.md">
# uicu Implementation Plan - v0.2.0 to v1.0

## Executive Summary

The `uicu` project has successfully implemented core Unicode functionality with PyICU wrappers. Based on the development status and existing streamlining plan, this document outlines the path from the current v0.2.0-dev state to a streamlined v1.0 MVP release that focuses on reliability and performance.

## Current State (v0.2.0-dev)

### ✅ Successfully Implemented
1. **Character Properties** - Complete Unicode character analysis (95% coverage)
2. **Locale Management** - BCP 47 compliant handling (90% coverage)
3. **Collation & Sorting** - Culture-aware comparison (95% coverage)
4. **Text Segmentation** - All break types working (90% coverage)
5. **Transliteration** - Basic functionality (80% coverage)
6. **Date/Time Formatting** - Formatting works, parsing broken (60% coverage)

### ⚠️ Issues Requiring Fixes
1. **src/uicu/uicu.py** - Already removed (placeholder file deleted)
2. **DateTimeFormatter parsing** - Returns 1970 dates (millisecond bug)
3. **Transliterator transform IDs** - Some IDs incorrect
4. **Multi-codepoint handling** - Can't handle flag emojis in Char class
5. **Exception over-engineering** - Too many custom exceptions

### ❌ Not Yet Implemented
1. **Sphinx documentation** - Not set up
2. **Performance benchmarks** - Not created
3. **CI/CD pipeline** - Not configured

## Streamlining Analysis

### Code Quality Issues

1. **Excessive Exception Wrapping**
   - Every module wraps ICU exceptions unnecessarily
   - Loses valuable error context
   - Adds ~5 lines for every 1 line of functionality

2. **Verbose Documentation**
   - Docstrings repeat type hints
   - Explain obvious parameters
   - Multi-paragraph explanations for simple functions

3. **Redundant Validation**
   - Locale validation in every class
   - Character validation repeated
   - Strength validation duplicated

4. **Demo Script Issues**
   - Interactive input() calls break automation
   - Try-except blocks hide real errors
   - Hardcoded mappings duplicate functionality

5. **Import Inefficiencies**
   - Importing entire modules for one constant
   - Multiple conditional imports
   - Complex import error handling

## v1.0 MVP Strategy

### Core Principles
1. **Reliability First** - Only ship features that work 100%
2. **Performance Focus** - <5% overhead vs raw PyICU
3. **Minimal Surface** - Fewer classes, more functions
4. **Clear Errors** - Let ICU errors provide context
5. **Small & Fast** - <100KB package, <100ms imports

### Keep for v1.0 (Working Features)
| Feature | Status | Action |
|---------|--------|--------|
| Character Properties | ✅ Works | Fix multi-codepoint handling |
| Collation/Sorting | ✅ Works | Keep as-is |
| Text Segmentation | ✅ Works | Keep as-is |
| Transliteration | ⚡ Partial | Fix transform IDs |
| Locale Management | ✅ Works | Keep as-is |
| Date Formatting | ⚡ Partial | Keep formatting, remove parsing |

### Remove for v1.0 (Defer/Delete)
| Feature | Reason | Action |
|---------|--------|--------|
| DateTimeFormatter.parse() | Broken (1970 bug) | Delete method |
| NumberFormatter | Not implemented | Defer to v2.0 |
| ListFormatter | Not implemented | Defer to v2.0 |
| MessageFormatter | Not implemented | Defer to v2.0 |
| Field position tracking | Stub code | Delete |
| Relative time formatting | Stub code | Delete |
| Interactive demo | Breaks automation | Make scriptable |

## Implementation Plan (Priority Order)

### Phase 1: Critical Fixes (Week 1) ✅ COMPLETE
- [x] Fix DateTimeFormatter.parse() or remove it entirely (never implemented, no action needed)
- [x] Fix transliterator transform IDs (Issue #202 - added find_transforms() helper)
- [x] Fix multi-codepoint handling in Char class (documented limitation with helpful errors)
- [x] Remove all TODO stub comments from format.py (none found)

### Phase 2: Code Cleanup (Week 2) ✅ COMPLETE
- [x] Simplify exception handling across all modules
- [x] Remove excessive try-except wrapping
- [x] Clean up verbose docstrings
- [x] Optimize imports (conditional imports all well-justified)
- [x] Make demo script non-interactive (already was non-interactive)
- [x] Remove hardcoded category mappings from demo

### Phase 3: API Simplification (Week 3)
- [ ] Consolidate duplicate validation code
- [ ] Reduce custom exceptions from 6 to 3
- [ ] Remove field position tracking stubs
- [ ] Move constants inline where appropriate
- [ ] Make internal classes private (_prefixed)

### Phase 4: Documentation & Testing (Week 4)
- [ ] Set up Sphinx with modern theme (Furo)
- [ ] Auto-generate API documentation from docstrings
- [ ] Write user guides for common use cases
- [ ] Create cookbook with real-world examples
- [ ] Set up automatic deployment to GitHub Pages
- [ ] Update tests for streamlined API
- [ ] Remove tests for deleted features
- [ ] Update README for v1.0 features
- [ ] Create migration guide from v0.2 to v1.0
- [ ] Final performance testing

## Success Metrics

### v1.0 Target Metrics
| Metric | Current | Target | Impact |
|--------|---------|--------|--------|
| Test Coverage | ~80% | >95% | Higher reliability |
| Import Time | ~150ms | <100ms | Faster startup |
| Package Size | ~150KB | <100KB | Smaller footprint |
| Core Code Lines | ~3000 | <2000 | Easier maintenance |
| PyICU Overhead | ~10% | <5% | Better performance |
| Working Features | 90% | 100% | No broken features |

### Code Quality Improvements
- **Exception Classes**: 6 → 3 (50% reduction)
- **Import Complexity**: High → Low
- **Docstring Verbosity**: 40% reduction
- **Validation Duplication**: Eliminated
- **Dead Code**: 0 lines

## Migration Path

### From v0.2.0-dev to v1.0
1. **Breaking Changes**
   - DateTimeFormatter.parse() removed
   - Some exception classes consolidated
   - Internal classes made private
   
2. **API Improvements**
   - Cleaner function signatures
   - Better error messages
   - Consistent naming

3. **Performance Gains**
   - Faster imports
   - Lower memory usage
   - Direct PyICU access where beneficial

## Post-v1.0 Roadmap (v1.1+)

### v1.1 - Enhanced Features
- NumberFormatter for currency, percentages, scientific notation
- ListFormatter for proper locale-aware list joining
- MessageFormatter for complex pluralization
- Advanced timezone handling
- Bulk processing APIs

### v1.2 - Ecosystem Integration
- Django integration
- pandas Unicode extension
- FastAPI i18n plugin
- Jupyter notebook support

## Conclusion

The path to v1.0 focuses on delivering a reliable, performant Unicode library by:
1. Fixing all broken features or removing them
2. Streamlining the codebase for maintainability
3. Optimizing for performance and size
4. Ensuring 100% of shipped features work correctly

This approach prioritizes quality over quantity, resulting in a focused tool that excels at core Unicode operations.
</file>

<file path="pyproject.toml">
# this_file: pyproject.toml
#==============================================================================
# UICU PACKAGE CONFIGURATION
# This pyproject.toml defines the package metadata, dependencies, build system,
# and development environment for the uicu package.
#==============================================================================

#------------------------------------------------------------------------------
# PROJECT METADATA
# Core package information used by PyPI and package managers.
#------------------------------------------------------------------------------
[project]
name = 'uicu' # Package name on PyPI
description = 'A Pythonic wrapper around PyICU with supplementary Unicode functionality from fontTools.unicodedata' # Short description
readme = 'README.md' # Path to README file
requires-python = '>=3.10' # Minimum Python version
keywords = [
    'unicode',
    'icu',
    'pyicu',
    'i18n',
    'internationalization',
    'localization',
    'text',
    'collation',
    'segmentation',
    'transliteration',
] # Keywords for PyPI search
dynamic = ["version"] # Fields set dynamically at build time

# PyPI classifiers for package categorization
classifiers = [
    'Development Status :: 4 - Beta', # Package maturity level
    'Programming Language :: Python',
    'Programming Language :: Python :: 3.10',
    'Programming Language :: Python :: 3.11',
    'Programming Language :: Python :: 3.12',
    'Programming Language :: Python :: Implementation :: CPython',
    'Programming Language :: Python :: Implementation :: PyPy',
    'Operating System :: OS Independent',
    'License :: OSI Approved :: MIT License',
    'Intended Audience :: Developers',
]

dependencies = [
    'PyICU>=2.11',
    'fontTools[unicode]>=4.38.0',
]

# Author information
[[project.authors]]
name = 'Adam Twardoch'
email = 'adam+github@twardoch.com'

# License information
[project.license]
text = 'MIT'

# Project URLs
[project.urls]
Documentation = 'https://github.com/twardoch/uicu#readme'
Issues = 'https://github.com/twardoch/uicu/issues'
Source = 'https://github.com/twardoch/uicu'

#------------------------------------------------------------------------------
# OPTIONAL DEPENDENCIES
# Additional dependencies for optional features, development, and testing.
#------------------------------------------------------------------------------
[project.optional-dependencies]

# Development tools
dev = [
    'pre-commit>=4.1.0', # Pre-commit hook manager - Keep pre-commit as is, update if newer pre-commit version is required
    'ruff>=0.9.7', # Linting and formatting - Keep ruff as is, update if newer ruff version is required
    'mypy>=1.15.0', # Type checking - Keep mypy as is, update if newer mypy version is required
    'absolufy-imports>=0.3.1', # Convert relative imports to absolute - Keep absolufy-imports as is, update if newer absolufy-imports version is required
    'pyupgrade>=3.19.1', # Upgrade Python syntax - Keep pyupgrade as is, update if newer pyupgrade version is required
    'isort>=6.0.1', # Sort imports - Keep isort as is, update if newer isort version is required
]

# Testing tools and frameworks
test = [
    'pytest>=8.3.4', # Testing framework - Keep pytest as is, update if newer pytest version is required
    'pytest-cov>=6.0.0', # Coverage plugin for pytest - Keep pytest-cov as is, update if newer pytest-cov version is required
    'pytest-xdist>=3.6.1', # Parallel test execution - Keep pytest-xdist as is, update if newer pytest-xdist version is required
    'pytest-benchmark[histogram]>=5.1.0', # Benchmarking plugin - Keep pytest-benchmark as is, update if newer pytest-benchmark version is required
    'pytest-asyncio>=0.25.3', # Async test support - Keep pytest-asyncio as is, update if newer pytest-asyncio version is required
    'coverage[toml]>=7.6.12',
]

docs = [
    "sphinx>=7.2.6",
    "sphinx-rtd-theme>=2.0.0",
    "sphinx-autodoc-typehints>=2.0.0",
    "myst-parser>=3.0.0", # Markdown support in Sphinx
]

# All optional dependencies combined
all = [
]

#------------------------------------------------------------------------------
# COMMAND-LINE SCRIPTS
# Entry points for command-line executables installed with the package.
#------------------------------------------------------------------------------
[project.scripts]
# CLINAME = "uicu.__main__:main"

#------------------------------------------------------------------------------
# BUILD SYSTEM CONFIGURATION
# Defines the tools required to build the package and the build backend.
#------------------------------------------------------------------------------
[build-system]
# Hatchling is a modern build backend for Python packaging
# hatch-vcs integrates with version control systems for versioning
requires = [
    'hatchling>=1.27.0', # Keep hatchling as is, update if newer hatchling version is required
    'hatch-vcs>=0.4.0', # Keep hatch-vcs as is, update if newer hatch-vcs version is required
]
build-backend = 'hatchling.build' # Specifies Hatchling as the build backend


#------------------------------------------------------------------------------
# HATCH BUILD CONFIGURATION
# Configures the build process, specifying which packages to include and
# how to handle versioning.
#------------------------------------------------------------------------------
[tool.hatch.build]
# Include package data files
include = [
    "src/uicu/py.typed", # For better type checking support
    "src/uicu/data/**/*", # Include data files if any

]
exclude = ["**/__pycache__", "**/.pytest_cache", "**/.mypy_cache"]

[tool.hatch.build.targets.wheel]
packages = ["src/uicu"]
reproducible = true


# Version control system hook configuration
# Automatically updates the version file from git tags
[tool.hatch.build.hooks.vcs]
version-file = "src/uicu/__version__.py"

# Version source configuration
[tool.hatch.version]
source = 'vcs' # Get version from git tags or other VCS info

# Metadata handling configuration
[tool.hatch.metadata]
allow-direct-references = true # Allow direct references in metadata (useful for local dependencies)


#------------------------------------------------------------------------------
# DEVELOPMENT ENVIRONMENTS

[tool.hatch.envs.default]
features = ['dev', 'test', 'all']
dependencies = [
]

# Commands available in the default environment
[tool.hatch.envs.default.scripts]
# Run tests with optional arguments
test = 'pytest {args:tests}'
# Run tests with coverage reporting
test-cov = "pytest --cov-report=term-missing --cov-config=pyproject.toml --cov=src/uicu --cov=tests {args:tests}"
# Run type checking
type-check = "mypy src/uicu tests"
# Run linting and formatting
lint = ["ruff check src/uicu tests", "ruff format --respect-gitignore src/uicu tests"]
# Format and fix style issues
fmt = ["ruff format --respect-gitignore src/uicu tests", "ruff check --fix src/uicu tests"]
fix = ["ruff check --fix --unsafe-fixes src/uicu tests", "ruff format --respect-gitignore src/uicu tests"]

# Matrix configuration to test across multiple Python versions

[[tool.hatch.envs.all.matrix]]
python = ["3.10", "3.11", "3.12"]

#------------------------------------------------------------------------------
# SPECIALIZED ENVIRONMENTS
# Additional environments for specific development tasks.
#------------------------------------------------------------------------------

# Dedicated environment for linting and code quality checks
[tool.hatch.envs.lint]
detached = true # Create a separate, isolated environment
features = ['dev'] # Use dev extras  dependencies 

# Linting environment commands
[tool.hatch.envs.lint.scripts]
# Type checking with automatic type installation
typing = "mypy --install-types --non-interactive {args:src/uicu tests}"
# Check style and format code
style = ["ruff check {args:.}", "ruff format --respect-gitignore {args:.}"]
# Format and fix style issues
fmt = ["ruff format --respect-gitignore {args:.}", "ruff check --fix {args:.}"]
fix = ["ruff check --fix --unsafe-fixes {args:.}", "ruff format --respect-gitignore {args:.}"]
# Run all ops
all = ["style", "typing", "fix"]

# Dedicated environment for testing
[tool.hatch.envs.test]
features = ['test'] # Use test extras as dependencies

# Testing environment commands
[tool.hatch.envs.test.scripts]
# Run tests in parallel
test = "python -m pytest -n auto {args:tests}"
# Run tests with coverage in parallel
test-cov = "python -m pytest -n auto --cov-report=term-missing --cov-config=pyproject.toml --cov=src/uicu --cov=tests {args:tests}"
# Run benchmarks
bench = "python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only"
# Run benchmarks and save results
bench-save = "python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only --benchmark-json=benchmark/results.json"

# Documentation environment
[tool.hatch.envs.docs]
features = ['docs']

# Documentation environment commands
[tool.hatch.envs.docs.scripts]
build = "sphinx-build -b html docs/source docs/build"

# GitHub Actions workflow configuration
[tool.hatch.envs.ci]
features = ['test']


[tool.hatch.envs.ci.scripts]
test = "pytest --cov=src/uicu --cov-report=xml"


#------------------------------------------------------------------------------
# CODE QUALITY TOOLS
# Configuration for linting, formatting, and code quality enforcement.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# COVERAGE CONFIGURATION
# Settings for test coverage measurement and reporting.
#------------------------------------------------------------------------------

# Path mapping for coverage in different environments
[tool.coverage.paths]
uicu = ["src/uicu", "*/uicu/src/uicu"]
tests = ["tests", "*/uicu/tests"]

# Coverage report configuration
[tool.coverage.report]
# Lines to exclude from coverage reporting
exclude_lines = [
    'no cov', # Custom marker to skip coverage
    'if __name__ == .__main__.:', # Script execution guard
    'if TYPE_CHECKING:', # Type checking imports and code
    'pass', # Empty pass statements
    'raise NotImplementedError', # Unimplemented method placeholders
    'raise ImportError', # Import error handling
    'except ImportError', # Import error handling
    'except KeyError', # Common error handling
    'except AttributeError', # Common error handling
    'except NotImplementedError', # Common error handling
]

[tool.coverage.run]
source_pkgs = ["uicu", "tests"]
branch = true # Measure branch coverage (if/else statements)
parallel = true # Support parallel test execution
omit = [
    "src/uicu/__about__.py",
]

#------------------------------------------------------------------------------
# MYPY CONFIGURATION
# Configuration for type checking with mypy.
#------------------------------------------------------------------------------

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true

[[tool.mypy.overrides]]
module = "icu.*"
ignore_missing_imports = true

[[tool.mypy.overrides]]
module = ["tests.*"]
disallow_untyped_defs = false

#------------------------------------------------------------------------------
# PYTEST CONFIGURATION
# Configuration for pytest, including markers, options, and benchmark settings.
#------------------------------------------------------------------------------

[tool.pytest.ini_options]
addopts = "-v --durations=10 -p no:briefcase"
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"
console_output_style = "progress"
filterwarnings = ["ignore::DeprecationWarning", "ignore::UserWarning"]
log_cli = true
log_cli_level = "INFO"
markers = [
    "benchmark: marks tests as benchmarks (select with '-m benchmark')",
    "unit: mark a test as a unit test",
    "integration: mark a test as an integration test",
    "permutation: tests for permutation functionality", 
    "parameter: tests for parameter parsing",
    "prompt: tests for prompt parsing",
]
norecursedirs = [
    ".*",
    "build",
    "dist", 
    "venv",
    "__pycache__",
    "*.egg-info",
    "_private",
]
python_classes = ["Test*"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
testpaths = ["tests"]

[tool.pytest-benchmark]
min_rounds = 100
min_time = 0.1
histogram = true
storage = "file"
save-data = true
compare = [
    "min",    # Minimum time
    "max",    # Maximum time
    "mean",   # Mean time
    "stddev", # Standard deviation
    "median", # Median time
    "iqr",    # Inter-quartile range
    "ops",    # Operations per second
    "rounds", # Number of rounds
]

#------------------------------------------------------------------------------
# RUFF CONFIGURATION
# Configuration for Ruff, including linter and formatter settings.
#------------------------------------------------------------------------------ 

# Ruff linter and formatter configuration
[tool.ruff]
target-version = "py310"
line-length = 120

# Linting rules configuration
[tool.ruff.lint]
# Rule sets to enable, organized by category
select = [
    # flake8 plugins and extensions
    'A', # flake8-builtins: checks for shadowed builtins
    'ARG', # flake8-unused-arguments: checks for unused function arguments
    'ASYNC', # flake8-async: checks for async/await issues
    'B', # flake8-bugbear: finds likely bugs and design problems
    'C', # flake8-comprehensions: helps write better list/dict comprehensions
    'DTZ', # flake8-datetimez: checks for datetime timezone issues
    'E', # pycodestyle errors: PEP 8 style guide errors
    'EM', # flake8-errmsg: checks for better error messages
    'F', # pyflakes: detects various errors
    'FBT', # flake8-boolean-trap: checks for boolean traps in function signatures
    'I', # isort: sorts imports
    'ICN', # flake8-import-conventions: checks for import conventions
    'ISC', # flake8-implicit-str-concat: checks for implicit string concatenation
    'LOG', # flake8-logging: checks for logging issues
    'N', # pep8-naming: checks naming conventions
    'PLC', # pylint convention: checks for convention issues
    'PLE', # pylint error: checks for errors
    'PLR', # pylint refactor: suggests refactors
    'PLW', # pylint warning: checks for suspicious code
    'PT', # flake8-pytest-style: checks pytest-specific style
    'PTH', # flake8-use-pathlib: checks for stdlib path usage vs pathlib
    'PYI', # flake8-pyi: checks stub files
    'RET', # flake8-return: checks return statement consistency
    'RSE', # flake8-raise: checks raise statements
    'RUF', # Ruff-specific rules
    'S', # flake8-bandit: checks for security issues
    'SIM', # flake8-simplify: checks for code simplification opportunities
    'T', # flake8-print: checks for print statements
    'TCH', # flake8-type-checking: helps with type-checking
    'TID', # flake8-tidy-imports: checks for tidy import statements
    'UP', # pyupgrade: checks for opportunities to use newer Python features
    'W', # pycodestyle warnings: PEP 8 style guide warnings
    'YTT', # flake8-2020: checks for misuse of sys.version or sys.version_info

]
# Rules to ignore (with reasons)
ignore = [
    'B027', # Empty method in abstract base class - sometimes needed for interfaces
    'C901', # Function is too complex - sometimes complexity is necessary
    'FBT003', # Boolean positional argument in function definition - sometimes unavoidable
    'PLR0911', # Too many return statements - sometimes needed for readability
    'PLR0912', # Too many branches - sometimes needed for complex logic
    'PLR0913', # Too many arguments - sometimes needed in APIs
    'PLR0915', # Too many statements - sometimes needed for comprehensive functions
    'PLR1714', # Consider merging multiple comparisons - sometimes less readable
    'PLW0603', # Using the global statement - sometimes necessary
    'PT013', # Pytest explicit test parameter - sometimes clearer
    'PTH123', # Path traversal - sometimes needed
    'PYI056', # Calling open() in pyi file - sometimes needed in type stubs
    'S105', # Possible hardcoded password - often false positives
    'S106', # Possible hardcoded password - often false positives
    'S107', # Possible hardcoded password - often false positives
    'S110', # try-except-pass - sometimes valid for suppressing exceptions
    'SIM102'
    # Nested if statements - sometimes more readable than combined conditions
]
# Rules that should not be automatically fixed
unfixable = [
    'F401', # Don't automatically remove unused imports - may be needed later

]
# Configure exclude to ignore specific directories
exclude = [".git", ".venv", "venv", "dist", "build"]

# isort configuration within Ruff
[tool.ruff.lint.isort]
known-first-party = ['uicu'] # Treat as first-party imports for sorting

# flake8-tidy-imports configuration within Ruff
[tool.ruff.lint.flake8-tidy-imports]
ban-relative-imports = 'all' # Ban all relative imports for consistency

# Per-file rule exceptions
[tool.ruff.lint.per-file-ignores]
# Tests can use magic values, assertions, and relative imports
'tests/**/*' = [
    'PLR2004', # Allow magic values in tests for readability
    'S101', # Allow assertions in tests
    'TID252'
    # Allow relative imports in tests for convenience
]
</file>

<file path="tests/test_package.py">
"""Test suite for uicu."""

import uicu


def test_version():
    """Verify package exposes version."""
    assert uicu.__version__
</file>

<file path="README.md">
# `uicu`

A Pythonic wrapper around PyICU with supplementary Unicode functionality from fontTools.unicodedata.

<!-- badges-begin -->
[![PyPI - Version](https://img.shields.io/pypi/v/uicu.svg)](https://pypi.org/project/uicu)
[![PyPI - Python Version](https://img.shields.io/pypi/pyversions/uicu.svg)](https://pypi.org/project/uicu)
<!-- badges-end -->

## Overview

`uicu` provides natural, Pythonic interfaces to ICU's powerful internationalization and Unicode capabilities. It transforms PyICU's C++-style API into idiomatic Python, making advanced text processing accessible to Python developers.

### Key Features

- **Unicode Character Properties**: Rich character information with up-to-date Unicode data
- **Locale-Aware Operations**: Sorting, formatting, and text processing that respects locale rules
- **Text Segmentation**: Break text into graphemes, words, and sentences according to Unicode rules
- **Script Conversion**: Transliterate between writing systems (Greek→Latin, Cyrillic→Latin, etc.)
- **Collation**: Locale-sensitive string comparison and sorting with customizable strength levels
- **High Performance**: Built on ICU's optimized C++ implementation

## Installation

```bash
pip install uicu
```

### Dependencies

- Python 3.10+
- PyICU 2.11+
- fontTools[unicode] 4.38.0+ (for enhanced Unicode data)

## Quick Start

### Character Properties

```python
import uicu

# Get character information
char = uicu.Char('€')
print(char.name)         # 'EURO SIGN'
print(char.category)     # 'Sc' (Currency Symbol)
print(char.script)       # 'Zyyy' (Common)
print(char.block)        # 'Currency Symbols'

# Direct function access
print(uicu.name('你'))    # 'CJK UNIFIED IDEOGRAPH-4F60'
print(uicu.script('A'))   # 'Latn'

# Note: Multi-codepoint strings (like flag emojis) need special handling
# char = uicu.Char('🎉')  # ✅ Works: Party popper (single codepoint)
# char = uicu.Char('🇺🇸')  # ❌ Fails: US flag (two codepoints)
```

### Locale-Aware Collation

```python
import uicu

# Create a locale-specific collator
collator = uicu.Collator('de-DE')  # German collation rules

# Sort strings according to locale
words = ['Müller', 'Mueller', 'Mahler']
sorted_words = collator.sort(words)
print(sorted_words)  # German-specific ordering

# Numeric sorting
numeric_collator = uicu.Collator('en-US', numeric=True)
items = ['item10', 'item2', 'item1']
print(numeric_collator.sort(items))  # ['item1', 'item2', 'item10']

# Direct comparison
print(uicu.compare('café', 'cafe', 'en-US'))  # 1 (café > cafe)
```

### Text Segmentation

```python
import uicu

# Break text into user-perceived characters (grapheme clusters)
text = "👨‍👩‍👧‍👦"  # Family emoji
print(list(uicu.graphemes(text)))  # ['👨‍👩‍👧‍👦'] - single grapheme!

# Word segmentation
text = "Hello, world! How are you?"
words = list(uicu.words(text))
print(words)  # ['Hello', 'world', 'How', 'are', 'you']

# Sentence segmentation
text = "Dr. Smith went to N.Y.C. yesterday. He's busy!"
sentences = list(uicu.sentences(text))
print(sentences)  # Handles abbreviations correctly

# Language-specific segmentation
thai_text = "สวัสดีครับ"
thai_words = list(uicu.words(thai_text, locale='th-TH'))
```

### Script Conversion and Transliteration

```python
import uicu

# Convert between scripts
trans = uicu.Transliterator('Greek-Latin')
print(trans.transliterate('Ελληνικά'))  # 'Ellēniká'

# Remove accents
trans = uicu.Transliterator('Latin-ASCII')
print(trans.transliterate('café résumé'))  # 'cafe resume'

# Chain transformations
trans = uicu.Transliterator('Any-Latin; Latin-ASCII; Lower')
print(trans.transliterate('北京'))  # 'bei jing'

# Case transformations
upper = uicu.Transliterator('Upper')
print(upper.transliterate('hello'))  # 'HELLO'
```

### Working with Locales

```python
import uicu

# Create and inspect locales
locale = uicu.Locale('zh-Hant-TW')
print(locale.language)     # 'zh'
print(locale.script)       # 'Hant'
print(locale.region)       # 'TW'
print(locale.display_name) # 'Chinese (Traditional, Taiwan)'

# Get system default locale
default = uicu.get_default_locale()
print(default.language_tag)  # e.g., 'en-US'

# List available locales
locales = uicu.get_available_locales()
print(f"Available locales: {len(locales)}")  # 700+ locales

# Create locale-specific services
formatter = locale.get_datetime_formatter(date_style='long', time_style='short')
# Note: Formatting works but parsing is currently broken
```

## Advanced Usage

### Custom Collation Strength

```python
# Primary strength - ignores case and accents
collator = uicu.Collator('en-US', strength='primary')
print(collator.compare('café', 'CAFE'))  # 0 (equal)

# Secondary strength - considers accents but not case
collator = uicu.Collator('en-US', strength='secondary')
print(collator.compare('café', 'CAFÉ'))  # 0 (equal)
print(collator.compare('café', 'cafe'))  # 1 (café > cafe)

# Tertiary strength (default) - considers case
collator = uicu.Collator('en-US', strength='tertiary')
print(collator.compare('café', 'Café'))  # 1 (café > Café)
```

### Reusable Segmenters

```python
# Create reusable segmenters for better performance
word_segmenter = uicu.WordSegmenter('en-US')
sentences = [
    "This is a test.",
    "Another sentence here.",
    "And one more!"
]

for sentence in sentences:
    words = list(word_segmenter.segment(sentence))
    print(f"{len(words)} words: {words}")
```

### Script Detection

```python
# Detect the primary script in text
print(uicu.detect_script('Hello'))      # 'Latn'
print(uicu.detect_script('你好'))        # 'Hani'
print(uicu.detect_script('مرحبا'))      # 'Arab'
print(uicu.detect_script('Привет'))     # 'Cyrl'
```

## API Design Philosophy

`uicu` follows these principles:

1. **Pythonic**: Natural Python idioms, not C++ style
2. **Unicode-first**: Seamless handling of all Unicode text
3. **Locale-aware**: Respect cultural and linguistic differences
4. **Performance**: Efficient ICU algorithms under the hood
5. **Compatibility**: Works with Python's built-in string types
6. **Fallbacks**: Graceful degradation when optional features unavailable

## Development Status

### Version 0.1.1 (2025-01-25)

Currently implemented:
- ✅ Unicode character properties with fontTools.unicodedata integration
- ✅ Locale management with BCP 47 support
- ✅ Collation and sorting with customizable strength levels
- ✅ Text segmentation (graphemes, words, sentences, line breaks)
- ✅ Transliteration and script conversion
- ✅ Script detection for text analysis
- ✅ Comprehensive exception hierarchy
- ✅ Type hints throughout for better IDE support
- ⚡ Date/time formatting (partial - formatting works, parsing needs fixes)
- ✅ Comprehensive example script demonstrating all features

Recent improvements:
- 🔧 Fixed all critical linting issues for better code quality
- 🔧 Modernized type hints to use built-in types
- 🔧 Improved error handling with specific exceptions
- 🔧 Optimized imports and removed unused code
- 🆕 Added DateTimeFormatter with style-based and pattern-based formatting
- 🆕 Added date range formatting support
- 🆕 Added comprehensive demo script (`examples/uicu_demo.py`)

Coming soon:
- ⏳ Fix date/time parsing functionality
- ⏳ Number formatting (decimal, currency, percent, scientific)
- ⏳ Message formatting with plural/gender support
- ⏳ List formatting with locale-appropriate conjunctions
- ⏳ Relative time formatting ("3 days ago", "in 2 hours")
- ⏳ Calendar operations
- ⏳ Advanced timezone handling
- ⏳ Unicode regex support
- ⏳ Bidirectional text layout
- ⏳ Unicode security (confusables, spoofing detection)
- ⏳ Number spellout
- ⏳ Performance benchmarks
- ⏳ Sphinx documentation

## Examples

Run the comprehensive demo to see all features in action:

```bash
python examples/uicu_demo.py
```

This demo includes:
1. Unicode character exploration with properties
2. Culture-aware multilingual name sorting
3. Text segmentation (graphemes, words, sentences)
4. Script conversion and transliteration
5. Locale-aware date/time formatting
6. Smart numeric vs lexical sorting
7. Unicode text transformations
8. Automatic script detection
9. Thai word segmentation
10. Emoji and complex grapheme handling
11. Case-sensitive sorting control
12. Bidirectional text analysis

## Development

### Environment Setup

```bash
# Install and use uv for package management
pip install uv

# Use hatch for development workflow
uv pip install hatch
```

### Common Development Tasks

```bash
# Activate development environment
hatch shell

# Run tests
hatch run test

# Run tests with coverage
hatch run test-cov

# Run linting
hatch run lint

# Format code
hatch run format

# Run type checking
hatch run type-check
```

## Contributing

Contributions are welcome! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments

- Built on top of [PyICU](https://pypi.org/project/PyICU/), which provides Python bindings for ICU
- Enhanced with [fontTools.unicodedata](https://github.com/fonttools/fonttools) for up-to-date Unicode data
- Inspired by the need for more Pythonic Unicode handling in Python applications
</file>

<file path="TODO.md">
# TODO - uicu v1.0 MVP

## 🎯 Focus: Fast, Reliable, Essential Unicode Operations

## ✅ Already Completed

### Phase 1: Critical Fixes
- [x] Fix or remove DateTimeFormatter.parse() method (never implemented, no action needed)
- [x] Fix transliterator transform IDs (added find_transforms() helper)
- [x] Fix Char class to handle multi-codepoint strings (documented limitation, improved error messages)
- [x] Remove all TODO stub comments from format.py (none found)

### Phase 2: Code Cleanup
- [x] Simplify exception handling - removed excessive try-except wrapping
- [x] Let ICU exceptions bubble up with original context
- [x] Clean up verbose docstrings (removed parameter type repetition)
- [x] Optimize imports - conditional imports all well-justified
- [x] Make demo script non-interactive (already was non-interactive)
- [x] Remove hardcoded category mappings from demo

## 🎯 Current Tasks

### Phase 3: API Simplification
- [ ] Consolidate duplicate validation code
- [ ] Reduce custom exceptions from 6 to 3
- [ ] Remove field position tracking stubs
- [ ] Move constants inline where appropriate
- [ ] Make internal classes private (_prefixed)

### Phase 4: Documentation & Testing
- [ ] Set up Sphinx with modern theme (Furo)
- [ ] Auto-generate API documentation from docstrings
- [ ] Write user guides for common use cases
- [ ] Create cookbook with real-world examples
- [ ] Set up automatic deployment to GitHub Pages
- [ ] Update tests for streamlined API
- [ ] Remove tests for deleted features
- [ ] Update README for v1.0 features
- [ ] Create migration guide from v0.2 to v1.0
- [ ] Final performance testing

## 📏 Success Criteria for v1.0

### Metrics
- [ ] Test coverage: >95%
- [ ] Import time: <100ms
- [ ] Package size: <100KB
- [ ] Core code lines: <2000
- [ ] PyICU overhead: <5%
- [ ] Working features: 100%

### Code Quality
- [ ] Exception classes reduced to 3
- [ ] Import complexity reduced
- [ ] Docstring verbosity reduced by 40%
- [ ] Validation duplication eliminated
- [ ] Dead code eliminated

## 🚫 Deferred to v2.0

**Not implementing in v1.0:**
- NumberFormatter
- ListFormatter
- MessageFormatter
- Field position tracking
- Relative time formatting
- Property-based testing
- CI/CD pipeline
- Unicode regex support
- Advanced calendar systems

## ✨ v1.0 Feature Set

**Core Features (100% Working):**
1. **Character Properties** - Unicode character analysis
2. **Collation** - Locale-aware string comparison and sorting
3. **Segmentation** - Grapheme, word, sentence, line breaking
4. **Transliteration** - Script conversion and normalization
5. **Date Formatting** - Locale-aware date/time display (no parsing)
6. **Locale Management** - BCP 47 locale handling

**Philosophy**: Ship a small, fast, reliable v1.0 that excels at core Unicode operations.
</file>

</files>
